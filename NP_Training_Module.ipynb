{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "553bd2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as pl\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.optimize as spo\n",
    "import pandas as pd\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a38a478",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myEnv/lib/python3.12/site-packages/tensorflow/python/framework/constant_op.py:108: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return ops.EagerTensor(value, ctx.device_name, dtype)\n",
      "/opt/anaconda3/envs/myEnv/lib/python3.12/site-packages/tensorflow/python/framework/constant_op.py:108: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return ops.EagerTensor(value, ctx.device_name, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4819 - loss: 0.7142 - val_accuracy: 0.5120 - val_loss: 0.6945\n",
      "Epoch 2/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5100 - loss: 0.6968 - val_accuracy: 0.4819 - val_loss: 0.7010\n",
      "Epoch 3/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5382 - loss: 0.6900 - val_accuracy: 0.4779 - val_loss: 0.6978\n",
      "Epoch 4/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5683 - loss: 0.6899 - val_accuracy: 0.4940 - val_loss: 0.6989\n",
      "Epoch 5/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5502 - loss: 0.6892 - val_accuracy: 0.4699 - val_loss: 0.6978\n",
      "Epoch 6/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5361 - loss: 0.6891 - val_accuracy: 0.4859 - val_loss: 0.6973\n",
      "Epoch 7/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5422 - loss: 0.6860 - val_accuracy: 0.4679 - val_loss: 0.6998\n",
      "Epoch 8/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5743 - loss: 0.6857 - val_accuracy: 0.4759 - val_loss: 0.6986\n",
      "Epoch 9/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5562 - loss: 0.6832 - val_accuracy: 0.4920 - val_loss: 0.7005\n",
      "Epoch 10/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5341 - loss: 0.6856 - val_accuracy: 0.4679 - val_loss: 0.7016\n",
      "Epoch 11/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5402 - loss: 0.6851 - val_accuracy: 0.4859 - val_loss: 0.7004\n",
      "Epoch 12/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5582 - loss: 0.6830 - val_accuracy: 0.4920 - val_loss: 0.7021\n",
      "Epoch 13/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6124 - loss: 0.6766 - val_accuracy: 0.4819 - val_loss: 0.7024\n",
      "Epoch 14/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5683 - loss: 0.6786 - val_accuracy: 0.5040 - val_loss: 0.7012\n",
      "Epoch 15/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5904 - loss: 0.6753 - val_accuracy: 0.4900 - val_loss: 0.7043\n",
      "Epoch 16/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5763 - loss: 0.6781 - val_accuracy: 0.4880 - val_loss: 0.7056\n",
      "Epoch 17/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5763 - loss: 0.6745 - val_accuracy: 0.4880 - val_loss: 0.7048\n",
      "Epoch 18/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6185 - loss: 0.6670 - val_accuracy: 0.4880 - val_loss: 0.7080\n",
      "Epoch 19/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5984 - loss: 0.6672 - val_accuracy: 0.4759 - val_loss: 0.7099\n",
      "Epoch 20/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6044 - loss: 0.6625 - val_accuracy: 0.4940 - val_loss: 0.7133\n",
      "Epoch 21/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5924 - loss: 0.6590 - val_accuracy: 0.4699 - val_loss: 0.7146\n",
      "Epoch 22/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6084 - loss: 0.6568 - val_accuracy: 0.4719 - val_loss: 0.7168\n",
      "Epoch 23/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6165 - loss: 0.6535 - val_accuracy: 0.4980 - val_loss: 0.7166\n",
      "Epoch 24/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6486 - loss: 0.6489 - val_accuracy: 0.4699 - val_loss: 0.7219\n",
      "Epoch 25/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6285 - loss: 0.6431 - val_accuracy: 0.4960 - val_loss: 0.7202\n",
      "Epoch 26/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6245 - loss: 0.6444 - val_accuracy: 0.4940 - val_loss: 0.7218\n",
      "Epoch 27/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6325 - loss: 0.6384 - val_accuracy: 0.4819 - val_loss: 0.7266\n",
      "Epoch 28/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6426 - loss: 0.6368 - val_accuracy: 0.4900 - val_loss: 0.7275\n",
      "Epoch 29/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6466 - loss: 0.6348 - val_accuracy: 0.5040 - val_loss: 0.7262\n",
      "Epoch 30/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6486 - loss: 0.6292 - val_accuracy: 0.4839 - val_loss: 0.7352\n",
      "Epoch 31/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6426 - loss: 0.6244 - val_accuracy: 0.5161 - val_loss: 0.7367\n",
      "Epoch 32/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6546 - loss: 0.6231 - val_accuracy: 0.4799 - val_loss: 0.7421\n",
      "Epoch 33/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6486 - loss: 0.6167 - val_accuracy: 0.5040 - val_loss: 0.7416\n",
      "Epoch 34/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6566 - loss: 0.6197 - val_accuracy: 0.5020 - val_loss: 0.7455\n",
      "Epoch 35/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6546 - loss: 0.6137 - val_accuracy: 0.4980 - val_loss: 0.7469\n",
      "Epoch 36/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6707 - loss: 0.6136 - val_accuracy: 0.4859 - val_loss: 0.7613\n",
      "Epoch 37/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6426 - loss: 0.6139 - val_accuracy: 0.4980 - val_loss: 0.7595\n",
      "Epoch 38/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6627 - loss: 0.6084 - val_accuracy: 0.5141 - val_loss: 0.7535\n",
      "Epoch 39/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6847 - loss: 0.6003 - val_accuracy: 0.4940 - val_loss: 0.7632\n",
      "Epoch 40/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6667 - loss: 0.6007 - val_accuracy: 0.4980 - val_loss: 0.7694\n",
      "Epoch 41/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6687 - loss: 0.5968 - val_accuracy: 0.4960 - val_loss: 0.7672\n",
      "Epoch 42/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6747 - loss: 0.5949 - val_accuracy: 0.4920 - val_loss: 0.7670\n",
      "Epoch 43/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6747 - loss: 0.5922 - val_accuracy: 0.4859 - val_loss: 0.7764\n",
      "Epoch 44/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6606 - loss: 0.5916 - val_accuracy: 0.5141 - val_loss: 0.7833\n",
      "Epoch 45/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6827 - loss: 0.5875 - val_accuracy: 0.5000 - val_loss: 0.7830\n",
      "Epoch 46/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6807 - loss: 0.5896 - val_accuracy: 0.5040 - val_loss: 0.7754\n",
      "Epoch 47/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6807 - loss: 0.5881 - val_accuracy: 0.5080 - val_loss: 0.7899\n",
      "Epoch 48/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6767 - loss: 0.5862 - val_accuracy: 0.4960 - val_loss: 0.7914\n",
      "Epoch 49/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6687 - loss: 0.5827 - val_accuracy: 0.5000 - val_loss: 0.7892\n",
      "Epoch 50/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6787 - loss: 0.5776 - val_accuracy: 0.4980 - val_loss: 0.7903\n",
      "Epoch 51/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6627 - loss: 0.5793 - val_accuracy: 0.4880 - val_loss: 0.8059\n",
      "Epoch 52/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6687 - loss: 0.5773 - val_accuracy: 0.5120 - val_loss: 0.7972\n",
      "Epoch 53/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6586 - loss: 0.5883 - val_accuracy: 0.5141 - val_loss: 0.7999\n",
      "Epoch 54/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6948 - loss: 0.5766 - val_accuracy: 0.4880 - val_loss: 0.8032\n",
      "Epoch 55/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6968 - loss: 0.5707 - val_accuracy: 0.4839 - val_loss: 0.8137\n",
      "Epoch 56/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6847 - loss: 0.5683 - val_accuracy: 0.5060 - val_loss: 0.8106\n",
      "Epoch 57/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6908 - loss: 0.5710 - val_accuracy: 0.5060 - val_loss: 0.8190\n",
      "Epoch 58/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6908 - loss: 0.5704 - val_accuracy: 0.5100 - val_loss: 0.8081\n",
      "Epoch 59/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6928 - loss: 0.5649 - val_accuracy: 0.4940 - val_loss: 0.8241\n",
      "Epoch 60/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6948 - loss: 0.5592 - val_accuracy: 0.5040 - val_loss: 0.8306\n",
      "Epoch 61/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6928 - loss: 0.5593 - val_accuracy: 0.4960 - val_loss: 0.8220\n",
      "Epoch 62/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7008 - loss: 0.5608 - val_accuracy: 0.4940 - val_loss: 0.8349\n",
      "Epoch 63/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6847 - loss: 0.5630 - val_accuracy: 0.5120 - val_loss: 0.8247\n",
      "Epoch 64/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6807 - loss: 0.5586 - val_accuracy: 0.4900 - val_loss: 0.8364\n",
      "Epoch 65/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6867 - loss: 0.5536 - val_accuracy: 0.4940 - val_loss: 0.8447\n",
      "Epoch 66/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6968 - loss: 0.5493 - val_accuracy: 0.4980 - val_loss: 0.8398\n",
      "Epoch 67/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6908 - loss: 0.5557 - val_accuracy: 0.4960 - val_loss: 0.8550\n",
      "Epoch 68/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6988 - loss: 0.5468 - val_accuracy: 0.4940 - val_loss: 0.8511\n",
      "Epoch 69/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7088 - loss: 0.5454 - val_accuracy: 0.4920 - val_loss: 0.8560\n",
      "Epoch 70/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7028 - loss: 0.5427 - val_accuracy: 0.5000 - val_loss: 0.8623\n",
      "Epoch 71/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7028 - loss: 0.5453 - val_accuracy: 0.4819 - val_loss: 0.8745\n",
      "Epoch 72/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7048 - loss: 0.5380 - val_accuracy: 0.4839 - val_loss: 0.8722\n",
      "Epoch 73/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6867 - loss: 0.5435 - val_accuracy: 0.4839 - val_loss: 0.8765\n",
      "Epoch 74/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7028 - loss: 0.5371 - val_accuracy: 0.5000 - val_loss: 0.8725\n",
      "Epoch 75/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6988 - loss: 0.5465 - val_accuracy: 0.5161 - val_loss: 0.8823\n",
      "Epoch 76/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6988 - loss: 0.5399 - val_accuracy: 0.4839 - val_loss: 0.8774\n",
      "Epoch 77/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7048 - loss: 0.5394 - val_accuracy: 0.4819 - val_loss: 0.8946\n",
      "Epoch 78/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7088 - loss: 0.5340 - val_accuracy: 0.4799 - val_loss: 0.8982\n",
      "Epoch 79/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7088 - loss: 0.5325 - val_accuracy: 0.4880 - val_loss: 0.8806\n",
      "Epoch 80/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7048 - loss: 0.5316 - val_accuracy: 0.4759 - val_loss: 0.9150\n",
      "Epoch 81/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7209 - loss: 0.5309 - val_accuracy: 0.4920 - val_loss: 0.8959\n",
      "Epoch 82/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7088 - loss: 0.5282 - val_accuracy: 0.4960 - val_loss: 0.9033\n",
      "Epoch 83/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7209 - loss: 0.5236 - val_accuracy: 0.4900 - val_loss: 0.9080\n",
      "Epoch 84/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7088 - loss: 0.5228 - val_accuracy: 0.4839 - val_loss: 0.9027\n",
      "Epoch 85/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7169 - loss: 0.5306 - val_accuracy: 0.4920 - val_loss: 0.9161\n",
      "Epoch 86/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7108 - loss: 0.5290 - val_accuracy: 0.5000 - val_loss: 0.9137\n",
      "Epoch 87/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7189 - loss: 0.5270 - val_accuracy: 0.4859 - val_loss: 0.9111\n",
      "Epoch 88/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7129 - loss: 0.5226 - val_accuracy: 0.4880 - val_loss: 0.9160\n",
      "Epoch 89/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6968 - loss: 0.5242 - val_accuracy: 0.4900 - val_loss: 0.9343\n",
      "Epoch 90/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7209 - loss: 0.5123 - val_accuracy: 0.4940 - val_loss: 0.9248\n",
      "Epoch 91/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7269 - loss: 0.5079 - val_accuracy: 0.4880 - val_loss: 0.9349\n",
      "Epoch 92/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7249 - loss: 0.5080 - val_accuracy: 0.4819 - val_loss: 0.9494\n",
      "Epoch 93/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7169 - loss: 0.5148 - val_accuracy: 0.4819 - val_loss: 0.9354\n",
      "Epoch 94/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7088 - loss: 0.5108 - val_accuracy: 0.4799 - val_loss: 0.9479\n",
      "Epoch 95/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7149 - loss: 0.5054 - val_accuracy: 0.4980 - val_loss: 0.9532\n",
      "Epoch 96/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6948 - loss: 0.5323 - val_accuracy: 0.4960 - val_loss: 0.9354\n",
      "Epoch 97/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7169 - loss: 0.5261 - val_accuracy: 0.4920 - val_loss: 0.9618\n",
      "Epoch 98/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7329 - loss: 0.5088 - val_accuracy: 0.4900 - val_loss: 0.9504\n",
      "Epoch 99/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7289 - loss: 0.5043 - val_accuracy: 0.4859 - val_loss: 0.9756\n",
      "Epoch 100/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7269 - loss: 0.5043 - val_accuracy: 0.4759 - val_loss: 0.9698\n",
      "Epoch 101/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7269 - loss: 0.4977 - val_accuracy: 0.4900 - val_loss: 0.9646\n",
      "Epoch 102/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7349 - loss: 0.5014 - val_accuracy: 0.4659 - val_loss: 0.9791\n",
      "Epoch 103/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7149 - loss: 0.5079 - val_accuracy: 0.4839 - val_loss: 0.9609\n",
      "Epoch 104/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7269 - loss: 0.5122 - val_accuracy: 0.4839 - val_loss: 0.9685\n",
      "Epoch 105/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7309 - loss: 0.5116 - val_accuracy: 0.4739 - val_loss: 0.9765\n",
      "Epoch 106/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7229 - loss: 0.4952 - val_accuracy: 0.4759 - val_loss: 0.9823\n",
      "Epoch 107/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7430 - loss: 0.4879 - val_accuracy: 0.4839 - val_loss: 0.9904\n",
      "Epoch 108/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7369 - loss: 0.4906 - val_accuracy: 0.4699 - val_loss: 0.9945\n",
      "Epoch 109/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7329 - loss: 0.4897 - val_accuracy: 0.4799 - val_loss: 1.0053\n",
      "Epoch 110/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7249 - loss: 0.5011 - val_accuracy: 0.4759 - val_loss: 0.9926\n",
      "Epoch 111/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7209 - loss: 0.5039 - val_accuracy: 0.4639 - val_loss: 0.9938\n",
      "Epoch 112/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7490 - loss: 0.4885 - val_accuracy: 0.4759 - val_loss: 0.9990\n",
      "Epoch 113/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7410 - loss: 0.4863 - val_accuracy: 0.4799 - val_loss: 1.0094\n",
      "Epoch 114/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7349 - loss: 0.4893 - val_accuracy: 0.4960 - val_loss: 0.9966\n",
      "Epoch 115/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7349 - loss: 0.4797 - val_accuracy: 0.4759 - val_loss: 1.0219\n",
      "Epoch 116/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7309 - loss: 0.4840 - val_accuracy: 0.4839 - val_loss: 1.0254\n",
      "Epoch 117/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7249 - loss: 0.5031 - val_accuracy: 0.5000 - val_loss: 1.0014\n",
      "Epoch 118/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7510 - loss: 0.4865 - val_accuracy: 0.4839 - val_loss: 1.0273\n",
      "Epoch 119/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7369 - loss: 0.4894 - val_accuracy: 0.4839 - val_loss: 1.0325\n",
      "Epoch 120/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7450 - loss: 0.4826 - val_accuracy: 0.4799 - val_loss: 1.0466\n",
      "Epoch 121/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7369 - loss: 0.4929 - val_accuracy: 0.4719 - val_loss: 1.0352\n",
      "Epoch 122/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7309 - loss: 0.4959 - val_accuracy: 0.4839 - val_loss: 1.0267\n",
      "Epoch 123/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7430 - loss: 0.4739 - val_accuracy: 0.4859 - val_loss: 1.0355\n",
      "Epoch 124/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7410 - loss: 0.4761 - val_accuracy: 0.4759 - val_loss: 1.0660\n",
      "Epoch 125/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7470 - loss: 0.4755 - val_accuracy: 0.4719 - val_loss: 1.0426\n",
      "Epoch 126/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7490 - loss: 0.4722 - val_accuracy: 0.4819 - val_loss: 1.0389\n",
      "Epoch 127/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7450 - loss: 0.4802 - val_accuracy: 0.4839 - val_loss: 1.0733\n",
      "Epoch 128/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7490 - loss: 0.4776 - val_accuracy: 0.4880 - val_loss: 1.0553\n",
      "Epoch 129/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7369 - loss: 0.4842 - val_accuracy: 0.4859 - val_loss: 1.0379\n",
      "Epoch 130/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7430 - loss: 0.4726 - val_accuracy: 0.4900 - val_loss: 1.0897\n",
      "Epoch 131/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7510 - loss: 0.4918 - val_accuracy: 0.4880 - val_loss: 1.0497\n",
      "Epoch 132/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7329 - loss: 0.4777 - val_accuracy: 0.4839 - val_loss: 1.0542\n",
      "Epoch 133/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7510 - loss: 0.4770 - val_accuracy: 0.4839 - val_loss: 1.0753\n",
      "Epoch 134/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7430 - loss: 0.4834 - val_accuracy: 0.4799 - val_loss: 1.0560\n",
      "Epoch 135/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7510 - loss: 0.4742 - val_accuracy: 0.4719 - val_loss: 1.0632\n",
      "Epoch 136/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7510 - loss: 0.4741 - val_accuracy: 0.4739 - val_loss: 1.0736\n",
      "Epoch 137/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7470 - loss: 0.4674 - val_accuracy: 0.4719 - val_loss: 1.0734\n",
      "Epoch 138/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7570 - loss: 0.4666 - val_accuracy: 0.4839 - val_loss: 1.0793\n",
      "Epoch 139/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7550 - loss: 0.4680 - val_accuracy: 0.4859 - val_loss: 1.0723\n",
      "Epoch 140/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7390 - loss: 0.4856 - val_accuracy: 0.4799 - val_loss: 1.0797\n",
      "Epoch 141/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7550 - loss: 0.4788 - val_accuracy: 0.4839 - val_loss: 1.1084\n",
      "Epoch 142/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7510 - loss: 0.4822 - val_accuracy: 0.4779 - val_loss: 1.0761\n",
      "Epoch 143/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7490 - loss: 0.4757 - val_accuracy: 0.4779 - val_loss: 1.0753\n",
      "Epoch 144/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7570 - loss: 0.4607 - val_accuracy: 0.4739 - val_loss: 1.0918\n",
      "Epoch 145/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7490 - loss: 0.4670 - val_accuracy: 0.4799 - val_loss: 1.0920\n",
      "Epoch 146/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7530 - loss: 0.4676 - val_accuracy: 0.4819 - val_loss: 1.0761\n",
      "Epoch 147/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7510 - loss: 0.4658 - val_accuracy: 0.4819 - val_loss: 1.0989\n",
      "Epoch 148/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7550 - loss: 0.4624 - val_accuracy: 0.4719 - val_loss: 1.1030\n",
      "Epoch 149/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7530 - loss: 0.4571 - val_accuracy: 0.4839 - val_loss: 1.1026\n",
      "Epoch 150/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7470 - loss: 0.4609 - val_accuracy: 0.4699 - val_loss: 1.1187\n",
      "Epoch 151/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7390 - loss: 0.4644 - val_accuracy: 0.4759 - val_loss: 1.1123\n",
      "Epoch 152/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7510 - loss: 0.4627 - val_accuracy: 0.4719 - val_loss: 1.1141\n",
      "Epoch 153/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7651 - loss: 0.4591 - val_accuracy: 0.4759 - val_loss: 1.1221\n",
      "Epoch 154/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7570 - loss: 0.4594 - val_accuracy: 0.4699 - val_loss: 1.1273\n",
      "Epoch 155/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7550 - loss: 0.4642 - val_accuracy: 0.4900 - val_loss: 1.1178\n",
      "Epoch 156/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7570 - loss: 0.4595 - val_accuracy: 0.4759 - val_loss: 1.0933\n",
      "Epoch 157/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7510 - loss: 0.4571 - val_accuracy: 0.4739 - val_loss: 1.1096\n",
      "Epoch 158/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7530 - loss: 0.4631 - val_accuracy: 0.4739 - val_loss: 1.1161\n",
      "Epoch 159/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7430 - loss: 0.4619 - val_accuracy: 0.4859 - val_loss: 1.1327\n",
      "Epoch 160/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7691 - loss: 0.4497 - val_accuracy: 0.4659 - val_loss: 1.1642\n",
      "Epoch 161/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7631 - loss: 0.4583 - val_accuracy: 0.4699 - val_loss: 1.1264\n",
      "Epoch 162/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7550 - loss: 0.4541 - val_accuracy: 0.4719 - val_loss: 1.1150\n",
      "Epoch 163/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7550 - loss: 0.4555 - val_accuracy: 0.4679 - val_loss: 1.1282\n",
      "Epoch 164/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7610 - loss: 0.4592 - val_accuracy: 0.4859 - val_loss: 1.1184\n",
      "Epoch 165/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7590 - loss: 0.4531 - val_accuracy: 0.4779 - val_loss: 1.1550\n",
      "Epoch 166/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7651 - loss: 0.4579 - val_accuracy: 0.4799 - val_loss: 1.1396\n",
      "Epoch 167/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7530 - loss: 0.4611 - val_accuracy: 0.4839 - val_loss: 1.1214\n",
      "Epoch 168/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7450 - loss: 0.4573 - val_accuracy: 0.4759 - val_loss: 1.1584\n",
      "Epoch 169/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7570 - loss: 0.4541 - val_accuracy: 0.4839 - val_loss: 1.1554\n",
      "Epoch 170/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7651 - loss: 0.4495 - val_accuracy: 0.4679 - val_loss: 1.1629\n",
      "Epoch 171/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7590 - loss: 0.4482 - val_accuracy: 0.4779 - val_loss: 1.1526\n",
      "Epoch 172/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7731 - loss: 0.4526 - val_accuracy: 0.4779 - val_loss: 1.1752\n",
      "Epoch 173/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7590 - loss: 0.4442 - val_accuracy: 0.4699 - val_loss: 1.1473\n",
      "Epoch 174/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7691 - loss: 0.4463 - val_accuracy: 0.4759 - val_loss: 1.1966\n",
      "Epoch 175/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7530 - loss: 0.4620 - val_accuracy: 0.4799 - val_loss: 1.1480\n",
      "Epoch 176/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7470 - loss: 0.4593 - val_accuracy: 0.4739 - val_loss: 1.1548\n",
      "Epoch 177/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7651 - loss: 0.4516 - val_accuracy: 0.4679 - val_loss: 1.1733\n",
      "Epoch 178/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7711 - loss: 0.4431 - val_accuracy: 0.4819 - val_loss: 1.1806\n",
      "Epoch 179/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7590 - loss: 0.4538 - val_accuracy: 0.4719 - val_loss: 1.1529\n",
      "Epoch 180/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7651 - loss: 0.4508 - val_accuracy: 0.4719 - val_loss: 1.1741\n",
      "Epoch 181/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7651 - loss: 0.4492 - val_accuracy: 0.4719 - val_loss: 1.1670\n",
      "Epoch 182/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7631 - loss: 0.4532 - val_accuracy: 0.4679 - val_loss: 1.1751\n",
      "Epoch 183/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7711 - loss: 0.4463 - val_accuracy: 0.4719 - val_loss: 1.1957\n",
      "Epoch 184/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7450 - loss: 0.4616 - val_accuracy: 0.4699 - val_loss: 1.1979\n",
      "Epoch 185/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7570 - loss: 0.4536 - val_accuracy: 0.4799 - val_loss: 1.1783\n",
      "Epoch 186/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7671 - loss: 0.4596 - val_accuracy: 0.4819 - val_loss: 1.1978\n",
      "Epoch 187/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7671 - loss: 0.4534 - val_accuracy: 0.4799 - val_loss: 1.2022\n",
      "Epoch 188/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7691 - loss: 0.4546 - val_accuracy: 0.4719 - val_loss: 1.1882\n",
      "Epoch 189/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7590 - loss: 0.4446 - val_accuracy: 0.4739 - val_loss: 1.1807\n",
      "Epoch 190/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7751 - loss: 0.4389 - val_accuracy: 0.4819 - val_loss: 1.2115\n",
      "Epoch 191/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7590 - loss: 0.4405 - val_accuracy: 0.4779 - val_loss: 1.1870\n",
      "Epoch 192/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7651 - loss: 0.4420 - val_accuracy: 0.4719 - val_loss: 1.1892\n",
      "Epoch 193/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7590 - loss: 0.4407 - val_accuracy: 0.4719 - val_loss: 1.1969\n",
      "Epoch 194/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7751 - loss: 0.4351 - val_accuracy: 0.4739 - val_loss: 1.1951\n",
      "Epoch 195/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7731 - loss: 0.4354 - val_accuracy: 0.4900 - val_loss: 1.2155\n",
      "Epoch 196/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7631 - loss: 0.4499 - val_accuracy: 0.4739 - val_loss: 1.1907\n",
      "Epoch 197/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7711 - loss: 0.4421 - val_accuracy: 0.4819 - val_loss: 1.1935\n",
      "Epoch 198/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7711 - loss: 0.4346 - val_accuracy: 0.4679 - val_loss: 1.2056\n",
      "Epoch 199/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7671 - loss: 0.4331 - val_accuracy: 0.4699 - val_loss: 1.2132\n",
      "Epoch 200/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7671 - loss: 0.4392 - val_accuracy: 0.4759 - val_loss: 1.2157\n",
      "Epoch 201/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7610 - loss: 0.4474 - val_accuracy: 0.4819 - val_loss: 1.2202\n",
      "Epoch 202/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7610 - loss: 0.4434 - val_accuracy: 0.4639 - val_loss: 1.2331\n",
      "Epoch 203/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7570 - loss: 0.4499 - val_accuracy: 0.4799 - val_loss: 1.2077\n",
      "Epoch 204/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7550 - loss: 0.4503 - val_accuracy: 0.4699 - val_loss: 1.2189\n",
      "Epoch 205/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7590 - loss: 0.4534 - val_accuracy: 0.4719 - val_loss: 1.2464\n",
      "Epoch 206/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7791 - loss: 0.4382 - val_accuracy: 0.4699 - val_loss: 1.2137\n",
      "Epoch 207/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7631 - loss: 0.4408 - val_accuracy: 0.4779 - val_loss: 1.2019\n",
      "Epoch 208/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7691 - loss: 0.4402 - val_accuracy: 0.4759 - val_loss: 1.2284\n",
      "Epoch 209/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7570 - loss: 0.4342 - val_accuracy: 0.4699 - val_loss: 1.2280\n",
      "Epoch 210/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7651 - loss: 0.4335 - val_accuracy: 0.4739 - val_loss: 1.2196\n",
      "Epoch 211/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7711 - loss: 0.4325 - val_accuracy: 0.4799 - val_loss: 1.2710\n",
      "Epoch 212/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7731 - loss: 0.4285 - val_accuracy: 0.4739 - val_loss: 1.2309\n",
      "Epoch 213/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7691 - loss: 0.4316 - val_accuracy: 0.4659 - val_loss: 1.2887\n",
      "Epoch 214/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7711 - loss: 0.4365 - val_accuracy: 0.4679 - val_loss: 1.2527\n",
      "Epoch 215/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7731 - loss: 0.4340 - val_accuracy: 0.4779 - val_loss: 1.2542\n",
      "Epoch 216/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7711 - loss: 0.4381 - val_accuracy: 0.4618 - val_loss: 1.2367\n",
      "Epoch 217/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7751 - loss: 0.4287 - val_accuracy: 0.4679 - val_loss: 1.2309\n",
      "Epoch 218/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7671 - loss: 0.4340 - val_accuracy: 0.4618 - val_loss: 1.2643\n",
      "Epoch 219/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7671 - loss: 0.4284 - val_accuracy: 0.4719 - val_loss: 1.2408\n",
      "Epoch 220/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7671 - loss: 0.4294 - val_accuracy: 0.4819 - val_loss: 1.2365\n",
      "Epoch 221/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7731 - loss: 0.4319 - val_accuracy: 0.4759 - val_loss: 1.2460\n",
      "Epoch 222/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7631 - loss: 0.4322 - val_accuracy: 0.4699 - val_loss: 1.2747\n",
      "Epoch 223/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7671 - loss: 0.4487 - val_accuracy: 0.4799 - val_loss: 1.2765\n",
      "Epoch 224/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7691 - loss: 0.4411 - val_accuracy: 0.4679 - val_loss: 1.2426\n",
      "Epoch 225/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7731 - loss: 0.4352 - val_accuracy: 0.4819 - val_loss: 1.2736\n",
      "Epoch 226/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7671 - loss: 0.4268 - val_accuracy: 0.4779 - val_loss: 1.2495\n",
      "Epoch 227/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7731 - loss: 0.4257 - val_accuracy: 0.4719 - val_loss: 1.2797\n",
      "Epoch 228/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7711 - loss: 0.4277 - val_accuracy: 0.4779 - val_loss: 1.2621\n",
      "Epoch 229/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7771 - loss: 0.4270 - val_accuracy: 0.4739 - val_loss: 1.2620\n",
      "Epoch 230/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7651 - loss: 0.4373 - val_accuracy: 0.4719 - val_loss: 1.2668\n",
      "Epoch 231/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7791 - loss: 0.4269 - val_accuracy: 0.4719 - val_loss: 1.2784\n",
      "Epoch 232/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7610 - loss: 0.4367 - val_accuracy: 0.4839 - val_loss: 1.2362\n",
      "Epoch 233/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7711 - loss: 0.4312 - val_accuracy: 0.4679 - val_loss: 1.2554\n",
      "Epoch 234/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7711 - loss: 0.4277 - val_accuracy: 0.4759 - val_loss: 1.2821\n",
      "Epoch 235/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7631 - loss: 0.4317 - val_accuracy: 0.4659 - val_loss: 1.2691\n",
      "Epoch 236/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7570 - loss: 0.4370 - val_accuracy: 0.4759 - val_loss: 1.2384\n",
      "Epoch 237/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7691 - loss: 0.4284 - val_accuracy: 0.4618 - val_loss: 1.2921\n",
      "Epoch 238/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7269 - loss: 0.5496 - val_accuracy: 0.4819 - val_loss: 1.2158\n",
      "Epoch 239/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7169 - loss: 0.5417 - val_accuracy: 0.4920 - val_loss: 1.1996\n",
      "Epoch 240/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7229 - loss: 0.5196 - val_accuracy: 0.4639 - val_loss: 1.2541\n",
      "Epoch 241/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7349 - loss: 0.4811 - val_accuracy: 0.4799 - val_loss: 1.2620\n",
      "Epoch 242/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7470 - loss: 0.4669 - val_accuracy: 0.4759 - val_loss: 1.2629\n",
      "Epoch 243/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7470 - loss: 0.4683 - val_accuracy: 0.4819 - val_loss: 1.2768\n",
      "Epoch 244/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7510 - loss: 0.4848 - val_accuracy: 0.4659 - val_loss: 1.2627\n",
      "Epoch 245/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7369 - loss: 0.4763 - val_accuracy: 0.4859 - val_loss: 1.2341\n",
      "Epoch 246/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7430 - loss: 0.4662 - val_accuracy: 0.4819 - val_loss: 1.2495\n",
      "Epoch 247/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7349 - loss: 0.4716 - val_accuracy: 0.4799 - val_loss: 1.2477\n",
      "Epoch 248/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7510 - loss: 0.4643 - val_accuracy: 0.4679 - val_loss: 1.2809\n",
      "Epoch 249/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7610 - loss: 0.4545 - val_accuracy: 0.4859 - val_loss: 1.2443\n",
      "Epoch 250/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7651 - loss: 0.4502 - val_accuracy: 0.4839 - val_loss: 1.2633\n",
      "Epoch 251/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7631 - loss: 0.4457 - val_accuracy: 0.4859 - val_loss: 1.2557\n",
      "Epoch 252/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7691 - loss: 0.4492 - val_accuracy: 0.4799 - val_loss: 1.2484\n",
      "Epoch 253/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7791 - loss: 0.4411 - val_accuracy: 0.4819 - val_loss: 1.2634\n",
      "Epoch 254/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7631 - loss: 0.4516 - val_accuracy: 0.4739 - val_loss: 1.2737\n",
      "Epoch 255/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7610 - loss: 0.4633 - val_accuracy: 0.4859 - val_loss: 1.2166\n",
      "Epoch 256/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7691 - loss: 0.4482 - val_accuracy: 0.4719 - val_loss: 1.2765\n",
      "Epoch 257/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7651 - loss: 0.4495 - val_accuracy: 0.4739 - val_loss: 1.2840\n",
      "Epoch 258/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7751 - loss: 0.4431 - val_accuracy: 0.4799 - val_loss: 1.2768\n",
      "Epoch 259/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7731 - loss: 0.4405 - val_accuracy: 0.4699 - val_loss: 1.2601\n",
      "Epoch 260/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7711 - loss: 0.4442 - val_accuracy: 0.4739 - val_loss: 1.2726\n",
      "Epoch 261/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7791 - loss: 0.4381 - val_accuracy: 0.4779 - val_loss: 1.2798\n",
      "Epoch 262/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7671 - loss: 0.4412 - val_accuracy: 0.4779 - val_loss: 1.2510\n",
      "Epoch 263/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7610 - loss: 0.4549 - val_accuracy: 0.4799 - val_loss: 1.2608\n",
      "Epoch 264/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7731 - loss: 0.4478 - val_accuracy: 0.4679 - val_loss: 1.3031\n",
      "Epoch 265/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7851 - loss: 0.4442 - val_accuracy: 0.4900 - val_loss: 1.2341\n",
      "Epoch 266/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7711 - loss: 0.4362 - val_accuracy: 0.4779 - val_loss: 1.3072\n",
      "Epoch 267/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7751 - loss: 0.4410 - val_accuracy: 0.4719 - val_loss: 1.2885\n",
      "Epoch 268/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7731 - loss: 0.4469 - val_accuracy: 0.4719 - val_loss: 1.2632\n",
      "Epoch 269/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7671 - loss: 0.4384 - val_accuracy: 0.4739 - val_loss: 1.2661\n",
      "Epoch 270/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7791 - loss: 0.4396 - val_accuracy: 0.4799 - val_loss: 1.2801\n",
      "Epoch 271/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7791 - loss: 0.4290 - val_accuracy: 0.4719 - val_loss: 1.2921\n",
      "Epoch 272/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7811 - loss: 0.4253 - val_accuracy: 0.4719 - val_loss: 1.2852\n",
      "Epoch 273/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7831 - loss: 0.4332 - val_accuracy: 0.4839 - val_loss: 1.2886\n",
      "Epoch 274/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7831 - loss: 0.4366 - val_accuracy: 0.4739 - val_loss: 1.2995\n",
      "Epoch 275/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7791 - loss: 0.4296 - val_accuracy: 0.4659 - val_loss: 1.3004\n",
      "Epoch 276/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7871 - loss: 0.4275 - val_accuracy: 0.4799 - val_loss: 1.2740\n",
      "Epoch 277/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7791 - loss: 0.4339 - val_accuracy: 0.4859 - val_loss: 1.2736\n",
      "Epoch 278/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7711 - loss: 0.4435 - val_accuracy: 0.4759 - val_loss: 1.2816\n",
      "Epoch 279/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7851 - loss: 0.4336 - val_accuracy: 0.4719 - val_loss: 1.3127\n",
      "Epoch 280/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7711 - loss: 0.4348 - val_accuracy: 0.4759 - val_loss: 1.2990\n",
      "Epoch 281/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7570 - loss: 0.4816 - val_accuracy: 0.4759 - val_loss: 1.2794\n",
      "Epoch 282/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7751 - loss: 0.4588 - val_accuracy: 0.4558 - val_loss: 1.2877\n",
      "Epoch 283/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7791 - loss: 0.4443 - val_accuracy: 0.4639 - val_loss: 1.2999\n",
      "Epoch 284/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7651 - loss: 0.4381 - val_accuracy: 0.4739 - val_loss: 1.2641\n",
      "Epoch 285/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7811 - loss: 0.4316 - val_accuracy: 0.4739 - val_loss: 1.2985\n",
      "Epoch 286/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7831 - loss: 0.4251 - val_accuracy: 0.4719 - val_loss: 1.3005\n",
      "Epoch 287/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7912 - loss: 0.4272 - val_accuracy: 0.4699 - val_loss: 1.3100\n",
      "Epoch 288/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7892 - loss: 0.4226 - val_accuracy: 0.4739 - val_loss: 1.3152\n",
      "Epoch 289/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7771 - loss: 0.4198 - val_accuracy: 0.4719 - val_loss: 1.3051\n",
      "Epoch 290/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7831 - loss: 0.4415 - val_accuracy: 0.4739 - val_loss: 1.3084\n",
      "Epoch 291/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7871 - loss: 0.4449 - val_accuracy: 0.4719 - val_loss: 1.2990\n",
      "Epoch 292/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7691 - loss: 0.4300 - val_accuracy: 0.4739 - val_loss: 1.3065\n",
      "Epoch 293/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7912 - loss: 0.4270 - val_accuracy: 0.4719 - val_loss: 1.3212\n",
      "Epoch 294/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7731 - loss: 0.4320 - val_accuracy: 0.4799 - val_loss: 1.3136\n",
      "Epoch 295/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7751 - loss: 0.4247 - val_accuracy: 0.4639 - val_loss: 1.3168\n",
      "Epoch 296/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7972 - loss: 0.4185 - val_accuracy: 0.4699 - val_loss: 1.3223\n",
      "Epoch 297/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7731 - loss: 0.4323 - val_accuracy: 0.4679 - val_loss: 1.3126\n",
      "Epoch 298/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7791 - loss: 0.4281 - val_accuracy: 0.4779 - val_loss: 1.3150\n",
      "Epoch 299/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7791 - loss: 0.4272 - val_accuracy: 0.4759 - val_loss: 1.3189\n",
      "Epoch 300/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7711 - loss: 0.4462 - val_accuracy: 0.4779 - val_loss: 1.2839\n",
      "Epoch 301/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7731 - loss: 0.4343 - val_accuracy: 0.4659 - val_loss: 1.3214\n",
      "Epoch 302/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7871 - loss: 0.4178 - val_accuracy: 0.4839 - val_loss: 1.3286\n",
      "Epoch 303/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7811 - loss: 0.4191 - val_accuracy: 0.4739 - val_loss: 1.3236\n",
      "Epoch 304/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7771 - loss: 0.4213 - val_accuracy: 0.4779 - val_loss: 1.3361\n",
      "Epoch 305/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7651 - loss: 0.4368 - val_accuracy: 0.4719 - val_loss: 1.3806\n",
      "Epoch 306/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7550 - loss: 0.4549 - val_accuracy: 0.4719 - val_loss: 1.2863\n",
      "Epoch 307/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7791 - loss: 0.4301 - val_accuracy: 0.4679 - val_loss: 1.3357\n",
      "Epoch 308/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7972 - loss: 0.4160 - val_accuracy: 0.4719 - val_loss: 1.3405\n",
      "Epoch 309/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7952 - loss: 0.4227 - val_accuracy: 0.4739 - val_loss: 1.3079\n",
      "Epoch 310/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7751 - loss: 0.4194 - val_accuracy: 0.4759 - val_loss: 1.3300\n",
      "Epoch 311/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7811 - loss: 0.4285 - val_accuracy: 0.4699 - val_loss: 1.3640\n",
      "Epoch 312/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7892 - loss: 0.4317 - val_accuracy: 0.4839 - val_loss: 1.3113\n",
      "Epoch 313/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7831 - loss: 0.4228 - val_accuracy: 0.4759 - val_loss: 1.3529\n",
      "Epoch 314/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7771 - loss: 0.4309 - val_accuracy: 0.4639 - val_loss: 1.2897\n",
      "Epoch 315/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7831 - loss: 0.4270 - val_accuracy: 0.4779 - val_loss: 1.3433\n",
      "Epoch 316/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7892 - loss: 0.4169 - val_accuracy: 0.4659 - val_loss: 1.3589\n",
      "Epoch 317/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7871 - loss: 0.4163 - val_accuracy: 0.4799 - val_loss: 1.3261\n",
      "Epoch 318/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7892 - loss: 0.4103 - val_accuracy: 0.4739 - val_loss: 1.3400\n",
      "Epoch 319/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7892 - loss: 0.4124 - val_accuracy: 0.4679 - val_loss: 1.3602\n",
      "Epoch 320/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7912 - loss: 0.4180 - val_accuracy: 0.4679 - val_loss: 1.3419\n",
      "Epoch 321/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7751 - loss: 0.4082 - val_accuracy: 0.4739 - val_loss: 1.3307\n",
      "Epoch 322/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7912 - loss: 0.4066 - val_accuracy: 0.4659 - val_loss: 1.3504\n",
      "Epoch 323/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7912 - loss: 0.4066 - val_accuracy: 0.4779 - val_loss: 1.3497\n",
      "Epoch 324/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7771 - loss: 0.4091 - val_accuracy: 0.4679 - val_loss: 1.3506\n",
      "Epoch 325/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7912 - loss: 0.4083 - val_accuracy: 0.4819 - val_loss: 1.3387\n",
      "Epoch 326/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7892 - loss: 0.4067 - val_accuracy: 0.4699 - val_loss: 1.3405\n",
      "Epoch 327/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7952 - loss: 0.4107 - val_accuracy: 0.4779 - val_loss: 1.3656\n",
      "Epoch 328/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7892 - loss: 0.4120 - val_accuracy: 0.4679 - val_loss: 1.3682\n",
      "Epoch 329/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7791 - loss: 0.4117 - val_accuracy: 0.4859 - val_loss: 1.3618\n",
      "Epoch 330/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7871 - loss: 0.4115 - val_accuracy: 0.4779 - val_loss: 1.3556\n",
      "Epoch 331/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7912 - loss: 0.4167 - val_accuracy: 0.4659 - val_loss: 1.3796\n",
      "Epoch 332/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7671 - loss: 0.4604 - val_accuracy: 0.4679 - val_loss: 1.3558\n",
      "Epoch 333/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7731 - loss: 0.4363 - val_accuracy: 0.4538 - val_loss: 1.3601\n",
      "Epoch 334/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7731 - loss: 0.4316 - val_accuracy: 0.4940 - val_loss: 1.3482\n",
      "Epoch 335/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7892 - loss: 0.4074 - val_accuracy: 0.4799 - val_loss: 1.3491\n",
      "Epoch 336/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8052 - loss: 0.4023 - val_accuracy: 0.4719 - val_loss: 1.3717\n",
      "Epoch 337/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7952 - loss: 0.4014 - val_accuracy: 0.4719 - val_loss: 1.3470\n",
      "Epoch 338/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7851 - loss: 0.4331 - val_accuracy: 0.4679 - val_loss: 1.3778\n",
      "Epoch 339/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7952 - loss: 0.4311 - val_accuracy: 0.4679 - val_loss: 1.3607\n",
      "Epoch 340/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7771 - loss: 0.4399 - val_accuracy: 0.4679 - val_loss: 1.3582\n",
      "Epoch 341/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7871 - loss: 0.4230 - val_accuracy: 0.4699 - val_loss: 1.3480\n",
      "Epoch 342/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7932 - loss: 0.4121 - val_accuracy: 0.4679 - val_loss: 1.3467\n",
      "Epoch 343/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7912 - loss: 0.4066 - val_accuracy: 0.4679 - val_loss: 1.3655\n",
      "Epoch 344/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7932 - loss: 0.4099 - val_accuracy: 0.4618 - val_loss: 1.3664\n",
      "Epoch 345/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7932 - loss: 0.4118 - val_accuracy: 0.4578 - val_loss: 1.3445\n",
      "Epoch 346/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7811 - loss: 0.4118 - val_accuracy: 0.4759 - val_loss: 1.3712\n",
      "Epoch 347/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7831 - loss: 0.3997 - val_accuracy: 0.4679 - val_loss: 1.3642\n",
      "Epoch 348/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7932 - loss: 0.4004 - val_accuracy: 0.4639 - val_loss: 1.3628\n",
      "Epoch 349/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8032 - loss: 0.4025 - val_accuracy: 0.4659 - val_loss: 1.3938\n",
      "Epoch 350/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7912 - loss: 0.4023 - val_accuracy: 0.4699 - val_loss: 1.3500\n",
      "Epoch 351/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7932 - loss: 0.4061 - val_accuracy: 0.4779 - val_loss: 1.3715\n",
      "Epoch 352/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8012 - loss: 0.3945 - val_accuracy: 0.4719 - val_loss: 1.3743\n",
      "Epoch 353/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7932 - loss: 0.3988 - val_accuracy: 0.4598 - val_loss: 1.3794\n",
      "Epoch 354/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7952 - loss: 0.4013 - val_accuracy: 0.4799 - val_loss: 1.3679\n",
      "Epoch 355/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7972 - loss: 0.3972 - val_accuracy: 0.4699 - val_loss: 1.3888\n",
      "Epoch 356/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7952 - loss: 0.3971 - val_accuracy: 0.4618 - val_loss: 1.3868\n",
      "Epoch 357/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7992 - loss: 0.3982 - val_accuracy: 0.4659 - val_loss: 1.3763\n",
      "Epoch 358/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7912 - loss: 0.4084 - val_accuracy: 0.4739 - val_loss: 1.3715\n",
      "Epoch 359/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8012 - loss: 0.3981 - val_accuracy: 0.4618 - val_loss: 1.3838\n",
      "Epoch 360/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7972 - loss: 0.4026 - val_accuracy: 0.4739 - val_loss: 1.4048\n",
      "Epoch 361/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7912 - loss: 0.4179 - val_accuracy: 0.4719 - val_loss: 1.3832\n",
      "Epoch 362/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7631 - loss: 0.4282 - val_accuracy: 0.4699 - val_loss: 1.3572\n",
      "Epoch 363/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7791 - loss: 0.4214 - val_accuracy: 0.4940 - val_loss: 1.4308\n",
      "Epoch 364/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7791 - loss: 0.4290 - val_accuracy: 0.4799 - val_loss: 1.4181\n",
      "Epoch 365/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8012 - loss: 0.4063 - val_accuracy: 0.4679 - val_loss: 1.4013\n",
      "Epoch 366/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7992 - loss: 0.4151 - val_accuracy: 0.4759 - val_loss: 1.3970\n",
      "Epoch 367/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7932 - loss: 0.4054 - val_accuracy: 0.4739 - val_loss: 1.3654\n",
      "Epoch 368/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7771 - loss: 0.4099 - val_accuracy: 0.4759 - val_loss: 1.3690\n",
      "Epoch 369/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7751 - loss: 0.4205 - val_accuracy: 0.4779 - val_loss: 1.4091\n",
      "Epoch 370/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7892 - loss: 0.3963 - val_accuracy: 0.4819 - val_loss: 1.3892\n",
      "Epoch 371/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8012 - loss: 0.3977 - val_accuracy: 0.4880 - val_loss: 1.3914\n",
      "Epoch 372/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7831 - loss: 0.4104 - val_accuracy: 0.4779 - val_loss: 1.3887\n",
      "Epoch 373/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7771 - loss: 0.4133 - val_accuracy: 0.4739 - val_loss: 1.3926\n",
      "Epoch 374/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7851 - loss: 0.4019 - val_accuracy: 0.4719 - val_loss: 1.4159\n",
      "Epoch 375/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7992 - loss: 0.3996 - val_accuracy: 0.4699 - val_loss: 1.4236\n",
      "Epoch 376/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7992 - loss: 0.3881 - val_accuracy: 0.4639 - val_loss: 1.4077\n",
      "Epoch 377/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8092 - loss: 0.3907 - val_accuracy: 0.4779 - val_loss: 1.4197\n",
      "Epoch 378/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7892 - loss: 0.4037 - val_accuracy: 0.4699 - val_loss: 1.3834\n",
      "Epoch 379/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7932 - loss: 0.4021 - val_accuracy: 0.4618 - val_loss: 1.4087\n",
      "Epoch 380/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7631 - loss: 0.4157 - val_accuracy: 0.4859 - val_loss: 1.3662\n",
      "Epoch 381/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7932 - loss: 0.4097 - val_accuracy: 0.4699 - val_loss: 1.4301\n",
      "Epoch 382/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8032 - loss: 0.4026 - val_accuracy: 0.4659 - val_loss: 1.3791\n",
      "Epoch 383/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7851 - loss: 0.4294 - val_accuracy: 0.4679 - val_loss: 1.4650\n",
      "Epoch 384/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7831 - loss: 0.4268 - val_accuracy: 0.4719 - val_loss: 1.3801\n",
      "Epoch 385/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7691 - loss: 0.4233 - val_accuracy: 0.4759 - val_loss: 1.3619\n",
      "Epoch 386/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7831 - loss: 0.4084 - val_accuracy: 0.4719 - val_loss: 1.3816\n",
      "Epoch 387/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7892 - loss: 0.3960 - val_accuracy: 0.4659 - val_loss: 1.3968\n",
      "Epoch 388/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7952 - loss: 0.3965 - val_accuracy: 0.4719 - val_loss: 1.4014\n",
      "Epoch 389/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7831 - loss: 0.4089 - val_accuracy: 0.4739 - val_loss: 1.3814\n",
      "Epoch 390/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7932 - loss: 0.3949 - val_accuracy: 0.4799 - val_loss: 1.3834\n",
      "Epoch 391/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7871 - loss: 0.3919 - val_accuracy: 0.4779 - val_loss: 1.4011\n",
      "Epoch 392/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8012 - loss: 0.3993 - val_accuracy: 0.4639 - val_loss: 1.3918\n",
      "Epoch 393/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7932 - loss: 0.3992 - val_accuracy: 0.4739 - val_loss: 1.4090\n",
      "Epoch 394/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7369 - loss: 0.5982 - val_accuracy: 0.4859 - val_loss: 1.5371\n",
      "Epoch 395/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7410 - loss: 0.5274 - val_accuracy: 0.4679 - val_loss: 1.4507\n",
      "Epoch 396/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7430 - loss: 0.4998 - val_accuracy: 0.4719 - val_loss: 1.3975\n",
      "Epoch 397/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7590 - loss: 0.4683 - val_accuracy: 0.4759 - val_loss: 1.4021\n",
      "Epoch 398/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7751 - loss: 0.4277 - val_accuracy: 0.4819 - val_loss: 1.3625\n",
      "Epoch 399/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7871 - loss: 0.4017 - val_accuracy: 0.4739 - val_loss: 1.3801\n",
      "Epoch 400/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7972 - loss: 0.3980 - val_accuracy: 0.4699 - val_loss: 1.3717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x123fad880>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filename = 'np_lin_c_100.csv'\n",
    "#filename1 = 'np_circ_c_100.csv'\n",
    "\n",
    "# train the LSTM\n",
    "\n",
    "batch_x_train = []\n",
    "batch_y_train = []\n",
    "\n",
    "df_1 = pd.read_csv('np_lin_300.csv')\n",
    "\n",
    "for index, rows in df_1.iterrows():\n",
    "    batch_y_train.append(0)\n",
    "    list_1 = rows\n",
    "    batch_x_train.append(list_1)\n",
    "    \n",
    "df_2 = pd.read_csv('np_circ_300.csv')            \n",
    "\n",
    "for index, rows in df_2.iterrows():\n",
    "    batch_y_train.append(1)\n",
    "    list_2 = rows\n",
    "    batch_x_train.append(list_2)\n",
    "\n",
    "#batch_x_train = tf.keras.utils.to_categorical(batch_x_train) #turn this into a tensor not categorical\n",
    "batch_x_train = tf.convert_to_tensor(batch_x_train, dtype=tf.float32) \n",
    "#batch_x_train = np.asarray(batch_x_train, dtype=object)\n",
    "batch_y_train = tf.keras.utils.to_categorical(batch_y_train, num_classes=2)\n",
    "batch_y_test = batch_y_train\n",
    "\n",
    "batch_x_test = []\n",
    "\n",
    "df_3 = pd.read_csv('np_t_lin_300.csv')\n",
    "\n",
    "for index, rows in df_3.iterrows():\n",
    "    list_3 = rows\n",
    "    batch_x_test.append(list_3)\n",
    "    \n",
    "df_4 = pd.read_csv('np_t_circ_300.csv')\n",
    "for index, rows in df_4.iterrows():\n",
    "    list_4 = rows\n",
    "    batch_x_test.append(list_4)\n",
    "    \n",
    "batch_x_test = tf.convert_to_tensor(batch_x_test, dtype=tf.float32)\n",
    "\n",
    "lr = 1e-2\n",
    "num_nodes = 6\n",
    "num_classes = 2\n",
    "num_epochs = 400\n",
    "timesteps = 71\n",
    "tf.keras.backend.clear_session()\n",
    "X = tf.keras.Input(name='X', shape=[batch_x_train.shape[1],1], dtype=tf.dtypes.float32)\n",
    "lstm_output = tf.keras.layers.LSTM(num_nodes)(X)\n",
    "prediction = tf.keras.layers.Dense(num_classes)(lstm_output)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "model = keras.Model(inputs=X, outputs=prediction)\n",
    "model.compile(optimizer=opt, loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "model.fit(x=batch_x_train, y=batch_y_train, epochs=num_epochs, validation_data=(batch_x_test,batch_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e749e39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x_val = []\n",
    "df_3 = pd.read_csv('np_lin_400.csv')\n",
    "for index, rows in df_3.iterrows():\n",
    "    list_3 = rows\n",
    "    batch_x_val.append(list_3)\n",
    "    \n",
    "df_4 = pd.read_csv('np_circ_400.csv')\n",
    "for index, rows in df_4.iterrows():\n",
    "    list_4 = rows\n",
    "    batch_x_val.append(list_4)\n",
    "    \n",
    "batch_x_val = tf.convert_to_tensor(batch_x_val, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c94795c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = model.predict(batch_x_val)\n",
    "y_prediction = np.argmax(y_prediction, axis=1)\n",
    "y_test = np.argmax(batch_y_train, axis=1)\n",
    "result = tf.math.confusion_matrix(y_test, y_prediction, num_classes=2, weights=None)\n",
    "labels = [\"linear\", \"circular\"]\n",
    "cm = confusion_matrix(y_test, y_prediction)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38e242d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"linear\", \"circular\"]\n",
    "cm = confusion_matrix(y_test, y_prediction)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb91b421",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x_train_2 = []\n",
    "batch_y_train_2 = []\n",
    "\n",
    "df_3 = pd.read_csv('big_boi_s_1.csv', nrows=498)\n",
    "\n",
    "for index, rows in df_3.iterrows():\n",
    "    list_3 = rows\n",
    "    batch_x_train_2.append(list_3)\n",
    "    \n",
    "#batch_x_train = tf.keras.utils.to_categorical(batch_x_train) #turn this into a tensor not categorical\n",
    "batch_x_train_2 = tf.convert_to_tensor(batch_x_train_2, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5240dce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = model.predict(batch_x_train_2)\n",
    "y_prediction = np.argmax (y_prediction, axis =1)\n",
    "y_test = np.argmax(batch_y_train, axis=1)\n",
    "result = tf.math.confusion_matrix(y_test, y_prediction, num_classes=2, weights=None)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b697ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = y_prediction\n",
    "res2 = res1.reshape(1,498)\n",
    "results = np.concatenate((batch_x_train_2, res2.T), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f680bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"big_boi_1_t.csv\", results,\n",
    "              delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69f6cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('NP_LSTM.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b252ca16",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x_train = []\n",
    "batch_y_train = []\n",
    "\n",
    "df_1 = pd.read_csv('np_lin_100.csv')\n",
    "#df_1 = df_1.drop('101', axis=1)\n",
    "#lst_0 = [0]*100\n",
    "#lst_1 = [1]*100\n",
    "\n",
    "for index, rows in df_1.iterrows():\n",
    "    batch_y_train.append(0)\n",
    "    list_1 = rows\n",
    "    batch_x_train.append(list_1)\n",
    "    \n",
    "df_2 = pd.read_csv('np_circ_100.csv')            \n",
    "\n",
    "for index, rows in df_2.iterrows():\n",
    "    batch_y_train.append(1)\n",
    "    list_2 = rows\n",
    "    batch_x_train.append(list_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49981fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_x_train = tf.keras.utils.to_categorical(batch_x_train) #turn this into a tensor not categorical\n",
    "batch_x_train = tf.convert_to_tensor(batch_x_train, dtype=tf.float32) \n",
    "#batch_x_train = np.asarray(batch_x_train, dtype=object)\n",
    "batch_y_train = tf.keras.utils.to_categorical(batch_y_train, num_classes=2)\n",
    "batch_y_test = batch_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9b8594",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
