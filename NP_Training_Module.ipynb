{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "553bd2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as pl\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.optimize as spo\n",
    "import pandas as pd\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a38a478",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myEnv/lib/python3.12/site-packages/tensorflow/python/framework/constant_op.py:108: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return ops.EagerTensor(value, ctx.device_name, dtype)\n",
      "/opt/anaconda3/envs/myEnv/lib/python3.12/site-packages/tensorflow/python/framework/constant_op.py:108: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return ops.EagerTensor(value, ctx.device_name, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4699 - loss: 0.7200 - val_accuracy: 0.5422 - val_loss: 0.6943\n",
      "Epoch 2/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4960 - loss: 0.6980 - val_accuracy: 0.4960 - val_loss: 0.6960\n",
      "Epoch 3/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5321 - loss: 0.6923 - val_accuracy: 0.4799 - val_loss: 0.7045\n",
      "Epoch 4/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5060 - loss: 0.6924 - val_accuracy: 0.4578 - val_loss: 0.7005\n",
      "Epoch 5/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5161 - loss: 0.6911 - val_accuracy: 0.4980 - val_loss: 0.6986\n",
      "Epoch 6/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5442 - loss: 0.6879 - val_accuracy: 0.4779 - val_loss: 0.7016\n",
      "Epoch 7/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5382 - loss: 0.6867 - val_accuracy: 0.5020 - val_loss: 0.7025\n",
      "Epoch 8/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5522 - loss: 0.6822 - val_accuracy: 0.4880 - val_loss: 0.7073\n",
      "Epoch 9/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5281 - loss: 0.6802 - val_accuracy: 0.4859 - val_loss: 0.7088\n",
      "Epoch 10/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5643 - loss: 0.6785 - val_accuracy: 0.4940 - val_loss: 0.7090\n",
      "Epoch 11/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5683 - loss: 0.6770 - val_accuracy: 0.4960 - val_loss: 0.7104\n",
      "Epoch 12/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5622 - loss: 0.6745 - val_accuracy: 0.4920 - val_loss: 0.7152\n",
      "Epoch 13/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5763 - loss: 0.6706 - val_accuracy: 0.4819 - val_loss: 0.7194\n",
      "Epoch 14/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5703 - loss: 0.6663 - val_accuracy: 0.4920 - val_loss: 0.7231\n",
      "Epoch 15/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5743 - loss: 0.6655 - val_accuracy: 0.4859 - val_loss: 0.7242\n",
      "Epoch 16/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5622 - loss: 0.6677 - val_accuracy: 0.4759 - val_loss: 0.7253\n",
      "Epoch 17/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5803 - loss: 0.6624 - val_accuracy: 0.4799 - val_loss: 0.7265\n",
      "Epoch 18/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5904 - loss: 0.6558 - val_accuracy: 0.4719 - val_loss: 0.7336\n",
      "Epoch 19/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5723 - loss: 0.6553 - val_accuracy: 0.4819 - val_loss: 0.7370\n",
      "Epoch 20/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5743 - loss: 0.6506 - val_accuracy: 0.4779 - val_loss: 0.7377\n",
      "Epoch 21/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5743 - loss: 0.6506 - val_accuracy: 0.4639 - val_loss: 0.7413\n",
      "Epoch 22/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6004 - loss: 0.6553 - val_accuracy: 0.4699 - val_loss: 0.7508\n",
      "Epoch 23/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5924 - loss: 0.6542 - val_accuracy: 0.4900 - val_loss: 0.7375\n",
      "Epoch 24/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6165 - loss: 0.6421 - val_accuracy: 0.4618 - val_loss: 0.7450\n",
      "Epoch 25/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5904 - loss: 0.6404 - val_accuracy: 0.4839 - val_loss: 0.7498\n",
      "Epoch 26/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6245 - loss: 0.6317 - val_accuracy: 0.4779 - val_loss: 0.7549\n",
      "Epoch 27/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6265 - loss: 0.6337 - val_accuracy: 0.4598 - val_loss: 0.7514\n",
      "Epoch 28/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6606 - loss: 0.6238 - val_accuracy: 0.4598 - val_loss: 0.7704\n",
      "Epoch 29/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6466 - loss: 0.6245 - val_accuracy: 0.4739 - val_loss: 0.7700\n",
      "Epoch 30/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6506 - loss: 0.6196 - val_accuracy: 0.4699 - val_loss: 0.7748\n",
      "Epoch 31/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6606 - loss: 0.6118 - val_accuracy: 0.4779 - val_loss: 0.7774\n",
      "Epoch 32/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6627 - loss: 0.6046 - val_accuracy: 0.4759 - val_loss: 0.7934\n",
      "Epoch 33/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6586 - loss: 0.5995 - val_accuracy: 0.4618 - val_loss: 0.8085\n",
      "Epoch 34/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6647 - loss: 0.6122 - val_accuracy: 0.4880 - val_loss: 0.7918\n",
      "Epoch 35/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6807 - loss: 0.6035 - val_accuracy: 0.4699 - val_loss: 0.8137\n",
      "Epoch 36/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6687 - loss: 0.6084 - val_accuracy: 0.4839 - val_loss: 0.7914\n",
      "Epoch 37/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6606 - loss: 0.6102 - val_accuracy: 0.5000 - val_loss: 0.7860\n",
      "Epoch 38/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6787 - loss: 0.5915 - val_accuracy: 0.4458 - val_loss: 0.8209\n",
      "Epoch 39/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6847 - loss: 0.5860 - val_accuracy: 0.4859 - val_loss: 0.8166\n",
      "Epoch 40/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6847 - loss: 0.5825 - val_accuracy: 0.4980 - val_loss: 0.8444\n",
      "Epoch 41/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7028 - loss: 0.5813 - val_accuracy: 0.4839 - val_loss: 0.8098\n",
      "Epoch 42/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6867 - loss: 0.5891 - val_accuracy: 0.4739 - val_loss: 0.8411\n",
      "Epoch 43/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6908 - loss: 0.5725 - val_accuracy: 0.4779 - val_loss: 0.8470\n",
      "Epoch 44/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6867 - loss: 0.5791 - val_accuracy: 0.4880 - val_loss: 0.8348\n",
      "Epoch 45/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7169 - loss: 0.5697 - val_accuracy: 0.4859 - val_loss: 0.8676\n",
      "Epoch 46/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6968 - loss: 0.5747 - val_accuracy: 0.4920 - val_loss: 0.8432\n",
      "Epoch 47/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7129 - loss: 0.5692 - val_accuracy: 0.4859 - val_loss: 0.8554\n",
      "Epoch 48/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7048 - loss: 0.5601 - val_accuracy: 0.4900 - val_loss: 0.8920\n",
      "Epoch 49/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7048 - loss: 0.5553 - val_accuracy: 0.4960 - val_loss: 0.8708\n",
      "Epoch 50/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7229 - loss: 0.5509 - val_accuracy: 0.4880 - val_loss: 0.8984\n",
      "Epoch 51/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7068 - loss: 0.5524 - val_accuracy: 0.4920 - val_loss: 0.8900\n",
      "Epoch 52/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7169 - loss: 0.5511 - val_accuracy: 0.5000 - val_loss: 0.8903\n",
      "Epoch 53/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7309 - loss: 0.5449 - val_accuracy: 0.4578 - val_loss: 0.9337\n",
      "Epoch 54/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7028 - loss: 0.5570 - val_accuracy: 0.4920 - val_loss: 0.8839\n",
      "Epoch 55/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6807 - loss: 0.5803 - val_accuracy: 0.4839 - val_loss: 0.8483\n",
      "Epoch 56/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7269 - loss: 0.5492 - val_accuracy: 0.4960 - val_loss: 0.9038\n",
      "Epoch 57/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7349 - loss: 0.5421 - val_accuracy: 0.4900 - val_loss: 0.9173\n",
      "Epoch 58/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7149 - loss: 0.5402 - val_accuracy: 0.4859 - val_loss: 0.9051\n",
      "Epoch 59/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7209 - loss: 0.5494 - val_accuracy: 0.4880 - val_loss: 0.8977\n",
      "Epoch 60/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7289 - loss: 0.5310 - val_accuracy: 0.4880 - val_loss: 0.9164\n",
      "Epoch 61/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7048 - loss: 0.5547 - val_accuracy: 0.4659 - val_loss: 0.9073\n",
      "Epoch 62/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7269 - loss: 0.5466 - val_accuracy: 0.4859 - val_loss: 0.9298\n",
      "Epoch 63/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7309 - loss: 0.5286 - val_accuracy: 0.4900 - val_loss: 0.9157\n",
      "Epoch 64/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7229 - loss: 0.5312 - val_accuracy: 0.4859 - val_loss: 0.9881\n",
      "Epoch 65/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6767 - loss: 0.6032 - val_accuracy: 0.4859 - val_loss: 0.9289\n",
      "Epoch 66/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7068 - loss: 0.5599 - val_accuracy: 0.4880 - val_loss: 0.9379\n",
      "Epoch 67/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7008 - loss: 0.5523 - val_accuracy: 0.4799 - val_loss: 0.8882\n",
      "Epoch 68/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7149 - loss: 0.5414 - val_accuracy: 0.4839 - val_loss: 0.9054\n",
      "Epoch 69/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7530 - loss: 0.5296 - val_accuracy: 0.4859 - val_loss: 0.9165\n",
      "Epoch 70/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7390 - loss: 0.5245 - val_accuracy: 0.4739 - val_loss: 0.9265\n",
      "Epoch 71/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7349 - loss: 0.5247 - val_accuracy: 0.4920 - val_loss: 0.9288\n",
      "Epoch 72/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7430 - loss: 0.5106 - val_accuracy: 0.4779 - val_loss: 0.9622\n",
      "Epoch 73/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7470 - loss: 0.5154 - val_accuracy: 0.4699 - val_loss: 0.9491\n",
      "Epoch 74/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7470 - loss: 0.5048 - val_accuracy: 0.4679 - val_loss: 0.9740\n",
      "Epoch 75/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7329 - loss: 0.5125 - val_accuracy: 0.4699 - val_loss: 0.9515\n",
      "Epoch 76/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6867 - loss: 0.5735 - val_accuracy: 0.4799 - val_loss: 0.9342\n",
      "Epoch 77/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7108 - loss: 0.5383 - val_accuracy: 0.4699 - val_loss: 0.9247\n",
      "Epoch 78/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7329 - loss: 0.5308 - val_accuracy: 0.4498 - val_loss: 0.9733\n",
      "Epoch 79/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7450 - loss: 0.5102 - val_accuracy: 0.4839 - val_loss: 0.9572\n",
      "Epoch 80/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7590 - loss: 0.5013 - val_accuracy: 0.4799 - val_loss: 0.9821\n",
      "Epoch 81/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7369 - loss: 0.5070 - val_accuracy: 0.4759 - val_loss: 0.9563\n",
      "Epoch 82/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7450 - loss: 0.5074 - val_accuracy: 0.4940 - val_loss: 0.9717\n",
      "Epoch 83/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7550 - loss: 0.5030 - val_accuracy: 0.4719 - val_loss: 0.9963\n",
      "Epoch 84/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7410 - loss: 0.5073 - val_accuracy: 0.4719 - val_loss: 0.9599\n",
      "Epoch 85/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7550 - loss: 0.5028 - val_accuracy: 0.4779 - val_loss: 1.0160\n",
      "Epoch 86/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7590 - loss: 0.4981 - val_accuracy: 0.4699 - val_loss: 1.0302\n",
      "Epoch 87/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7450 - loss: 0.5052 - val_accuracy: 0.4839 - val_loss: 1.0143\n",
      "Epoch 88/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7289 - loss: 0.5098 - val_accuracy: 0.4819 - val_loss: 0.9653\n",
      "Epoch 89/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7229 - loss: 0.5341 - val_accuracy: 0.4538 - val_loss: 0.9711\n",
      "Epoch 90/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7008 - loss: 0.5636 - val_accuracy: 0.4799 - val_loss: 0.9700\n",
      "Epoch 91/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6867 - loss: 0.5703 - val_accuracy: 0.4578 - val_loss: 0.9640\n",
      "Epoch 92/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7088 - loss: 0.5513 - val_accuracy: 0.4799 - val_loss: 0.9141\n",
      "Epoch 93/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7169 - loss: 0.5418 - val_accuracy: 0.4659 - val_loss: 0.9664\n",
      "Epoch 94/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7309 - loss: 0.5102 - val_accuracy: 0.4759 - val_loss: 0.9715\n",
      "Epoch 95/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7510 - loss: 0.4925 - val_accuracy: 0.4799 - val_loss: 1.0068\n",
      "Epoch 96/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7570 - loss: 0.4891 - val_accuracy: 0.4699 - val_loss: 1.0081\n",
      "Epoch 97/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7631 - loss: 0.4842 - val_accuracy: 0.4779 - val_loss: 1.0335\n",
      "Epoch 98/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7550 - loss: 0.4832 - val_accuracy: 0.4719 - val_loss: 1.0268\n",
      "Epoch 99/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7490 - loss: 0.4905 - val_accuracy: 0.4779 - val_loss: 1.0085\n",
      "Epoch 100/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7530 - loss: 0.4827 - val_accuracy: 0.4799 - val_loss: 1.0481\n",
      "Epoch 101/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7430 - loss: 0.4898 - val_accuracy: 0.4940 - val_loss: 1.0040\n",
      "Epoch 102/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.4815 - val_accuracy: 0.4759 - val_loss: 1.0366\n",
      "Epoch 103/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7771 - loss: 0.4784 - val_accuracy: 0.4699 - val_loss: 1.0720\n",
      "Epoch 104/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7610 - loss: 0.4799 - val_accuracy: 0.4880 - val_loss: 1.0708\n",
      "Epoch 105/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7651 - loss: 0.4855 - val_accuracy: 0.4679 - val_loss: 1.0427\n",
      "Epoch 106/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7671 - loss: 0.4819 - val_accuracy: 0.4639 - val_loss: 1.0576\n",
      "Epoch 107/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7530 - loss: 0.4888 - val_accuracy: 0.4859 - val_loss: 1.0516\n",
      "Epoch 108/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7651 - loss: 0.4736 - val_accuracy: 0.4699 - val_loss: 1.1139\n",
      "Epoch 109/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7410 - loss: 0.4990 - val_accuracy: 0.4578 - val_loss: 1.0399\n",
      "Epoch 110/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7249 - loss: 0.5175 - val_accuracy: 0.4679 - val_loss: 1.0556\n",
      "Epoch 111/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7550 - loss: 0.4863 - val_accuracy: 0.4819 - val_loss: 1.0472\n",
      "Epoch 112/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7631 - loss: 0.4761 - val_accuracy: 0.4598 - val_loss: 1.0713\n",
      "Epoch 113/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7610 - loss: 0.4717 - val_accuracy: 0.4759 - val_loss: 1.0657\n",
      "Epoch 114/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7631 - loss: 0.4698 - val_accuracy: 0.4659 - val_loss: 1.0876\n",
      "Epoch 115/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7691 - loss: 0.4734 - val_accuracy: 0.4779 - val_loss: 1.0459\n",
      "Epoch 116/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7711 - loss: 0.4768 - val_accuracy: 0.4659 - val_loss: 1.0933\n",
      "Epoch 117/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7590 - loss: 0.4728 - val_accuracy: 0.4900 - val_loss: 1.0628\n",
      "Epoch 118/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7631 - loss: 0.4730 - val_accuracy: 0.4819 - val_loss: 1.0777\n",
      "Epoch 119/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7209 - loss: 0.5246 - val_accuracy: 0.4699 - val_loss: 1.0939\n",
      "Epoch 120/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7149 - loss: 0.5483 - val_accuracy: 0.4839 - val_loss: 0.9861\n",
      "Epoch 121/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7329 - loss: 0.5169 - val_accuracy: 0.4859 - val_loss: 1.0164\n",
      "Epoch 122/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7209 - loss: 0.4992 - val_accuracy: 0.4618 - val_loss: 1.0945\n",
      "Epoch 123/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7309 - loss: 0.5088 - val_accuracy: 0.4478 - val_loss: 1.0766\n",
      "Epoch 124/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7068 - loss: 0.5562 - val_accuracy: 0.4779 - val_loss: 0.9762\n",
      "Epoch 125/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7048 - loss: 0.5436 - val_accuracy: 0.4940 - val_loss: 0.9659\n",
      "Epoch 126/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7430 - loss: 0.5013 - val_accuracy: 0.4839 - val_loss: 1.0055\n",
      "Epoch 127/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7450 - loss: 0.4856 - val_accuracy: 0.4659 - val_loss: 1.0625\n",
      "Epoch 128/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7771 - loss: 0.4648 - val_accuracy: 0.4900 - val_loss: 1.0637\n",
      "Epoch 129/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7671 - loss: 0.4612 - val_accuracy: 0.4900 - val_loss: 1.1026\n",
      "Epoch 130/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7751 - loss: 0.4531 - val_accuracy: 0.4759 - val_loss: 1.1047\n",
      "Epoch 131/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7450 - loss: 0.5364 - val_accuracy: 0.4759 - val_loss: 1.1364\n",
      "Epoch 132/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6667 - loss: 0.5738 - val_accuracy: 0.4799 - val_loss: 1.0162\n",
      "Epoch 133/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7349 - loss: 0.5003 - val_accuracy: 0.4859 - val_loss: 1.0196\n",
      "Epoch 134/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7570 - loss: 0.4763 - val_accuracy: 0.4558 - val_loss: 1.0487\n",
      "Epoch 135/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7711 - loss: 0.4785 - val_accuracy: 0.4659 - val_loss: 1.0353\n",
      "Epoch 136/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7570 - loss: 0.4944 - val_accuracy: 0.4438 - val_loss: 1.0723\n",
      "Epoch 137/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7711 - loss: 0.4682 - val_accuracy: 0.4598 - val_loss: 1.0887\n",
      "Epoch 138/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7831 - loss: 0.4601 - val_accuracy: 0.4759 - val_loss: 1.1016\n",
      "Epoch 139/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7791 - loss: 0.4555 - val_accuracy: 0.4779 - val_loss: 1.0705\n",
      "Epoch 140/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7871 - loss: 0.4457 - val_accuracy: 0.4779 - val_loss: 1.1319\n",
      "Epoch 141/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7711 - loss: 0.4505 - val_accuracy: 0.4739 - val_loss: 1.1430\n",
      "Epoch 142/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7932 - loss: 0.4462 - val_accuracy: 0.4719 - val_loss: 1.1061\n",
      "Epoch 143/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7831 - loss: 0.4561 - val_accuracy: 0.4779 - val_loss: 1.0710\n",
      "Epoch 144/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7771 - loss: 0.4617 - val_accuracy: 0.4779 - val_loss: 1.0742\n",
      "Epoch 145/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7892 - loss: 0.4563 - val_accuracy: 0.4719 - val_loss: 1.1201\n",
      "Epoch 146/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7892 - loss: 0.4495 - val_accuracy: 0.4759 - val_loss: 1.1067\n",
      "Epoch 147/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7992 - loss: 0.4436 - val_accuracy: 0.4699 - val_loss: 1.1423\n",
      "Epoch 148/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7972 - loss: 0.4374 - val_accuracy: 0.4699 - val_loss: 1.1650\n",
      "Epoch 149/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8032 - loss: 0.4349 - val_accuracy: 0.4639 - val_loss: 1.1696\n",
      "Epoch 150/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8072 - loss: 0.4423 - val_accuracy: 0.4759 - val_loss: 1.1030\n",
      "Epoch 151/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7992 - loss: 0.4322 - val_accuracy: 0.4639 - val_loss: 1.2013\n",
      "Epoch 152/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7831 - loss: 0.4403 - val_accuracy: 0.4759 - val_loss: 1.1405\n",
      "Epoch 153/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8092 - loss: 0.4378 - val_accuracy: 0.4659 - val_loss: 1.1654\n",
      "Epoch 154/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7972 - loss: 0.4357 - val_accuracy: 0.4618 - val_loss: 1.1595\n",
      "Epoch 155/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7791 - loss: 0.4402 - val_accuracy: 0.4659 - val_loss: 1.1848\n",
      "Epoch 156/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7972 - loss: 0.4309 - val_accuracy: 0.4699 - val_loss: 1.2045\n",
      "Epoch 157/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8012 - loss: 0.4271 - val_accuracy: 0.4799 - val_loss: 1.2012\n",
      "Epoch 158/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7992 - loss: 0.4271 - val_accuracy: 0.4719 - val_loss: 1.2012\n",
      "Epoch 159/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7932 - loss: 0.4499 - val_accuracy: 0.4639 - val_loss: 1.1926\n",
      "Epoch 160/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7671 - loss: 0.4898 - val_accuracy: 0.4598 - val_loss: 1.1551\n",
      "Epoch 161/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7811 - loss: 0.4757 - val_accuracy: 0.4739 - val_loss: 1.1108\n",
      "Epoch 162/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.4961 - val_accuracy: 0.4859 - val_loss: 1.1269\n",
      "Epoch 163/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7610 - loss: 0.4801 - val_accuracy: 0.4799 - val_loss: 1.1420\n",
      "Epoch 164/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7751 - loss: 0.4564 - val_accuracy: 0.5080 - val_loss: 1.0907\n",
      "Epoch 165/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7952 - loss: 0.4515 - val_accuracy: 0.4839 - val_loss: 1.1020\n",
      "Epoch 166/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7590 - loss: 0.4617 - val_accuracy: 0.4739 - val_loss: 1.0772\n",
      "Epoch 167/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7490 - loss: 0.5258 - val_accuracy: 0.4799 - val_loss: 1.0310\n",
      "Epoch 168/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7410 - loss: 0.5055 - val_accuracy: 0.4799 - val_loss: 1.0749\n",
      "Epoch 169/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7510 - loss: 0.4813 - val_accuracy: 0.4759 - val_loss: 1.1056\n",
      "Epoch 170/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7610 - loss: 0.4784 - val_accuracy: 0.4639 - val_loss: 1.1427\n",
      "Epoch 171/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7510 - loss: 0.4853 - val_accuracy: 0.4819 - val_loss: 1.1224\n",
      "Epoch 172/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7631 - loss: 0.4750 - val_accuracy: 0.4719 - val_loss: 1.1190\n",
      "Epoch 173/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7209 - loss: 0.5454 - val_accuracy: 0.4819 - val_loss: 1.0683\n",
      "Epoch 174/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7390 - loss: 0.5177 - val_accuracy: 0.4920 - val_loss: 0.9860\n",
      "Epoch 175/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7410 - loss: 0.5046 - val_accuracy: 0.4719 - val_loss: 1.0601\n",
      "Epoch 176/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7711 - loss: 0.4813 - val_accuracy: 0.4739 - val_loss: 1.0513\n",
      "Epoch 177/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7610 - loss: 0.4683 - val_accuracy: 0.4739 - val_loss: 1.0939\n",
      "Epoch 178/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7550 - loss: 0.4804 - val_accuracy: 0.4799 - val_loss: 1.0798\n",
      "Epoch 179/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7369 - loss: 0.4794 - val_accuracy: 0.4699 - val_loss: 1.0700\n",
      "Epoch 180/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7851 - loss: 0.4569 - val_accuracy: 0.4819 - val_loss: 1.0714\n",
      "Epoch 181/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7851 - loss: 0.4454 - val_accuracy: 0.4880 - val_loss: 1.1025\n",
      "Epoch 182/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7892 - loss: 0.4441 - val_accuracy: 0.4839 - val_loss: 1.1098\n",
      "Epoch 183/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7912 - loss: 0.4365 - val_accuracy: 0.4779 - val_loss: 1.1147\n",
      "Epoch 184/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7831 - loss: 0.4405 - val_accuracy: 0.4880 - val_loss: 1.1314\n",
      "Epoch 185/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7711 - loss: 0.4453 - val_accuracy: 0.4859 - val_loss: 1.1305\n",
      "Epoch 186/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7851 - loss: 0.4290 - val_accuracy: 0.4759 - val_loss: 1.1386\n",
      "Epoch 187/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7972 - loss: 0.4230 - val_accuracy: 0.4739 - val_loss: 1.1854\n",
      "Epoch 188/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8012 - loss: 0.4157 - val_accuracy: 0.4659 - val_loss: 1.2171\n",
      "Epoch 189/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8032 - loss: 0.4137 - val_accuracy: 0.4639 - val_loss: 1.1831\n",
      "Epoch 190/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7952 - loss: 0.4228 - val_accuracy: 0.4719 - val_loss: 1.1689\n",
      "Epoch 191/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7731 - loss: 0.4606 - val_accuracy: 0.4799 - val_loss: 1.2042\n",
      "Epoch 192/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7871 - loss: 0.4316 - val_accuracy: 0.4659 - val_loss: 1.1457\n",
      "Epoch 193/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7851 - loss: 0.4322 - val_accuracy: 0.4719 - val_loss: 1.1742\n",
      "Epoch 194/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7711 - loss: 0.4618 - val_accuracy: 0.4819 - val_loss: 1.1835\n",
      "Epoch 195/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7570 - loss: 0.4941 - val_accuracy: 0.4618 - val_loss: 1.1482\n",
      "Epoch 196/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7309 - loss: 0.5114 - val_accuracy: 0.4880 - val_loss: 1.0930\n",
      "Epoch 197/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7369 - loss: 0.5428 - val_accuracy: 0.4819 - val_loss: 1.1628\n",
      "Epoch 198/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7390 - loss: 0.5052 - val_accuracy: 0.4779 - val_loss: 1.1154\n",
      "Epoch 199/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7771 - loss: 0.4546 - val_accuracy: 0.4679 - val_loss: 1.1168\n",
      "Epoch 200/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7771 - loss: 0.4404 - val_accuracy: 0.4639 - val_loss: 1.1497\n",
      "Epoch 201/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7831 - loss: 0.4349 - val_accuracy: 0.4679 - val_loss: 1.2038\n",
      "Epoch 202/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7671 - loss: 0.4754 - val_accuracy: 0.4819 - val_loss: 1.1821\n",
      "Epoch 203/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7811 - loss: 0.4461 - val_accuracy: 0.4759 - val_loss: 1.1855\n",
      "Epoch 204/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7851 - loss: 0.4467 - val_accuracy: 0.4819 - val_loss: 1.1366\n",
      "Epoch 205/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7871 - loss: 0.4323 - val_accuracy: 0.4739 - val_loss: 1.1707\n",
      "Epoch 206/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7771 - loss: 0.4393 - val_accuracy: 0.4719 - val_loss: 1.1646\n",
      "Epoch 207/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7932 - loss: 0.4262 - val_accuracy: 0.4779 - val_loss: 1.1913\n",
      "Epoch 208/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7811 - loss: 0.4385 - val_accuracy: 0.4859 - val_loss: 1.1758\n",
      "Epoch 209/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7791 - loss: 0.4284 - val_accuracy: 0.4819 - val_loss: 1.1693\n",
      "Epoch 210/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7972 - loss: 0.4157 - val_accuracy: 0.4779 - val_loss: 1.2038\n",
      "Epoch 211/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8012 - loss: 0.4133 - val_accuracy: 0.4759 - val_loss: 1.2376\n",
      "Epoch 212/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7992 - loss: 0.4120 - val_accuracy: 0.4799 - val_loss: 1.2340\n",
      "Epoch 213/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8032 - loss: 0.4133 - val_accuracy: 0.4759 - val_loss: 1.2219\n",
      "Epoch 214/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7992 - loss: 0.4278 - val_accuracy: 0.4759 - val_loss: 1.2510\n",
      "Epoch 215/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7791 - loss: 0.4278 - val_accuracy: 0.4799 - val_loss: 1.2157\n",
      "Epoch 216/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7811 - loss: 0.4305 - val_accuracy: 0.4639 - val_loss: 1.2644\n",
      "Epoch 217/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8052 - loss: 0.4143 - val_accuracy: 0.4719 - val_loss: 1.2139\n",
      "Epoch 218/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7892 - loss: 0.4266 - val_accuracy: 0.4699 - val_loss: 1.2554\n",
      "Epoch 219/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8092 - loss: 0.4082 - val_accuracy: 0.4679 - val_loss: 1.2629\n",
      "Epoch 220/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8092 - loss: 0.4096 - val_accuracy: 0.4558 - val_loss: 1.3070\n",
      "Epoch 221/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8032 - loss: 0.4023 - val_accuracy: 0.4598 - val_loss: 1.2723\n",
      "Epoch 222/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8133 - loss: 0.4041 - val_accuracy: 0.4659 - val_loss: 1.3005\n",
      "Epoch 223/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8072 - loss: 0.4069 - val_accuracy: 0.4699 - val_loss: 1.2809\n",
      "Epoch 224/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7972 - loss: 0.4168 - val_accuracy: 0.4819 - val_loss: 1.2607\n",
      "Epoch 225/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8012 - loss: 0.4148 - val_accuracy: 0.4739 - val_loss: 1.2470\n",
      "Epoch 226/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7932 - loss: 0.4138 - val_accuracy: 0.4699 - val_loss: 1.3043\n",
      "Epoch 227/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8012 - loss: 0.4048 - val_accuracy: 0.4699 - val_loss: 1.3004\n",
      "Epoch 228/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8012 - loss: 0.4023 - val_accuracy: 0.4618 - val_loss: 1.3173\n",
      "Epoch 229/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8092 - loss: 0.3993 - val_accuracy: 0.4639 - val_loss: 1.3353\n",
      "Epoch 230/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8153 - loss: 0.3971 - val_accuracy: 0.4639 - val_loss: 1.3392\n",
      "Epoch 231/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8153 - loss: 0.3960 - val_accuracy: 0.4659 - val_loss: 1.3379\n",
      "Epoch 232/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8153 - loss: 0.3980 - val_accuracy: 0.4659 - val_loss: 1.3376\n",
      "Epoch 233/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7731 - loss: 0.4431 - val_accuracy: 0.4618 - val_loss: 1.2811\n",
      "Epoch 234/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7892 - loss: 0.4611 - val_accuracy: 0.4799 - val_loss: 1.2842\n",
      "Epoch 235/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7912 - loss: 0.4427 - val_accuracy: 0.4719 - val_loss: 1.2310\n",
      "Epoch 236/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7912 - loss: 0.4186 - val_accuracy: 0.4558 - val_loss: 1.3052\n",
      "Epoch 237/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7691 - loss: 0.4905 - val_accuracy: 0.4859 - val_loss: 1.1805\n",
      "Epoch 238/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7369 - loss: 0.4972 - val_accuracy: 0.4719 - val_loss: 1.1492\n",
      "Epoch 239/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7510 - loss: 0.4972 - val_accuracy: 0.4759 - val_loss: 1.2060\n",
      "Epoch 240/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7691 - loss: 0.4607 - val_accuracy: 0.4759 - val_loss: 1.2611\n",
      "Epoch 241/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7811 - loss: 0.4296 - val_accuracy: 0.4759 - val_loss: 1.2703\n",
      "Epoch 242/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7952 - loss: 0.4182 - val_accuracy: 0.4639 - val_loss: 1.3391\n",
      "Epoch 243/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8112 - loss: 0.4069 - val_accuracy: 0.4679 - val_loss: 1.3266\n",
      "Epoch 244/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8092 - loss: 0.4008 - val_accuracy: 0.4518 - val_loss: 1.3393\n",
      "Epoch 245/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8072 - loss: 0.3974 - val_accuracy: 0.4438 - val_loss: 1.3432\n",
      "Epoch 246/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8153 - loss: 0.3967 - val_accuracy: 0.4699 - val_loss: 1.3296\n",
      "Epoch 247/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8213 - loss: 0.3962 - val_accuracy: 0.4618 - val_loss: 1.3729\n",
      "Epoch 248/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8213 - loss: 0.3945 - val_accuracy: 0.4699 - val_loss: 1.3221\n",
      "Epoch 249/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8092 - loss: 0.3940 - val_accuracy: 0.4558 - val_loss: 1.3858\n",
      "Epoch 250/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7892 - loss: 0.4363 - val_accuracy: 0.4900 - val_loss: 1.2453\n",
      "Epoch 251/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8012 - loss: 0.4153 - val_accuracy: 0.4618 - val_loss: 1.3710\n",
      "Epoch 252/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8112 - loss: 0.4038 - val_accuracy: 0.4739 - val_loss: 1.3500\n",
      "Epoch 253/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8012 - loss: 0.4160 - val_accuracy: 0.4438 - val_loss: 1.5323\n",
      "Epoch 254/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7871 - loss: 0.4580 - val_accuracy: 0.4578 - val_loss: 1.4855\n",
      "Epoch 255/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7671 - loss: 0.4956 - val_accuracy: 0.4779 - val_loss: 1.3715\n",
      "Epoch 256/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7871 - loss: 0.4238 - val_accuracy: 0.4679 - val_loss: 1.4009\n",
      "Epoch 257/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7731 - loss: 0.4624 - val_accuracy: 0.4659 - val_loss: 1.3516\n",
      "Epoch 258/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7952 - loss: 0.4140 - val_accuracy: 0.4679 - val_loss: 1.4138\n",
      "Epoch 259/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7610 - loss: 0.4934 - val_accuracy: 0.4920 - val_loss: 1.2735\n",
      "Epoch 260/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7390 - loss: 0.5042 - val_accuracy: 0.4819 - val_loss: 1.2895\n",
      "Epoch 261/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7711 - loss: 0.4666 - val_accuracy: 0.4578 - val_loss: 1.2582\n",
      "Epoch 262/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7530 - loss: 0.4972 - val_accuracy: 0.4699 - val_loss: 1.3142\n",
      "Epoch 263/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7791 - loss: 0.4574 - val_accuracy: 0.4819 - val_loss: 1.2315\n",
      "Epoch 264/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7851 - loss: 0.4193 - val_accuracy: 0.4759 - val_loss: 1.3308\n",
      "Epoch 265/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7952 - loss: 0.4134 - val_accuracy: 0.4759 - val_loss: 1.3239\n",
      "Epoch 266/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8032 - loss: 0.4056 - val_accuracy: 0.4679 - val_loss: 1.3633\n",
      "Epoch 267/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7932 - loss: 0.4118 - val_accuracy: 0.4699 - val_loss: 1.4507\n",
      "Epoch 268/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7932 - loss: 0.4152 - val_accuracy: 0.4799 - val_loss: 1.2777\n",
      "Epoch 269/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7892 - loss: 0.4217 - val_accuracy: 0.4759 - val_loss: 1.3019\n",
      "Epoch 270/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8032 - loss: 0.4055 - val_accuracy: 0.4659 - val_loss: 1.4006\n",
      "Epoch 271/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8052 - loss: 0.3950 - val_accuracy: 0.4679 - val_loss: 1.3524\n",
      "Epoch 272/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7691 - loss: 0.4476 - val_accuracy: 0.4759 - val_loss: 1.3692\n",
      "Epoch 273/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7751 - loss: 0.4460 - val_accuracy: 0.4659 - val_loss: 1.2909\n",
      "Epoch 274/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7972 - loss: 0.4236 - val_accuracy: 0.4618 - val_loss: 1.3082\n",
      "Epoch 275/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8092 - loss: 0.4065 - val_accuracy: 0.4699 - val_loss: 1.4328\n",
      "Epoch 276/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7992 - loss: 0.4170 - val_accuracy: 0.4699 - val_loss: 1.4299\n",
      "Epoch 277/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7771 - loss: 0.4444 - val_accuracy: 0.4598 - val_loss: 1.3358\n",
      "Epoch 278/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8012 - loss: 0.4203 - val_accuracy: 0.4538 - val_loss: 1.3561\n",
      "Epoch 279/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8072 - loss: 0.4160 - val_accuracy: 0.4578 - val_loss: 1.3648\n",
      "Epoch 280/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8032 - loss: 0.4047 - val_accuracy: 0.4679 - val_loss: 1.3701\n",
      "Epoch 281/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8213 - loss: 0.3951 - val_accuracy: 0.4639 - val_loss: 1.3765\n",
      "Epoch 282/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8032 - loss: 0.4174 - val_accuracy: 0.4478 - val_loss: 1.4050\n",
      "Epoch 283/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7952 - loss: 0.4482 - val_accuracy: 0.4639 - val_loss: 1.4098\n",
      "Epoch 284/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7410 - loss: 0.5739 - val_accuracy: 0.5060 - val_loss: 1.3465\n",
      "Epoch 285/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7450 - loss: 0.5867 - val_accuracy: 0.4699 - val_loss: 1.2186\n",
      "Epoch 286/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7229 - loss: 0.5492 - val_accuracy: 0.4799 - val_loss: 1.1674\n",
      "Epoch 287/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7430 - loss: 0.4864 - val_accuracy: 0.5060 - val_loss: 1.1049\n",
      "Epoch 288/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7610 - loss: 0.4645 - val_accuracy: 0.4880 - val_loss: 1.1725\n",
      "Epoch 289/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7831 - loss: 0.4500 - val_accuracy: 0.4739 - val_loss: 1.2180\n",
      "Epoch 290/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7651 - loss: 0.4366 - val_accuracy: 0.4739 - val_loss: 1.2342\n",
      "Epoch 291/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7811 - loss: 0.4245 - val_accuracy: 0.4659 - val_loss: 1.2574\n",
      "Epoch 292/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7831 - loss: 0.4378 - val_accuracy: 0.4598 - val_loss: 1.3040\n",
      "Epoch 293/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7651 - loss: 0.4776 - val_accuracy: 0.4779 - val_loss: 1.2480\n",
      "Epoch 294/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7892 - loss: 0.4218 - val_accuracy: 0.4699 - val_loss: 1.3251\n",
      "Epoch 295/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6365 - loss: 1.1194 - val_accuracy: 0.5201 - val_loss: 1.5766\n",
      "Epoch 296/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5924 - loss: 1.2128 - val_accuracy: 0.5120 - val_loss: 1.4545\n",
      "Epoch 297/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5622 - loss: 1.1439 - val_accuracy: 0.4940 - val_loss: 1.2639\n",
      "Epoch 298/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5622 - loss: 0.9804 - val_accuracy: 0.5020 - val_loss: 1.0993\n",
      "Epoch 299/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5763 - loss: 0.8267 - val_accuracy: 0.4859 - val_loss: 1.0061\n",
      "Epoch 300/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5783 - loss: 0.7733 - val_accuracy: 0.4880 - val_loss: 0.9442\n",
      "Epoch 301/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5843 - loss: 0.7092 - val_accuracy: 0.4779 - val_loss: 0.9366\n",
      "Epoch 302/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5904 - loss: 0.6910 - val_accuracy: 0.4759 - val_loss: 0.9145\n",
      "Epoch 303/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5924 - loss: 0.6737 - val_accuracy: 0.4759 - val_loss: 0.8999\n",
      "Epoch 304/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6044 - loss: 0.6589 - val_accuracy: 0.4659 - val_loss: 0.8960\n",
      "Epoch 305/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6225 - loss: 0.6516 - val_accuracy: 0.4679 - val_loss: 0.8817\n",
      "Epoch 306/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6024 - loss: 0.6524 - val_accuracy: 0.4659 - val_loss: 0.8766\n",
      "Epoch 307/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6084 - loss: 0.6446 - val_accuracy: 0.4799 - val_loss: 0.8642\n",
      "Epoch 308/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6024 - loss: 0.6452 - val_accuracy: 0.4759 - val_loss: 0.8617\n",
      "Epoch 309/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5964 - loss: 0.6481 - val_accuracy: 0.4839 - val_loss: 0.8567\n",
      "Epoch 310/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5803 - loss: 0.6795 - val_accuracy: 0.4859 - val_loss: 0.8454\n",
      "Epoch 311/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5763 - loss: 0.6791 - val_accuracy: 0.4759 - val_loss: 0.8327\n",
      "Epoch 312/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5884 - loss: 0.6653 - val_accuracy: 0.4699 - val_loss: 0.8218\n",
      "Epoch 313/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6145 - loss: 0.6560 - val_accuracy: 0.4639 - val_loss: 0.8222\n",
      "Epoch 314/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5944 - loss: 0.6482 - val_accuracy: 0.4679 - val_loss: 0.8128\n",
      "Epoch 315/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5783 - loss: 0.6565 - val_accuracy: 0.4699 - val_loss: 0.7948\n",
      "Epoch 316/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5803 - loss: 0.6549 - val_accuracy: 0.4799 - val_loss: 0.7943\n",
      "Epoch 317/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5884 - loss: 0.6471 - val_accuracy: 0.4839 - val_loss: 0.7883\n",
      "Epoch 318/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6124 - loss: 0.6405 - val_accuracy: 0.4960 - val_loss: 0.7888\n",
      "Epoch 319/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6024 - loss: 0.6388 - val_accuracy: 0.4739 - val_loss: 0.7911\n",
      "Epoch 320/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5803 - loss: 0.6419 - val_accuracy: 0.4598 - val_loss: 0.7865\n",
      "Epoch 321/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5884 - loss: 0.6388 - val_accuracy: 0.4839 - val_loss: 0.7888\n",
      "Epoch 322/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6084 - loss: 0.6374 - val_accuracy: 0.4819 - val_loss: 0.7906\n",
      "Epoch 323/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5803 - loss: 0.6349 - val_accuracy: 0.4679 - val_loss: 0.7916\n",
      "Epoch 324/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5944 - loss: 0.6380 - val_accuracy: 0.4558 - val_loss: 0.7891\n",
      "Epoch 325/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6064 - loss: 0.6379 - val_accuracy: 0.4699 - val_loss: 0.7877\n",
      "Epoch 326/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6084 - loss: 0.6368 - val_accuracy: 0.4779 - val_loss: 0.7876\n",
      "Epoch 327/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6205 - loss: 0.6320 - val_accuracy: 0.4679 - val_loss: 0.7846\n",
      "Epoch 328/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5984 - loss: 0.6315 - val_accuracy: 0.4759 - val_loss: 0.7887\n",
      "Epoch 329/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6205 - loss: 0.6256 - val_accuracy: 0.4719 - val_loss: 0.7888\n",
      "Epoch 330/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6265 - loss: 0.6243 - val_accuracy: 0.4679 - val_loss: 0.7936\n",
      "Epoch 331/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6345 - loss: 0.6178 - val_accuracy: 0.4779 - val_loss: 0.7953\n",
      "Epoch 332/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6345 - loss: 0.6162 - val_accuracy: 0.4920 - val_loss: 0.7917\n",
      "Epoch 333/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6486 - loss: 0.6151 - val_accuracy: 0.4980 - val_loss: 0.7846\n",
      "Epoch 334/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6365 - loss: 0.6201 - val_accuracy: 0.4859 - val_loss: 0.7829\n",
      "Epoch 335/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6245 - loss: 0.6216 - val_accuracy: 0.4940 - val_loss: 0.7827\n",
      "Epoch 336/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6426 - loss: 0.6167 - val_accuracy: 0.4759 - val_loss: 0.7866\n",
      "Epoch 337/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6345 - loss: 0.6117 - val_accuracy: 0.5060 - val_loss: 0.7888\n",
      "Epoch 338/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6406 - loss: 0.6105 - val_accuracy: 0.4960 - val_loss: 0.7919\n",
      "Epoch 339/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6245 - loss: 0.6150 - val_accuracy: 0.4900 - val_loss: 0.7915\n",
      "Epoch 340/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6185 - loss: 0.6205 - val_accuracy: 0.4980 - val_loss: 0.7946\n",
      "Epoch 341/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6245 - loss: 0.6159 - val_accuracy: 0.4900 - val_loss: 0.8032\n",
      "Epoch 342/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6345 - loss: 0.6122 - val_accuracy: 0.4900 - val_loss: 0.8016\n",
      "Epoch 343/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6185 - loss: 0.6155 - val_accuracy: 0.4900 - val_loss: 0.7905\n",
      "Epoch 344/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6325 - loss: 0.6102 - val_accuracy: 0.4900 - val_loss: 0.7907\n",
      "Epoch 345/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6325 - loss: 0.6210 - val_accuracy: 0.4659 - val_loss: 0.7888\n",
      "Epoch 346/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6265 - loss: 0.6167 - val_accuracy: 0.4799 - val_loss: 0.7890\n",
      "Epoch 347/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6225 - loss: 0.6087 - val_accuracy: 0.4880 - val_loss: 0.7898\n",
      "Epoch 348/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6325 - loss: 0.6074 - val_accuracy: 0.4839 - val_loss: 0.7930\n",
      "Epoch 349/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6305 - loss: 0.6026 - val_accuracy: 0.4618 - val_loss: 0.8045\n",
      "Epoch 350/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6406 - loss: 0.6030 - val_accuracy: 0.4880 - val_loss: 0.8142\n",
      "Epoch 351/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6486 - loss: 0.5993 - val_accuracy: 0.4719 - val_loss: 0.8102\n",
      "Epoch 352/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6506 - loss: 0.6021 - val_accuracy: 0.4739 - val_loss: 0.8138\n",
      "Epoch 353/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6426 - loss: 0.6265 - val_accuracy: 0.4940 - val_loss: 0.7910\n",
      "Epoch 354/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6185 - loss: 0.6344 - val_accuracy: 0.4980 - val_loss: 0.7838\n",
      "Epoch 355/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6104 - loss: 0.6264 - val_accuracy: 0.5040 - val_loss: 0.7908\n",
      "Epoch 356/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6145 - loss: 0.6204 - val_accuracy: 0.5080 - val_loss: 0.7889\n",
      "Epoch 357/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6044 - loss: 0.6393 - val_accuracy: 0.5201 - val_loss: 0.7906\n",
      "Epoch 358/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6325 - loss: 0.6279 - val_accuracy: 0.4940 - val_loss: 0.7744\n",
      "Epoch 359/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6285 - loss: 0.6245 - val_accuracy: 0.5141 - val_loss: 0.7739\n",
      "Epoch 360/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6345 - loss: 0.6186 - val_accuracy: 0.5181 - val_loss: 0.7748\n",
      "Epoch 361/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6285 - loss: 0.6142 - val_accuracy: 0.5120 - val_loss: 0.7763\n",
      "Epoch 362/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6506 - loss: 0.6118 - val_accuracy: 0.5141 - val_loss: 0.7761\n",
      "Epoch 363/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6466 - loss: 0.6066 - val_accuracy: 0.5161 - val_loss: 0.7783\n",
      "Epoch 364/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6285 - loss: 0.6050 - val_accuracy: 0.5040 - val_loss: 0.7818\n",
      "Epoch 365/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6446 - loss: 0.6056 - val_accuracy: 0.5141 - val_loss: 0.7845\n",
      "Epoch 366/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6586 - loss: 0.6008 - val_accuracy: 0.5040 - val_loss: 0.7761\n",
      "Epoch 367/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5964 - loss: 0.6441 - val_accuracy: 0.5120 - val_loss: 0.7668\n",
      "Epoch 368/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6024 - loss: 0.6366 - val_accuracy: 0.5301 - val_loss: 0.7718\n",
      "Epoch 369/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5843 - loss: 0.6216 - val_accuracy: 0.5261 - val_loss: 0.7846\n",
      "Epoch 370/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6124 - loss: 0.6116 - val_accuracy: 0.5161 - val_loss: 0.7889\n",
      "Epoch 371/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5984 - loss: 0.6192 - val_accuracy: 0.4920 - val_loss: 0.7959\n",
      "Epoch 372/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5904 - loss: 0.6255 - val_accuracy: 0.4799 - val_loss: 0.7950\n",
      "Epoch 373/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6064 - loss: 0.6112 - val_accuracy: 0.4960 - val_loss: 0.8008\n",
      "Epoch 374/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6104 - loss: 0.6076 - val_accuracy: 0.4960 - val_loss: 0.8034\n",
      "Epoch 375/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6325 - loss: 0.6037 - val_accuracy: 0.4839 - val_loss: 0.7912\n",
      "Epoch 376/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5944 - loss: 0.6030 - val_accuracy: 0.4699 - val_loss: 0.7912\n",
      "Epoch 377/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6245 - loss: 0.6007 - val_accuracy: 0.4859 - val_loss: 0.7922\n",
      "Epoch 378/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6265 - loss: 0.6003 - val_accuracy: 0.5040 - val_loss: 0.7948\n",
      "Epoch 379/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6365 - loss: 0.5972 - val_accuracy: 0.4839 - val_loss: 0.7986\n",
      "Epoch 380/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6285 - loss: 0.5952 - val_accuracy: 0.4839 - val_loss: 0.7991\n",
      "Epoch 381/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6205 - loss: 0.5946 - val_accuracy: 0.4699 - val_loss: 0.8062\n",
      "Epoch 382/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6225 - loss: 0.5966 - val_accuracy: 0.4779 - val_loss: 0.8023\n",
      "Epoch 383/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6044 - loss: 0.5974 - val_accuracy: 0.4940 - val_loss: 0.8156\n",
      "Epoch 384/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6225 - loss: 0.6060 - val_accuracy: 0.4839 - val_loss: 0.8118\n",
      "Epoch 385/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6124 - loss: 0.6154 - val_accuracy: 0.4839 - val_loss: 0.7954\n",
      "Epoch 386/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6024 - loss: 0.6278 - val_accuracy: 0.5000 - val_loss: 0.8032\n",
      "Epoch 387/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5884 - loss: 0.6284 - val_accuracy: 0.4980 - val_loss: 0.7977\n",
      "Epoch 388/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6084 - loss: 0.6155 - val_accuracy: 0.4880 - val_loss: 0.7965\n",
      "Epoch 389/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6365 - loss: 0.6097 - val_accuracy: 0.4759 - val_loss: 0.8043\n",
      "Epoch 390/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6225 - loss: 0.6304 - val_accuracy: 0.4779 - val_loss: 0.8169\n",
      "Epoch 391/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6145 - loss: 0.6201 - val_accuracy: 0.4839 - val_loss: 0.8122\n",
      "Epoch 392/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6305 - loss: 0.5912 - val_accuracy: 0.5000 - val_loss: 0.8050\n",
      "Epoch 393/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6446 - loss: 0.5976 - val_accuracy: 0.5040 - val_loss: 0.8006\n",
      "Epoch 394/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6084 - loss: 0.6390 - val_accuracy: 0.5060 - val_loss: 0.8059\n",
      "Epoch 395/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6145 - loss: 0.6355 - val_accuracy: 0.5060 - val_loss: 0.7956\n",
      "Epoch 396/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6104 - loss: 0.6213 - val_accuracy: 0.5060 - val_loss: 0.8078\n",
      "Epoch 397/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6044 - loss: 0.6286 - val_accuracy: 0.4940 - val_loss: 0.8164\n",
      "Epoch 398/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5924 - loss: 0.6714 - val_accuracy: 0.5120 - val_loss: 0.8240\n",
      "Epoch 399/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6024 - loss: 0.6734 - val_accuracy: 0.5161 - val_loss: 0.7724\n",
      "Epoch 400/400\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6265 - loss: 0.6263 - val_accuracy: 0.5040 - val_loss: 0.7822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x303589760>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filename = 'np_lin_c_100.csv'\n",
    "#filename1 = 'np_circ_c_100.csv'\n",
    "\n",
    "# train the LSTM\n",
    "\n",
    "batch_x_train = []\n",
    "batch_y_train = []\n",
    "\n",
    "df_1 = pd.read_csv('np_lin_100.csv')\n",
    "\n",
    "for index, rows in df_1.iterrows():\n",
    "    batch_y_train.append(0)\n",
    "    list_1 = rows\n",
    "    batch_x_train.append(list_1)\n",
    "    \n",
    "df_2 = pd.read_csv('np_circ_100.csv')            \n",
    "\n",
    "for index, rows in df_2.iterrows():\n",
    "    batch_y_train.append(1)\n",
    "    list_2 = rows\n",
    "    batch_x_train.append(list_2)\n",
    "\n",
    "#batch_x_train = tf.keras.utils.to_categorical(batch_x_train) #turn this into a tensor not categorical\n",
    "batch_x_train = tf.convert_to_tensor(batch_x_train, dtype=tf.float32) \n",
    "#batch_x_train = np.asarray(batch_x_train, dtype=object)\n",
    "batch_y_train = tf.keras.utils.to_categorical(batch_y_train, num_classes=2)\n",
    "batch_y_test = batch_y_train\n",
    "\n",
    "batch_x_test = []\n",
    "\n",
    "df_3 = pd.read_csv('np_t_lin_100.csv')\n",
    "\n",
    "for index, rows in df_3.iterrows():\n",
    "    list_3 = rows\n",
    "    batch_x_test.append(list_3)\n",
    "    \n",
    "df_4 = pd.read_csv('np_t_circ_100.csv')\n",
    "for index, rows in df_4.iterrows():\n",
    "    list_4 = rows\n",
    "    batch_x_test.append(list_4)\n",
    "    \n",
    "batch_x_test = tf.convert_to_tensor(batch_x_test, dtype=tf.float32)\n",
    "\n",
    "lr = 1e-2\n",
    "num_nodes = 6\n",
    "num_classes = 2\n",
    "num_epochs = 400\n",
    "timesteps = 71\n",
    "tf.keras.backend.clear_session()\n",
    "X = tf.keras.Input(name='X', shape=[batch_x_train.shape[1],1], dtype=tf.dtypes.float32)\n",
    "lstm_output = tf.keras.layers.LSTM(num_nodes)(X)\n",
    "prediction = tf.keras.layers.Dense(num_classes)(lstm_output)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "model = keras.Model(inputs=X, outputs=prediction)\n",
    "model.compile(optimizer=opt, loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "model.fit(x=batch_x_train, y=batch_y_train, epochs=num_epochs, validation_data=(batch_x_test,batch_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e749e39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x_val = []\n",
    "df_3 = pd.read_csv('np_lin_400.csv')\n",
    "for index, rows in df_3.iterrows():\n",
    "    list_3 = rows\n",
    "    batch_x_val.append(list_3)\n",
    "    \n",
    "df_4 = pd.read_csv('np_circ_400.csv')\n",
    "for index, rows in df_4.iterrows():\n",
    "    list_4 = rows\n",
    "    batch_x_val.append(list_4)\n",
    "    \n",
    "batch_x_val = tf.convert_to_tensor(batch_x_val, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c94795c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = model.predict(batch_x_val)\n",
    "y_prediction = np.argmax(y_prediction, axis=1)\n",
    "y_test = np.argmax(batch_y_train, axis=1)\n",
    "result = tf.math.confusion_matrix(y_test, y_prediction, num_classes=2, weights=None)\n",
    "labels = [\"linear\", \"circular\"]\n",
    "cm = confusion_matrix(y_test, y_prediction)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38e242d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"linear\", \"circular\"]\n",
    "cm = confusion_matrix(y_test, y_prediction)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb91b421",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x_train_2 = []\n",
    "batch_y_train_2 = []\n",
    "\n",
    "df_3 = pd.read_csv('big_boi_s_1.csv', nrows=498)\n",
    "\n",
    "for index, rows in df_3.iterrows():\n",
    "    list_3 = rows\n",
    "    batch_x_train_2.append(list_3)\n",
    "    \n",
    "#batch_x_train = tf.keras.utils.to_categorical(batch_x_train) #turn this into a tensor not categorical\n",
    "batch_x_train_2 = tf.convert_to_tensor(batch_x_train_2, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5240dce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = model.predict(batch_x_train_2)\n",
    "y_prediction = np.argmax (y_prediction, axis =1)\n",
    "y_test = np.argmax(batch_y_train, axis=1)\n",
    "result = tf.math.confusion_matrix(y_test, y_prediction, num_classes=2, weights=None)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b697ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = y_prediction\n",
    "res2 = res1.reshape(1,498)\n",
    "results = np.concatenate((batch_x_train_2, res2.T), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78f680bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"big_boi_1_t.csv\", results,\n",
    "              delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69f6cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('NP_LSTM.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b252ca16",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x_train = []\n",
    "batch_y_train = []\n",
    "\n",
    "df_1 = pd.read_csv('np_lin_100.csv')\n",
    "#df_1 = df_1.drop('101', axis=1)\n",
    "#lst_0 = [0]*100\n",
    "#lst_1 = [1]*100\n",
    "\n",
    "for index, rows in df_1.iterrows():\n",
    "    batch_y_train.append(0)\n",
    "    list_1 = rows\n",
    "    batch_x_train.append(list_1)\n",
    "    \n",
    "df_2 = pd.read_csv('np_circ_100.csv')            \n",
    "\n",
    "for index, rows in df_2.iterrows():\n",
    "    batch_y_train.append(1)\n",
    "    list_2 = rows\n",
    "    batch_x_train.append(list_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49981fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_x_train = tf.keras.utils.to_categorical(batch_x_train) #turn this into a tensor not categorical\n",
    "batch_x_train = tf.convert_to_tensor(batch_x_train, dtype=tf.float32) \n",
    "#batch_x_train = np.asarray(batch_x_train, dtype=object)\n",
    "batch_y_train = tf.keras.utils.to_categorical(batch_y_train, num_classes=2)\n",
    "batch_y_test = batch_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9b8594",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
