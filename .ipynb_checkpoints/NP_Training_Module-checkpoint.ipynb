{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553bd2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as pl\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.optimize as spo\n",
    "import pandas as pd\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a38a478",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#filename = 'np_lin_100.csv'\n",
    "#filename1 = 'np_circ_100.csv'\n",
    "\n",
    "#train the LSTM\n",
    "\n",
    "#begin by setting up two batches for training data\n",
    "batch_x_train = []\n",
    "batch_y_train = []\n",
    "\n",
    "#half of the x training data is linear\n",
    "#a 'zero' corresponds to linear\n",
    "df_1 = pd.read_csv('np_lin_100.csv')\n",
    "\n",
    "for index, rows in df_1.iterrows():\n",
    "    batch_y_train.append(0)\n",
    "    list_1 = rows\n",
    "    batch_x_train.append(list_1)\n",
    "\n",
    "#the other half is circular\n",
    "#a 'one' corresponds to circular\n",
    "df_2 = pd.read_csv('np_circ_100.csv')            \n",
    "\n",
    "for index, rows in df_2.iterrows():\n",
    "    batch_y_train.append(1)\n",
    "    list_2 = rows\n",
    "    batch_x_train.append(list_2)\n",
    "\n",
    "#first, convert the x training data into a tensor\n",
    "#the y training data becomes categorical\n",
    "batch_x_train = tf.convert_to_tensor(batch_x_train, dtype=tf.float32) \n",
    "batch_y_train = tf.keras.utils.to_categorical(batch_y_train, num_classes=2)\n",
    "batch_y_val = batch_y_train\n",
    "\n",
    "#next, create a set to validate against.\n",
    "batch_x_val = []\n",
    "\n",
    "df_3 = pd.read_csv('np_t_lin_100.csv')\n",
    "\n",
    "for index, rows in df_3.iterrows():\n",
    "    list_3 = rows\n",
    "    batch_x_test.append(list_3)\n",
    "    \n",
    "df_4 = pd.read_csv('np_t_circ_100.csv')\n",
    "for index, rows in df_4.iterrows():\n",
    "    list_4 = rows\n",
    "    batch_x_test.append(list_4)\n",
    "\n",
    "#as before, convert it to a tensor\n",
    "batch_x_val = tf.convert_to_tensor(batch_x_val, dtype=tf.float32)\n",
    "\n",
    "#then tune the training parameters\n",
    "lr = 1e-2\n",
    "num_nodes = 6\n",
    "num_classes = 2\n",
    "num_epochs = 400\n",
    "timesteps = 71\n",
    "tf.keras.backend.clear_session()\n",
    "X = tf.keras.Input(name='X', shape=[batch_x_train.shape[1],1], dtype=tf.dtypes.float32)\n",
    "lstm_output = tf.keras.layers.LSTM(num_nodes)(X)\n",
    "prediction = tf.keras.layers.Dense(num_classes)(lstm_output)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "model = keras.Model(inputs=X, outputs=prediction)\n",
    "model.compile(optimizer=opt, loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "model.fit(x=batch_x_train, y=batch_y_train, epochs=num_epochs, validation_data=(batch_x_val,batch_y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e749e39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#since we have training and validation sets,\n",
    "#we can proceed with a testing set\n",
    "\n",
    "batch_x_test = []\n",
    "df_3 = pd.read_csv('np_lin_300.csv')\n",
    "for index, rows in df_3.iterrows():\n",
    "    list_3 = rows\n",
    "    batch_x_test.append(list_3)\n",
    "    \n",
    "df_4 = pd.read_csv('np_circ_300.csv')\n",
    "for index, rows in df_4.iterrows():\n",
    "    list_4 = rows\n",
    "    batch_x_test.append(list_4)\n",
    "    \n",
    "batch_x_test = tf.convert_to_tensor(batch_x_test, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c94795c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#next, we generate a confusion matrix\n",
    "y_prediction = model.predict(batch_x_test)\n",
    "y_prediction = np.argmax(y_prediction, axis=1)\n",
    "y_test = np.argmax(batch_y_train, axis=1)\n",
    "result = tf.math.confusion_matrix(y_test, y_prediction, num_classes=2, weights=None)\n",
    "labels = [\"linear\", \"circular\"]\n",
    "cm = confusion_matrix(y_test, y_prediction)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38e242d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"linear\", \"circular\"]\n",
    "cm = confusion_matrix(y_test, y_prediction)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69f6cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('NP_LSTM.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
