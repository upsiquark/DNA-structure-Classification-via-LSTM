{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55837807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as pl\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.optimize as spo\n",
    "import pandas as pd\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "429f991d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "10/10 [==============================] - 2s 51ms/step - loss: 0.7701 - accuracy: 0.5638 - val_loss: 0.7762 - val_accuracy: 0.5470\n",
      "Epoch 2/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7315 - accuracy: 0.5738 - val_loss: 0.7413 - val_accuracy: 0.5503\n",
      "Epoch 3/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7008 - accuracy: 0.5872 - val_loss: 0.7010 - val_accuracy: 0.5537\n",
      "Epoch 4/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6649 - accuracy: 0.6141 - val_loss: 0.6563 - val_accuracy: 0.6174\n",
      "Epoch 5/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6580 - accuracy: 0.6309 - val_loss: 0.6600 - val_accuracy: 0.6309\n",
      "Epoch 6/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6359 - accuracy: 0.6510 - val_loss: 0.6430 - val_accuracy: 0.6342\n",
      "Epoch 7/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6291 - accuracy: 0.6577 - val_loss: 0.6421 - val_accuracy: 0.6409\n",
      "Epoch 8/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6261 - accuracy: 0.6544 - val_loss: 0.6380 - val_accuracy: 0.6376\n",
      "Epoch 9/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6208 - accuracy: 0.6644 - val_loss: 0.6425 - val_accuracy: 0.6342\n",
      "Epoch 10/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6196 - accuracy: 0.6611 - val_loss: 0.6382 - val_accuracy: 0.6376\n",
      "Epoch 11/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6158 - accuracy: 0.6611 - val_loss: 0.6356 - val_accuracy: 0.6376\n",
      "Epoch 12/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6142 - accuracy: 0.6611 - val_loss: 0.6323 - val_accuracy: 0.6376\n",
      "Epoch 13/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6127 - accuracy: 0.6577 - val_loss: 0.6287 - val_accuracy: 0.6342\n",
      "Epoch 14/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6130 - accuracy: 0.6611 - val_loss: 0.6353 - val_accuracy: 0.6342\n",
      "Epoch 15/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6129 - accuracy: 0.6611 - val_loss: 0.6322 - val_accuracy: 0.6342\n",
      "Epoch 16/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6092 - accuracy: 0.6611 - val_loss: 0.6235 - val_accuracy: 0.6409\n",
      "Epoch 17/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6167 - accuracy: 0.6443 - val_loss: 0.6210 - val_accuracy: 0.6376\n",
      "Epoch 18/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6094 - accuracy: 0.6544 - val_loss: 0.6236 - val_accuracy: 0.6376\n",
      "Epoch 19/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6051 - accuracy: 0.6678 - val_loss: 0.6278 - val_accuracy: 0.6342\n",
      "Epoch 20/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6038 - accuracy: 0.6711 - val_loss: 0.6196 - val_accuracy: 0.6409\n",
      "Epoch 21/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6011 - accuracy: 0.6711 - val_loss: 0.6196 - val_accuracy: 0.6376\n",
      "Epoch 22/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6008 - accuracy: 0.6678 - val_loss: 0.6168 - val_accuracy: 0.6443\n",
      "Epoch 23/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5998 - accuracy: 0.6644 - val_loss: 0.6150 - val_accuracy: 0.6443\n",
      "Epoch 24/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5974 - accuracy: 0.6644 - val_loss: 0.6187 - val_accuracy: 0.6409\n",
      "Epoch 25/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5990 - accuracy: 0.6644 - val_loss: 0.6146 - val_accuracy: 0.6443\n",
      "Epoch 26/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6023 - accuracy: 0.6544 - val_loss: 0.6152 - val_accuracy: 0.6443\n",
      "Epoch 27/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5965 - accuracy: 0.6711 - val_loss: 0.6193 - val_accuracy: 0.6376\n",
      "Epoch 28/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5996 - accuracy: 0.6678 - val_loss: 0.6101 - val_accuracy: 0.6477\n",
      "Epoch 29/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5943 - accuracy: 0.6644 - val_loss: 0.6216 - val_accuracy: 0.6342\n",
      "Epoch 30/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5959 - accuracy: 0.6644 - val_loss: 0.6092 - val_accuracy: 0.6342\n",
      "Epoch 31/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6085 - accuracy: 0.6477 - val_loss: 0.6092 - val_accuracy: 0.6342\n",
      "Epoch 32/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5993 - accuracy: 0.6544 - val_loss: 0.6123 - val_accuracy: 0.6376\n",
      "Epoch 33/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5920 - accuracy: 0.6644 - val_loss: 0.6156 - val_accuracy: 0.6376\n",
      "Epoch 34/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5899 - accuracy: 0.6644 - val_loss: 0.6119 - val_accuracy: 0.6443\n",
      "Epoch 35/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5918 - accuracy: 0.6644 - val_loss: 0.6107 - val_accuracy: 0.6443\n",
      "Epoch 36/600\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.5931 - accuracy: 0.6745 - val_loss: 0.6089 - val_accuracy: 0.6443\n",
      "Epoch 37/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5929 - accuracy: 0.6544 - val_loss: 0.6075 - val_accuracy: 0.6409\n",
      "Epoch 38/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6043 - accuracy: 0.6544 - val_loss: 0.6162 - val_accuracy: 0.6342\n",
      "Epoch 39/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6013 - accuracy: 0.6577 - val_loss: 0.6059 - val_accuracy: 0.6409\n",
      "Epoch 40/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5943 - accuracy: 0.6577 - val_loss: 0.6102 - val_accuracy: 0.6443\n",
      "Epoch 41/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5935 - accuracy: 0.6678 - val_loss: 0.6116 - val_accuracy: 0.6409\n",
      "Epoch 42/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5842 - accuracy: 0.6711 - val_loss: 0.6057 - val_accuracy: 0.6409\n",
      "Epoch 43/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5836 - accuracy: 0.6711 - val_loss: 0.6071 - val_accuracy: 0.6342\n",
      "Epoch 44/600\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.5825 - accuracy: 0.6812 - val_loss: 0.6065 - val_accuracy: 0.6376\n",
      "Epoch 45/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5829 - accuracy: 0.6745 - val_loss: 0.6038 - val_accuracy: 0.6409\n",
      "Epoch 46/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5847 - accuracy: 0.6711 - val_loss: 0.6029 - val_accuracy: 0.6409\n",
      "Epoch 47/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5828 - accuracy: 0.6711 - val_loss: 0.6048 - val_accuracy: 0.6342\n",
      "Epoch 48/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5814 - accuracy: 0.6745 - val_loss: 0.6048 - val_accuracy: 0.6342\n",
      "Epoch 49/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5833 - accuracy: 0.6711 - val_loss: 0.6039 - val_accuracy: 0.6376\n",
      "Epoch 50/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5824 - accuracy: 0.6711 - val_loss: 0.6053 - val_accuracy: 0.6342\n",
      "Epoch 51/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5792 - accuracy: 0.6745 - val_loss: 0.6048 - val_accuracy: 0.6342\n",
      "Epoch 52/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5783 - accuracy: 0.6779 - val_loss: 0.6020 - val_accuracy: 0.6376\n",
      "Epoch 53/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5799 - accuracy: 0.6846 - val_loss: 0.6015 - val_accuracy: 0.6376\n",
      "Epoch 54/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5765 - accuracy: 0.6779 - val_loss: 0.5991 - val_accuracy: 0.6477\n",
      "Epoch 55/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5776 - accuracy: 0.6879 - val_loss: 0.6019 - val_accuracy: 0.6376\n",
      "Epoch 56/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5767 - accuracy: 0.6846 - val_loss: 0.6058 - val_accuracy: 0.6409\n",
      "Epoch 57/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6001 - accuracy: 0.6678 - val_loss: 0.6075 - val_accuracy: 0.6309\n",
      "Epoch 58/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5887 - accuracy: 0.6678 - val_loss: 0.6108 - val_accuracy: 0.6376\n",
      "Epoch 59/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5793 - accuracy: 0.6779 - val_loss: 0.5981 - val_accuracy: 0.6510\n",
      "Epoch 60/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5769 - accuracy: 0.6812 - val_loss: 0.5983 - val_accuracy: 0.6376\n",
      "Epoch 61/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5766 - accuracy: 0.6779 - val_loss: 0.5957 - val_accuracy: 0.6443\n",
      "Epoch 62/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5753 - accuracy: 0.6812 - val_loss: 0.5992 - val_accuracy: 0.6409\n",
      "Epoch 63/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5739 - accuracy: 0.6879 - val_loss: 0.5996 - val_accuracy: 0.6376\n",
      "Epoch 64/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5740 - accuracy: 0.6879 - val_loss: 0.5981 - val_accuracy: 0.6443\n",
      "Epoch 65/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5733 - accuracy: 0.6812 - val_loss: 0.5996 - val_accuracy: 0.6409\n",
      "Epoch 66/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5788 - accuracy: 0.6879 - val_loss: 0.6008 - val_accuracy: 0.6409\n",
      "Epoch 67/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5708 - accuracy: 0.6879 - val_loss: 0.6003 - val_accuracy: 0.6443\n",
      "Epoch 68/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5742 - accuracy: 0.6846 - val_loss: 0.5989 - val_accuracy: 0.6477\n",
      "Epoch 69/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5783 - accuracy: 0.6879 - val_loss: 0.5962 - val_accuracy: 0.6611\n",
      "Epoch 70/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5846 - accuracy: 0.6745 - val_loss: 0.5954 - val_accuracy: 0.6577\n",
      "Epoch 71/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5916 - accuracy: 0.6745 - val_loss: 0.5980 - val_accuracy: 0.6510\n",
      "Epoch 72/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5871 - accuracy: 0.6846 - val_loss: 0.6084 - val_accuracy: 0.6577\n",
      "Epoch 73/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6008 - accuracy: 0.6745 - val_loss: 0.6026 - val_accuracy: 0.6577\n",
      "Epoch 74/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5846 - accuracy: 0.6745 - val_loss: 0.5986 - val_accuracy: 0.6544\n",
      "Epoch 75/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5713 - accuracy: 0.6913 - val_loss: 0.5941 - val_accuracy: 0.6711\n",
      "Epoch 76/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5704 - accuracy: 0.6913 - val_loss: 0.5957 - val_accuracy: 0.6678\n",
      "Epoch 77/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5713 - accuracy: 0.6946 - val_loss: 0.5942 - val_accuracy: 0.6611\n",
      "Epoch 78/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5703 - accuracy: 0.6946 - val_loss: 0.5978 - val_accuracy: 0.6544\n",
      "Epoch 79/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5693 - accuracy: 0.6980 - val_loss: 0.5967 - val_accuracy: 0.6577\n",
      "Epoch 80/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5679 - accuracy: 0.6980 - val_loss: 0.5959 - val_accuracy: 0.6611\n",
      "Epoch 81/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5712 - accuracy: 0.6913 - val_loss: 0.5989 - val_accuracy: 0.6644\n",
      "Epoch 82/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5712 - accuracy: 0.6812 - val_loss: 0.6011 - val_accuracy: 0.6477\n",
      "Epoch 83/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5689 - accuracy: 0.6946 - val_loss: 0.5984 - val_accuracy: 0.6477\n",
      "Epoch 84/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5679 - accuracy: 0.6913 - val_loss: 0.5986 - val_accuracy: 0.6644\n",
      "Epoch 85/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5676 - accuracy: 0.6812 - val_loss: 0.5981 - val_accuracy: 0.6544\n",
      "Epoch 86/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5741 - accuracy: 0.6745 - val_loss: 0.6034 - val_accuracy: 0.6544\n",
      "Epoch 87/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5682 - accuracy: 0.6846 - val_loss: 0.5961 - val_accuracy: 0.6477\n",
      "Epoch 88/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5662 - accuracy: 0.6879 - val_loss: 0.5976 - val_accuracy: 0.6510\n",
      "Epoch 89/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5689 - accuracy: 0.6779 - val_loss: 0.6001 - val_accuracy: 0.6644\n",
      "Epoch 90/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5664 - accuracy: 0.6946 - val_loss: 0.5975 - val_accuracy: 0.6611\n",
      "Epoch 91/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5651 - accuracy: 0.6980 - val_loss: 0.5981 - val_accuracy: 0.6544\n",
      "Epoch 92/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5681 - accuracy: 0.6913 - val_loss: 0.5978 - val_accuracy: 0.6544\n",
      "Epoch 93/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5655 - accuracy: 0.6846 - val_loss: 0.5995 - val_accuracy: 0.6477\n",
      "Epoch 94/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5648 - accuracy: 0.6846 - val_loss: 0.5962 - val_accuracy: 0.6544\n",
      "Epoch 95/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5645 - accuracy: 0.7047 - val_loss: 0.5978 - val_accuracy: 0.6510\n",
      "Epoch 96/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5630 - accuracy: 0.6946 - val_loss: 0.5968 - val_accuracy: 0.6577\n",
      "Epoch 97/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5637 - accuracy: 0.6879 - val_loss: 0.5947 - val_accuracy: 0.6510\n",
      "Epoch 98/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5645 - accuracy: 0.6879 - val_loss: 0.5958 - val_accuracy: 0.6611\n",
      "Epoch 99/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5693 - accuracy: 0.6812 - val_loss: 0.5984 - val_accuracy: 0.6477\n",
      "Epoch 100/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5683 - accuracy: 0.7013 - val_loss: 0.5956 - val_accuracy: 0.6544\n",
      "Epoch 101/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5652 - accuracy: 0.6879 - val_loss: 0.5965 - val_accuracy: 0.6510\n",
      "Epoch 102/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5634 - accuracy: 0.6879 - val_loss: 0.5950 - val_accuracy: 0.6510\n",
      "Epoch 103/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5615 - accuracy: 0.7047 - val_loss: 0.5950 - val_accuracy: 0.6544\n",
      "Epoch 104/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5614 - accuracy: 0.6946 - val_loss: 0.6011 - val_accuracy: 0.6544\n",
      "Epoch 105/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5606 - accuracy: 0.6846 - val_loss: 0.5939 - val_accuracy: 0.6611\n",
      "Epoch 106/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5609 - accuracy: 0.7081 - val_loss: 0.5928 - val_accuracy: 0.6510\n",
      "Epoch 107/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5667 - accuracy: 0.6946 - val_loss: 0.5927 - val_accuracy: 0.6477\n",
      "Epoch 108/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5624 - accuracy: 0.6913 - val_loss: 0.5981 - val_accuracy: 0.6477\n",
      "Epoch 109/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5601 - accuracy: 0.6879 - val_loss: 0.5939 - val_accuracy: 0.6477\n",
      "Epoch 110/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5674 - accuracy: 0.6980 - val_loss: 0.5943 - val_accuracy: 0.6477\n",
      "Epoch 111/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5604 - accuracy: 0.7013 - val_loss: 0.5986 - val_accuracy: 0.6577\n",
      "Epoch 112/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5587 - accuracy: 0.6913 - val_loss: 0.5933 - val_accuracy: 0.6544\n",
      "Epoch 113/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5614 - accuracy: 0.6946 - val_loss: 0.5952 - val_accuracy: 0.6577\n",
      "Epoch 114/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5598 - accuracy: 0.7081 - val_loss: 0.5924 - val_accuracy: 0.6611\n",
      "Epoch 115/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5580 - accuracy: 0.6980 - val_loss: 0.5950 - val_accuracy: 0.6577\n",
      "Epoch 116/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5595 - accuracy: 0.6913 - val_loss: 0.5926 - val_accuracy: 0.6577\n",
      "Epoch 117/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5611 - accuracy: 0.7047 - val_loss: 0.5933 - val_accuracy: 0.6644\n",
      "Epoch 118/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5723 - accuracy: 0.6745 - val_loss: 0.5975 - val_accuracy: 0.6510\n",
      "Epoch 119/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5602 - accuracy: 0.6946 - val_loss: 0.5924 - val_accuracy: 0.6644\n",
      "Epoch 120/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5585 - accuracy: 0.6913 - val_loss: 0.5967 - val_accuracy: 0.6510\n",
      "Epoch 121/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5580 - accuracy: 0.6913 - val_loss: 0.5915 - val_accuracy: 0.6577\n",
      "Epoch 122/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5629 - accuracy: 0.6913 - val_loss: 0.5919 - val_accuracy: 0.6577\n",
      "Epoch 123/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5634 - accuracy: 0.6846 - val_loss: 0.5972 - val_accuracy: 0.6443\n",
      "Epoch 124/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5643 - accuracy: 0.6879 - val_loss: 0.5911 - val_accuracy: 0.6544\n",
      "Epoch 125/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5567 - accuracy: 0.6879 - val_loss: 0.5964 - val_accuracy: 0.6443\n",
      "Epoch 126/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5593 - accuracy: 0.6779 - val_loss: 0.5921 - val_accuracy: 0.6544\n",
      "Epoch 127/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5608 - accuracy: 0.6913 - val_loss: 0.5890 - val_accuracy: 0.6577\n",
      "Epoch 128/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5540 - accuracy: 0.6913 - val_loss: 0.6000 - val_accuracy: 0.6409\n",
      "Epoch 129/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5745 - accuracy: 0.6946 - val_loss: 0.6055 - val_accuracy: 0.6510\n",
      "Epoch 130/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5599 - accuracy: 0.7081 - val_loss: 0.5896 - val_accuracy: 0.6544\n",
      "Epoch 131/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5530 - accuracy: 0.7013 - val_loss: 0.6215 - val_accuracy: 0.6242\n",
      "Epoch 132/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5809 - accuracy: 0.6711 - val_loss: 0.6127 - val_accuracy: 0.6275\n",
      "Epoch 133/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5720 - accuracy: 0.6779 - val_loss: 0.5937 - val_accuracy: 0.6577\n",
      "Epoch 134/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5597 - accuracy: 0.6812 - val_loss: 0.5912 - val_accuracy: 0.6577\n",
      "Epoch 135/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5541 - accuracy: 0.6946 - val_loss: 0.5904 - val_accuracy: 0.6544\n",
      "Epoch 136/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5542 - accuracy: 0.6946 - val_loss: 0.5922 - val_accuracy: 0.6544\n",
      "Epoch 137/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5526 - accuracy: 0.7047 - val_loss: 0.5929 - val_accuracy: 0.6510\n",
      "Epoch 138/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5521 - accuracy: 0.7013 - val_loss: 0.5945 - val_accuracy: 0.6544\n",
      "Epoch 139/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5528 - accuracy: 0.7081 - val_loss: 0.5955 - val_accuracy: 0.6577\n",
      "Epoch 140/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5519 - accuracy: 0.7114 - val_loss: 0.5971 - val_accuracy: 0.6544\n",
      "Epoch 141/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5516 - accuracy: 0.7181 - val_loss: 0.5944 - val_accuracy: 0.6577\n",
      "Epoch 142/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5570 - accuracy: 0.6846 - val_loss: 0.5936 - val_accuracy: 0.6611\n",
      "Epoch 143/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5543 - accuracy: 0.7081 - val_loss: 0.6111 - val_accuracy: 0.6342\n",
      "Epoch 144/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5520 - accuracy: 0.7081 - val_loss: 0.5941 - val_accuracy: 0.6510\n",
      "Epoch 145/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5533 - accuracy: 0.7013 - val_loss: 0.5939 - val_accuracy: 0.6544\n",
      "Epoch 146/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5514 - accuracy: 0.6980 - val_loss: 0.5906 - val_accuracy: 0.6611\n",
      "Epoch 147/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5513 - accuracy: 0.7081 - val_loss: 0.5957 - val_accuracy: 0.6477\n",
      "Epoch 148/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5501 - accuracy: 0.7047 - val_loss: 0.5910 - val_accuracy: 0.6544\n",
      "Epoch 149/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5490 - accuracy: 0.6980 - val_loss: 0.5932 - val_accuracy: 0.6477\n",
      "Epoch 150/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5484 - accuracy: 0.7114 - val_loss: 0.5924 - val_accuracy: 0.6577\n",
      "Epoch 151/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5488 - accuracy: 0.7081 - val_loss: 0.5931 - val_accuracy: 0.6477\n",
      "Epoch 152/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5499 - accuracy: 0.7114 - val_loss: 0.5948 - val_accuracy: 0.6544\n",
      "Epoch 153/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5458 - accuracy: 0.7148 - val_loss: 0.5960 - val_accuracy: 0.6443\n",
      "Epoch 154/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5488 - accuracy: 0.7114 - val_loss: 0.5940 - val_accuracy: 0.6443\n",
      "Epoch 155/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5563 - accuracy: 0.6980 - val_loss: 0.6168 - val_accuracy: 0.6342\n",
      "Epoch 156/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5473 - accuracy: 0.7047 - val_loss: 0.5951 - val_accuracy: 0.6510\n",
      "Epoch 157/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5501 - accuracy: 0.7013 - val_loss: 0.5921 - val_accuracy: 0.6510\n",
      "Epoch 158/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5483 - accuracy: 0.7114 - val_loss: 0.5942 - val_accuracy: 0.6477\n",
      "Epoch 159/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5473 - accuracy: 0.7148 - val_loss: 0.5939 - val_accuracy: 0.6544\n",
      "Epoch 160/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5462 - accuracy: 0.7114 - val_loss: 0.5926 - val_accuracy: 0.6510\n",
      "Epoch 161/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5457 - accuracy: 0.7047 - val_loss: 0.5925 - val_accuracy: 0.6510\n",
      "Epoch 162/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5434 - accuracy: 0.7148 - val_loss: 0.5961 - val_accuracy: 0.6409\n",
      "Epoch 163/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5450 - accuracy: 0.7114 - val_loss: 0.5940 - val_accuracy: 0.6443\n",
      "Epoch 164/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5450 - accuracy: 0.7081 - val_loss: 0.5945 - val_accuracy: 0.6477\n",
      "Epoch 165/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5465 - accuracy: 0.7047 - val_loss: 0.5966 - val_accuracy: 0.6376\n",
      "Epoch 166/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5440 - accuracy: 0.7114 - val_loss: 0.5923 - val_accuracy: 0.6409\n",
      "Epoch 167/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5459 - accuracy: 0.7047 - val_loss: 0.6020 - val_accuracy: 0.6376\n",
      "Epoch 168/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5452 - accuracy: 0.7047 - val_loss: 0.5903 - val_accuracy: 0.6477\n",
      "Epoch 169/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5458 - accuracy: 0.7013 - val_loss: 0.5986 - val_accuracy: 0.6443\n",
      "Epoch 170/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5440 - accuracy: 0.7148 - val_loss: 0.5934 - val_accuracy: 0.6544\n",
      "Epoch 171/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5599 - accuracy: 0.6879 - val_loss: 0.6068 - val_accuracy: 0.6376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5548 - accuracy: 0.6879 - val_loss: 0.5936 - val_accuracy: 0.6510\n",
      "Epoch 173/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5462 - accuracy: 0.7047 - val_loss: 0.5946 - val_accuracy: 0.6443\n",
      "Epoch 174/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5486 - accuracy: 0.7081 - val_loss: 0.5931 - val_accuracy: 0.6409\n",
      "Epoch 175/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5460 - accuracy: 0.7114 - val_loss: 0.5874 - val_accuracy: 0.6544\n",
      "Epoch 176/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5427 - accuracy: 0.7047 - val_loss: 0.5985 - val_accuracy: 0.6342\n",
      "Epoch 177/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5421 - accuracy: 0.7148 - val_loss: 0.5917 - val_accuracy: 0.6443\n",
      "Epoch 178/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5402 - accuracy: 0.7181 - val_loss: 0.5899 - val_accuracy: 0.6477\n",
      "Epoch 179/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5394 - accuracy: 0.7148 - val_loss: 0.5896 - val_accuracy: 0.6510\n",
      "Epoch 180/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5408 - accuracy: 0.7181 - val_loss: 0.5865 - val_accuracy: 0.6477\n",
      "Epoch 181/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5408 - accuracy: 0.7081 - val_loss: 0.5915 - val_accuracy: 0.6477\n",
      "Epoch 182/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5418 - accuracy: 0.7081 - val_loss: 0.5951 - val_accuracy: 0.6510\n",
      "Epoch 183/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5388 - accuracy: 0.7215 - val_loss: 0.5939 - val_accuracy: 0.6409\n",
      "Epoch 184/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5431 - accuracy: 0.7148 - val_loss: 0.5901 - val_accuracy: 0.6477\n",
      "Epoch 185/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5437 - accuracy: 0.7047 - val_loss: 0.5904 - val_accuracy: 0.6544\n",
      "Epoch 186/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5403 - accuracy: 0.7181 - val_loss: 0.5948 - val_accuracy: 0.6443\n",
      "Epoch 187/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5389 - accuracy: 0.7148 - val_loss: 0.5897 - val_accuracy: 0.6443\n",
      "Epoch 188/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5375 - accuracy: 0.7215 - val_loss: 0.5905 - val_accuracy: 0.6443\n",
      "Epoch 189/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5369 - accuracy: 0.7248 - val_loss: 0.5910 - val_accuracy: 0.6409\n",
      "Epoch 190/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5362 - accuracy: 0.7282 - val_loss: 0.5916 - val_accuracy: 0.6443\n",
      "Epoch 191/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5378 - accuracy: 0.7215 - val_loss: 0.5871 - val_accuracy: 0.6544\n",
      "Epoch 192/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5354 - accuracy: 0.7315 - val_loss: 0.5944 - val_accuracy: 0.6376\n",
      "Epoch 193/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5355 - accuracy: 0.7248 - val_loss: 0.5910 - val_accuracy: 0.6409\n",
      "Epoch 194/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5353 - accuracy: 0.7315 - val_loss: 0.5904 - val_accuracy: 0.6443\n",
      "Epoch 195/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5354 - accuracy: 0.7248 - val_loss: 0.5929 - val_accuracy: 0.6376\n",
      "Epoch 196/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5348 - accuracy: 0.7282 - val_loss: 0.5915 - val_accuracy: 0.6409\n",
      "Epoch 197/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5363 - accuracy: 0.7349 - val_loss: 0.5914 - val_accuracy: 0.6443\n",
      "Epoch 198/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5356 - accuracy: 0.7114 - val_loss: 0.5882 - val_accuracy: 0.6477\n",
      "Epoch 199/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5350 - accuracy: 0.7181 - val_loss: 0.5881 - val_accuracy: 0.6477\n",
      "Epoch 200/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5347 - accuracy: 0.7181 - val_loss: 0.5906 - val_accuracy: 0.6477\n",
      "Epoch 201/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5331 - accuracy: 0.7315 - val_loss: 0.5917 - val_accuracy: 0.6443\n",
      "Epoch 202/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5324 - accuracy: 0.7282 - val_loss: 0.5841 - val_accuracy: 0.6644\n",
      "Epoch 203/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5372 - accuracy: 0.7148 - val_loss: 0.5909 - val_accuracy: 0.6443\n",
      "Epoch 204/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5325 - accuracy: 0.7181 - val_loss: 0.5820 - val_accuracy: 0.6611\n",
      "Epoch 205/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5335 - accuracy: 0.7248 - val_loss: 0.5873 - val_accuracy: 0.6443\n",
      "Epoch 206/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5341 - accuracy: 0.7148 - val_loss: 0.5855 - val_accuracy: 0.6510\n",
      "Epoch 207/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5365 - accuracy: 0.7081 - val_loss: 0.5868 - val_accuracy: 0.6510\n",
      "Epoch 208/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5326 - accuracy: 0.7282 - val_loss: 0.5926 - val_accuracy: 0.6409\n",
      "Epoch 209/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5307 - accuracy: 0.7282 - val_loss: 0.5835 - val_accuracy: 0.6544\n",
      "Epoch 210/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5312 - accuracy: 0.7282 - val_loss: 0.5880 - val_accuracy: 0.6510\n",
      "Epoch 211/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5301 - accuracy: 0.7282 - val_loss: 0.5839 - val_accuracy: 0.6577\n",
      "Epoch 212/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5368 - accuracy: 0.7215 - val_loss: 0.5849 - val_accuracy: 0.6577\n",
      "Epoch 213/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5286 - accuracy: 0.7282 - val_loss: 0.5835 - val_accuracy: 0.6477\n",
      "Epoch 214/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5612 - accuracy: 0.7013 - val_loss: 0.5936 - val_accuracy: 0.6510\n",
      "Epoch 215/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5380 - accuracy: 0.7148 - val_loss: 0.5819 - val_accuracy: 0.6477\n",
      "Epoch 216/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5307 - accuracy: 0.7215 - val_loss: 0.5821 - val_accuracy: 0.6477\n",
      "Epoch 217/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5300 - accuracy: 0.7181 - val_loss: 0.5854 - val_accuracy: 0.6477\n",
      "Epoch 218/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5281 - accuracy: 0.7248 - val_loss: 0.5827 - val_accuracy: 0.6477\n",
      "Epoch 219/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5285 - accuracy: 0.7215 - val_loss: 0.5841 - val_accuracy: 0.6443\n",
      "Epoch 220/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5297 - accuracy: 0.7215 - val_loss: 0.5796 - val_accuracy: 0.6611\n",
      "Epoch 221/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5316 - accuracy: 0.7215 - val_loss: 0.5905 - val_accuracy: 0.6477\n",
      "Epoch 222/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5277 - accuracy: 0.7215 - val_loss: 0.5798 - val_accuracy: 0.6644\n",
      "Epoch 223/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5297 - accuracy: 0.7181 - val_loss: 0.5826 - val_accuracy: 0.6544\n",
      "Epoch 224/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5269 - accuracy: 0.7215 - val_loss: 0.5847 - val_accuracy: 0.6544\n",
      "Epoch 225/600\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.5269 - accuracy: 0.7215 - val_loss: 0.5807 - val_accuracy: 0.6577\n",
      "Epoch 226/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5345 - accuracy: 0.7148 - val_loss: 0.5808 - val_accuracy: 0.6577\n",
      "Epoch 227/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5362 - accuracy: 0.7248 - val_loss: 0.5856 - val_accuracy: 0.6510\n",
      "Epoch 228/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5309 - accuracy: 0.7181 - val_loss: 0.5778 - val_accuracy: 0.6711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5269 - accuracy: 0.7215 - val_loss: 0.6105 - val_accuracy: 0.6342\n",
      "Epoch 230/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5351 - accuracy: 0.7181 - val_loss: 0.5810 - val_accuracy: 0.6577\n",
      "Epoch 231/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5275 - accuracy: 0.7215 - val_loss: 0.5837 - val_accuracy: 0.6577\n",
      "Epoch 232/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5258 - accuracy: 0.7282 - val_loss: 0.5835 - val_accuracy: 0.6577\n",
      "Epoch 233/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5255 - accuracy: 0.7215 - val_loss: 0.5803 - val_accuracy: 0.6611\n",
      "Epoch 234/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5226 - accuracy: 0.7181 - val_loss: 0.5777 - val_accuracy: 0.6611\n",
      "Epoch 235/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5260 - accuracy: 0.7114 - val_loss: 0.5716 - val_accuracy: 0.6745\n",
      "Epoch 236/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5229 - accuracy: 0.7215 - val_loss: 0.5907 - val_accuracy: 0.6477\n",
      "Epoch 237/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5334 - accuracy: 0.7215 - val_loss: 0.5789 - val_accuracy: 0.6644\n",
      "Epoch 238/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5273 - accuracy: 0.7215 - val_loss: 0.5729 - val_accuracy: 0.6678\n",
      "Epoch 239/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5196 - accuracy: 0.7349 - val_loss: 0.5794 - val_accuracy: 0.6644\n",
      "Epoch 240/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5156 - accuracy: 0.7416 - val_loss: 0.5874 - val_accuracy: 0.6711\n",
      "Epoch 241/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5241 - accuracy: 0.7248 - val_loss: 0.5833 - val_accuracy: 0.6577\n",
      "Epoch 242/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5177 - accuracy: 0.7383 - val_loss: 0.5743 - val_accuracy: 0.6678\n",
      "Epoch 243/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5280 - accuracy: 0.7315 - val_loss: 0.5747 - val_accuracy: 0.6611\n",
      "Epoch 244/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5413 - accuracy: 0.7081 - val_loss: 0.6312 - val_accuracy: 0.6040\n",
      "Epoch 245/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5578 - accuracy: 0.7114 - val_loss: 0.6029 - val_accuracy: 0.6611\n",
      "Epoch 246/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5781 - accuracy: 0.6846 - val_loss: 0.5858 - val_accuracy: 0.6745\n",
      "Epoch 247/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5375 - accuracy: 0.7148 - val_loss: 0.6040 - val_accuracy: 0.6443\n",
      "Epoch 248/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5302 - accuracy: 0.7215 - val_loss: 0.5677 - val_accuracy: 0.6779\n",
      "Epoch 249/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5235 - accuracy: 0.7282 - val_loss: 0.5691 - val_accuracy: 0.6812\n",
      "Epoch 250/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5198 - accuracy: 0.7349 - val_loss: 0.5759 - val_accuracy: 0.6745\n",
      "Epoch 251/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5190 - accuracy: 0.7349 - val_loss: 0.5700 - val_accuracy: 0.6846\n",
      "Epoch 252/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5215 - accuracy: 0.7248 - val_loss: 0.5744 - val_accuracy: 0.6678\n",
      "Epoch 253/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5156 - accuracy: 0.7349 - val_loss: 0.5702 - val_accuracy: 0.6812\n",
      "Epoch 254/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5170 - accuracy: 0.7349 - val_loss: 0.5786 - val_accuracy: 0.6611\n",
      "Epoch 255/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5155 - accuracy: 0.7383 - val_loss: 0.5735 - val_accuracy: 0.6678\n",
      "Epoch 256/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5153 - accuracy: 0.7282 - val_loss: 0.5784 - val_accuracy: 0.6678\n",
      "Epoch 257/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5203 - accuracy: 0.7315 - val_loss: 0.5763 - val_accuracy: 0.6644\n",
      "Epoch 258/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5627 - accuracy: 0.6846 - val_loss: 0.5970 - val_accuracy: 0.6577\n",
      "Epoch 259/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5415 - accuracy: 0.7114 - val_loss: 0.5935 - val_accuracy: 0.6544\n",
      "Epoch 260/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5569 - accuracy: 0.7081 - val_loss: 0.6381 - val_accuracy: 0.6141\n",
      "Epoch 261/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5366 - accuracy: 0.7248 - val_loss: 0.5820 - val_accuracy: 0.6678\n",
      "Epoch 262/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5452 - accuracy: 0.7248 - val_loss: 0.6058 - val_accuracy: 0.6309\n",
      "Epoch 263/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5662 - accuracy: 0.7013 - val_loss: 0.5906 - val_accuracy: 0.6745\n",
      "Epoch 264/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5326 - accuracy: 0.7315 - val_loss: 0.5702 - val_accuracy: 0.6745\n",
      "Epoch 265/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5216 - accuracy: 0.7349 - val_loss: 0.5992 - val_accuracy: 0.6477\n",
      "Epoch 266/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5269 - accuracy: 0.7282 - val_loss: 0.5698 - val_accuracy: 0.6711\n",
      "Epoch 267/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5178 - accuracy: 0.7349 - val_loss: 0.5735 - val_accuracy: 0.6745\n",
      "Epoch 268/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5114 - accuracy: 0.7383 - val_loss: 0.5811 - val_accuracy: 0.6544\n",
      "Epoch 269/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5143 - accuracy: 0.7383 - val_loss: 0.5804 - val_accuracy: 0.6577\n",
      "Epoch 270/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5214 - accuracy: 0.7282 - val_loss: 0.5751 - val_accuracy: 0.6711\n",
      "Epoch 271/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5130 - accuracy: 0.7416 - val_loss: 0.5805 - val_accuracy: 0.6611\n",
      "Epoch 272/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5143 - accuracy: 0.7483 - val_loss: 0.5704 - val_accuracy: 0.6779\n",
      "Epoch 273/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5114 - accuracy: 0.7483 - val_loss: 0.5700 - val_accuracy: 0.6779\n",
      "Epoch 274/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5143 - accuracy: 0.7416 - val_loss: 0.5699 - val_accuracy: 0.6812\n",
      "Epoch 275/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5143 - accuracy: 0.7483 - val_loss: 0.5704 - val_accuracy: 0.6745\n",
      "Epoch 276/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5091 - accuracy: 0.7450 - val_loss: 0.5722 - val_accuracy: 0.6711\n",
      "Epoch 277/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5086 - accuracy: 0.7383 - val_loss: 0.5729 - val_accuracy: 0.6678\n",
      "Epoch 278/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5088 - accuracy: 0.7483 - val_loss: 0.5695 - val_accuracy: 0.6812\n",
      "Epoch 279/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5100 - accuracy: 0.7349 - val_loss: 0.5694 - val_accuracy: 0.6779\n",
      "Epoch 280/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5086 - accuracy: 0.7550 - val_loss: 0.5702 - val_accuracy: 0.6812\n",
      "Epoch 281/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5112 - accuracy: 0.7450 - val_loss: 0.5761 - val_accuracy: 0.6711\n",
      "Epoch 282/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5659 - accuracy: 0.6946 - val_loss: 0.6568 - val_accuracy: 0.5973\n",
      "Epoch 283/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5314 - accuracy: 0.7215 - val_loss: 0.5870 - val_accuracy: 0.6711\n",
      "Epoch 284/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5207 - accuracy: 0.7349 - val_loss: 0.5757 - val_accuracy: 0.6678\n",
      "Epoch 285/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5116 - accuracy: 0.7383 - val_loss: 0.5711 - val_accuracy: 0.6678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5137 - accuracy: 0.7349 - val_loss: 0.5786 - val_accuracy: 0.6678\n",
      "Epoch 287/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5154 - accuracy: 0.7416 - val_loss: 0.5751 - val_accuracy: 0.6812\n",
      "Epoch 288/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5376 - accuracy: 0.7181 - val_loss: 0.6088 - val_accuracy: 0.6477\n",
      "Epoch 289/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5483 - accuracy: 0.7349 - val_loss: 0.5885 - val_accuracy: 0.6644\n",
      "Epoch 290/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5412 - accuracy: 0.7282 - val_loss: 0.5842 - val_accuracy: 0.6745\n",
      "Epoch 291/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5133 - accuracy: 0.7349 - val_loss: 0.5795 - val_accuracy: 0.6779\n",
      "Epoch 292/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5142 - accuracy: 0.7416 - val_loss: 0.5666 - val_accuracy: 0.6846\n",
      "Epoch 293/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5193 - accuracy: 0.7517 - val_loss: 0.5744 - val_accuracy: 0.6779\n",
      "Epoch 294/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5216 - accuracy: 0.7416 - val_loss: 0.5758 - val_accuracy: 0.6711\n",
      "Epoch 295/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5690 - accuracy: 0.7114 - val_loss: 0.6120 - val_accuracy: 0.6644\n",
      "Epoch 296/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5574 - accuracy: 0.7148 - val_loss: 0.5823 - val_accuracy: 0.6812\n",
      "Epoch 297/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5066 - accuracy: 0.7383 - val_loss: 0.5944 - val_accuracy: 0.6544\n",
      "Epoch 298/600\n",
      "10/10 [==============================] - 1s 61ms/step - loss: 0.5247 - accuracy: 0.7282 - val_loss: 0.5693 - val_accuracy: 0.6779\n",
      "Epoch 299/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5067 - accuracy: 0.7450 - val_loss: 0.5735 - val_accuracy: 0.6745\n",
      "Epoch 300/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5064 - accuracy: 0.7416 - val_loss: 0.5725 - val_accuracy: 0.6779\n",
      "Epoch 301/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5041 - accuracy: 0.7450 - val_loss: 0.5716 - val_accuracy: 0.6779\n",
      "Epoch 302/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5037 - accuracy: 0.7450 - val_loss: 0.5721 - val_accuracy: 0.6812\n",
      "Epoch 303/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5028 - accuracy: 0.7416 - val_loss: 0.5827 - val_accuracy: 0.6611\n",
      "Epoch 304/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5083 - accuracy: 0.7450 - val_loss: 0.5722 - val_accuracy: 0.6812\n",
      "Epoch 305/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5023 - accuracy: 0.7483 - val_loss: 0.5748 - val_accuracy: 0.6812\n",
      "Epoch 306/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5043 - accuracy: 0.7483 - val_loss: 0.5888 - val_accuracy: 0.6644\n",
      "Epoch 307/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5103 - accuracy: 0.7483 - val_loss: 0.5756 - val_accuracy: 0.6779\n",
      "Epoch 308/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5316 - accuracy: 0.7383 - val_loss: 0.5927 - val_accuracy: 0.6577\n",
      "Epoch 309/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5359 - accuracy: 0.7416 - val_loss: 0.5884 - val_accuracy: 0.6745\n",
      "Epoch 310/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5120 - accuracy: 0.7483 - val_loss: 0.5792 - val_accuracy: 0.6678\n",
      "Epoch 311/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5018 - accuracy: 0.7517 - val_loss: 0.5859 - val_accuracy: 0.6812\n",
      "Epoch 312/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5073 - accuracy: 0.7450 - val_loss: 0.5821 - val_accuracy: 0.6644\n",
      "Epoch 313/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5098 - accuracy: 0.7483 - val_loss: 0.5839 - val_accuracy: 0.6779\n",
      "Epoch 314/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5039 - accuracy: 0.7483 - val_loss: 0.5739 - val_accuracy: 0.6678\n",
      "Epoch 315/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4982 - accuracy: 0.7517 - val_loss: 0.5779 - val_accuracy: 0.6678\n",
      "Epoch 316/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4986 - accuracy: 0.7550 - val_loss: 0.5747 - val_accuracy: 0.6644\n",
      "Epoch 317/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4958 - accuracy: 0.7517 - val_loss: 0.5754 - val_accuracy: 0.6678\n",
      "Epoch 318/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4970 - accuracy: 0.7517 - val_loss: 0.5709 - val_accuracy: 0.6745\n",
      "Epoch 319/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4951 - accuracy: 0.7450 - val_loss: 0.5714 - val_accuracy: 0.6745\n",
      "Epoch 320/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4956 - accuracy: 0.7550 - val_loss: 0.5694 - val_accuracy: 0.6711\n",
      "Epoch 321/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4973 - accuracy: 0.7416 - val_loss: 0.5778 - val_accuracy: 0.6745\n",
      "Epoch 322/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5039 - accuracy: 0.7550 - val_loss: 0.5739 - val_accuracy: 0.6812\n",
      "Epoch 323/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4960 - accuracy: 0.7483 - val_loss: 0.5749 - val_accuracy: 0.6711\n",
      "Epoch 324/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4965 - accuracy: 0.7517 - val_loss: 0.5747 - val_accuracy: 0.6678\n",
      "Epoch 325/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4979 - accuracy: 0.7550 - val_loss: 0.5693 - val_accuracy: 0.6812\n",
      "Epoch 326/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5057 - accuracy: 0.7517 - val_loss: 0.5700 - val_accuracy: 0.6812\n",
      "Epoch 327/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5001 - accuracy: 0.7483 - val_loss: 0.5713 - val_accuracy: 0.6745\n",
      "Epoch 328/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4975 - accuracy: 0.7450 - val_loss: 0.5750 - val_accuracy: 0.6711\n",
      "Epoch 329/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4975 - accuracy: 0.7517 - val_loss: 0.5694 - val_accuracy: 0.6745\n",
      "Epoch 330/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4982 - accuracy: 0.7517 - val_loss: 0.5707 - val_accuracy: 0.6812\n",
      "Epoch 331/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4951 - accuracy: 0.7483 - val_loss: 0.5736 - val_accuracy: 0.6678\n",
      "Epoch 332/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4947 - accuracy: 0.7483 - val_loss: 0.5757 - val_accuracy: 0.6678\n",
      "Epoch 333/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4931 - accuracy: 0.7617 - val_loss: 0.5681 - val_accuracy: 0.6812\n",
      "Epoch 334/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4963 - accuracy: 0.7483 - val_loss: 0.5850 - val_accuracy: 0.6678\n",
      "Epoch 335/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5120 - accuracy: 0.7483 - val_loss: 0.5855 - val_accuracy: 0.6644\n",
      "Epoch 336/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5001 - accuracy: 0.7517 - val_loss: 0.5853 - val_accuracy: 0.6779\n",
      "Epoch 337/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4942 - accuracy: 0.7517 - val_loss: 0.5801 - val_accuracy: 0.6611\n",
      "Epoch 338/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4938 - accuracy: 0.7550 - val_loss: 0.5731 - val_accuracy: 0.6779\n",
      "Epoch 339/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5013 - accuracy: 0.7450 - val_loss: 0.5701 - val_accuracy: 0.6711\n",
      "Epoch 340/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4968 - accuracy: 0.7517 - val_loss: 0.5802 - val_accuracy: 0.6711\n",
      "Epoch 341/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4943 - accuracy: 0.7517 - val_loss: 0.5695 - val_accuracy: 0.6745\n",
      "Epoch 342/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4967 - accuracy: 0.7450 - val_loss: 0.5802 - val_accuracy: 0.6711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5064 - accuracy: 0.7483 - val_loss: 0.5792 - val_accuracy: 0.6678\n",
      "Epoch 344/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5021 - accuracy: 0.7450 - val_loss: 0.5743 - val_accuracy: 0.6779\n",
      "Epoch 345/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4901 - accuracy: 0.7584 - val_loss: 0.5739 - val_accuracy: 0.6745\n",
      "Epoch 346/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4897 - accuracy: 0.7550 - val_loss: 0.5718 - val_accuracy: 0.6779\n",
      "Epoch 347/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4897 - accuracy: 0.7550 - val_loss: 0.5750 - val_accuracy: 0.6644\n",
      "Epoch 348/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4928 - accuracy: 0.7550 - val_loss: 0.5675 - val_accuracy: 0.6846\n",
      "Epoch 349/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4933 - accuracy: 0.7550 - val_loss: 0.5794 - val_accuracy: 0.6779\n",
      "Epoch 350/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4951 - accuracy: 0.7584 - val_loss: 0.5680 - val_accuracy: 0.6745\n",
      "Epoch 351/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4911 - accuracy: 0.7584 - val_loss: 0.5737 - val_accuracy: 0.6745\n",
      "Epoch 352/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4896 - accuracy: 0.7517 - val_loss: 0.5695 - val_accuracy: 0.6779\n",
      "Epoch 353/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4906 - accuracy: 0.7483 - val_loss: 0.5733 - val_accuracy: 0.6711\n",
      "Epoch 354/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4884 - accuracy: 0.7550 - val_loss: 0.5676 - val_accuracy: 0.6812\n",
      "Epoch 355/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4889 - accuracy: 0.7584 - val_loss: 0.5708 - val_accuracy: 0.6745\n",
      "Epoch 356/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4861 - accuracy: 0.7584 - val_loss: 0.5675 - val_accuracy: 0.6745\n",
      "Epoch 357/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4911 - accuracy: 0.7416 - val_loss: 0.5731 - val_accuracy: 0.6611\n",
      "Epoch 358/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4908 - accuracy: 0.7617 - val_loss: 0.5731 - val_accuracy: 0.6678\n",
      "Epoch 359/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4871 - accuracy: 0.7584 - val_loss: 0.5701 - val_accuracy: 0.6644\n",
      "Epoch 360/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4875 - accuracy: 0.7517 - val_loss: 0.5719 - val_accuracy: 0.6644\n",
      "Epoch 361/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4861 - accuracy: 0.7550 - val_loss: 0.5683 - val_accuracy: 0.6711\n",
      "Epoch 362/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4858 - accuracy: 0.7584 - val_loss: 0.5729 - val_accuracy: 0.6812\n",
      "Epoch 363/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4884 - accuracy: 0.7617 - val_loss: 0.5807 - val_accuracy: 0.6745\n",
      "Epoch 364/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4870 - accuracy: 0.7685 - val_loss: 0.5807 - val_accuracy: 0.6846\n",
      "Epoch 365/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5151 - accuracy: 0.7517 - val_loss: 0.5876 - val_accuracy: 0.6745\n",
      "Epoch 366/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5053 - accuracy: 0.7450 - val_loss: 0.5682 - val_accuracy: 0.6779\n",
      "Epoch 367/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5017 - accuracy: 0.7550 - val_loss: 0.5709 - val_accuracy: 0.6711\n",
      "Epoch 368/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4946 - accuracy: 0.7584 - val_loss: 0.5816 - val_accuracy: 0.6544\n",
      "Epoch 369/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4876 - accuracy: 0.7584 - val_loss: 0.5721 - val_accuracy: 0.6745\n",
      "Epoch 370/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4870 - accuracy: 0.7550 - val_loss: 0.5769 - val_accuracy: 0.6779\n",
      "Epoch 371/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4875 - accuracy: 0.7550 - val_loss: 0.5705 - val_accuracy: 0.6812\n",
      "Epoch 372/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4897 - accuracy: 0.7450 - val_loss: 0.5815 - val_accuracy: 0.6611\n",
      "Epoch 373/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4827 - accuracy: 0.7651 - val_loss: 0.5764 - val_accuracy: 0.6779\n",
      "Epoch 374/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4834 - accuracy: 0.7550 - val_loss: 0.5833 - val_accuracy: 0.6611\n",
      "Epoch 375/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4993 - accuracy: 0.7584 - val_loss: 0.5754 - val_accuracy: 0.6711\n",
      "Epoch 376/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5040 - accuracy: 0.7550 - val_loss: 0.5868 - val_accuracy: 0.6611\n",
      "Epoch 377/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5077 - accuracy: 0.7517 - val_loss: 0.5962 - val_accuracy: 0.6611\n",
      "Epoch 378/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4908 - accuracy: 0.7483 - val_loss: 0.5803 - val_accuracy: 0.6711\n",
      "Epoch 379/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4898 - accuracy: 0.7483 - val_loss: 0.5819 - val_accuracy: 0.6678\n",
      "Epoch 380/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4865 - accuracy: 0.7517 - val_loss: 0.5728 - val_accuracy: 0.6779\n",
      "Epoch 381/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4833 - accuracy: 0.7550 - val_loss: 0.5723 - val_accuracy: 0.6711\n",
      "Epoch 382/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4827 - accuracy: 0.7550 - val_loss: 0.5722 - val_accuracy: 0.6711\n",
      "Epoch 383/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4821 - accuracy: 0.7651 - val_loss: 0.5722 - val_accuracy: 0.6779\n",
      "Epoch 384/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4984 - accuracy: 0.7550 - val_loss: 0.5726 - val_accuracy: 0.6745\n",
      "Epoch 385/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4889 - accuracy: 0.7550 - val_loss: 0.5781 - val_accuracy: 0.6711\n",
      "Epoch 386/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5082 - accuracy: 0.7483 - val_loss: 0.5786 - val_accuracy: 0.6846\n",
      "Epoch 387/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5405 - accuracy: 0.7282 - val_loss: 0.5696 - val_accuracy: 0.6846\n",
      "Epoch 388/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5306 - accuracy: 0.7181 - val_loss: 0.5837 - val_accuracy: 0.6812\n",
      "Epoch 389/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5229 - accuracy: 0.7282 - val_loss: 0.5669 - val_accuracy: 0.6980\n",
      "Epoch 390/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5135 - accuracy: 0.7383 - val_loss: 0.5727 - val_accuracy: 0.6812\n",
      "Epoch 391/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5067 - accuracy: 0.7248 - val_loss: 0.5677 - val_accuracy: 0.6846\n",
      "Epoch 392/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4998 - accuracy: 0.7517 - val_loss: 0.5581 - val_accuracy: 0.6946\n",
      "Epoch 393/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4926 - accuracy: 0.7416 - val_loss: 0.5728 - val_accuracy: 0.6711\n",
      "Epoch 394/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4961 - accuracy: 0.7550 - val_loss: 0.5676 - val_accuracy: 0.6913\n",
      "Epoch 395/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4869 - accuracy: 0.7517 - val_loss: 0.5714 - val_accuracy: 0.6745\n",
      "Epoch 396/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4852 - accuracy: 0.7584 - val_loss: 0.5614 - val_accuracy: 0.6779\n",
      "Epoch 397/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4842 - accuracy: 0.7584 - val_loss: 0.5702 - val_accuracy: 0.6812\n",
      "Epoch 398/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4867 - accuracy: 0.7584 - val_loss: 0.5701 - val_accuracy: 0.6745\n",
      "Epoch 399/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4808 - accuracy: 0.7617 - val_loss: 0.5672 - val_accuracy: 0.6745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4817 - accuracy: 0.7617 - val_loss: 0.5705 - val_accuracy: 0.6779\n",
      "Epoch 401/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4791 - accuracy: 0.7584 - val_loss: 0.5661 - val_accuracy: 0.6913\n",
      "Epoch 402/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4868 - accuracy: 0.7550 - val_loss: 0.5706 - val_accuracy: 0.6711\n",
      "Epoch 403/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4808 - accuracy: 0.7550 - val_loss: 0.5739 - val_accuracy: 0.6678\n",
      "Epoch 404/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4800 - accuracy: 0.7550 - val_loss: 0.5714 - val_accuracy: 0.6711\n",
      "Epoch 405/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4809 - accuracy: 0.7617 - val_loss: 0.5664 - val_accuracy: 0.6846\n",
      "Epoch 406/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4878 - accuracy: 0.7517 - val_loss: 0.5845 - val_accuracy: 0.6745\n",
      "Epoch 407/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5216 - accuracy: 0.7349 - val_loss: 0.5906 - val_accuracy: 0.6644\n",
      "Epoch 408/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4846 - accuracy: 0.7651 - val_loss: 0.5868 - val_accuracy: 0.6644\n",
      "Epoch 409/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4925 - accuracy: 0.7550 - val_loss: 0.6015 - val_accuracy: 0.6711\n",
      "Epoch 410/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4993 - accuracy: 0.7584 - val_loss: 0.5857 - val_accuracy: 0.6779\n",
      "Epoch 411/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5227 - accuracy: 0.7349 - val_loss: 0.5868 - val_accuracy: 0.6678\n",
      "Epoch 412/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5124 - accuracy: 0.7651 - val_loss: 0.5860 - val_accuracy: 0.6779\n",
      "Epoch 413/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4953 - accuracy: 0.7584 - val_loss: 0.5949 - val_accuracy: 0.6644\n",
      "Epoch 414/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4883 - accuracy: 0.7718 - val_loss: 0.5841 - val_accuracy: 0.6779\n",
      "Epoch 415/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4826 - accuracy: 0.7584 - val_loss: 0.5822 - val_accuracy: 0.6678\n",
      "Epoch 416/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4818 - accuracy: 0.7785 - val_loss: 0.5828 - val_accuracy: 0.6779\n",
      "Epoch 417/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4862 - accuracy: 0.7651 - val_loss: 0.5787 - val_accuracy: 0.6577\n",
      "Epoch 418/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4825 - accuracy: 0.7651 - val_loss: 0.5713 - val_accuracy: 0.6779\n",
      "Epoch 419/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4883 - accuracy: 0.7450 - val_loss: 0.5736 - val_accuracy: 0.6846\n",
      "Epoch 420/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4800 - accuracy: 0.7685 - val_loss: 0.5720 - val_accuracy: 0.6812\n",
      "Epoch 421/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4798 - accuracy: 0.7617 - val_loss: 0.5776 - val_accuracy: 0.6745\n",
      "Epoch 422/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4861 - accuracy: 0.7617 - val_loss: 0.5696 - val_accuracy: 0.6879\n",
      "Epoch 423/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4800 - accuracy: 0.7584 - val_loss: 0.5733 - val_accuracy: 0.6745\n",
      "Epoch 424/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4794 - accuracy: 0.7651 - val_loss: 0.5714 - val_accuracy: 0.6779\n",
      "Epoch 425/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4850 - accuracy: 0.7550 - val_loss: 0.5795 - val_accuracy: 0.6611\n",
      "Epoch 426/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4793 - accuracy: 0.7617 - val_loss: 0.5692 - val_accuracy: 0.6913\n",
      "Epoch 427/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4774 - accuracy: 0.7617 - val_loss: 0.5712 - val_accuracy: 0.6812\n",
      "Epoch 428/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4764 - accuracy: 0.7584 - val_loss: 0.5761 - val_accuracy: 0.6745\n",
      "Epoch 429/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4745 - accuracy: 0.7685 - val_loss: 0.5712 - val_accuracy: 0.6846\n",
      "Epoch 430/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4873 - accuracy: 0.7617 - val_loss: 0.5676 - val_accuracy: 0.6812\n",
      "Epoch 431/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4731 - accuracy: 0.7651 - val_loss: 0.5803 - val_accuracy: 0.6779\n",
      "Epoch 432/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4829 - accuracy: 0.7718 - val_loss: 0.5883 - val_accuracy: 0.6711\n",
      "Epoch 433/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5015 - accuracy: 0.7483 - val_loss: 0.5708 - val_accuracy: 0.6846\n",
      "Epoch 434/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4787 - accuracy: 0.7718 - val_loss: 0.5735 - val_accuracy: 0.6779\n",
      "Epoch 435/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4766 - accuracy: 0.7617 - val_loss: 0.5721 - val_accuracy: 0.6812\n",
      "Epoch 436/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4755 - accuracy: 0.7617 - val_loss: 0.5693 - val_accuracy: 0.6812\n",
      "Epoch 437/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4759 - accuracy: 0.7617 - val_loss: 0.5691 - val_accuracy: 0.6846\n",
      "Epoch 438/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4786 - accuracy: 0.7617 - val_loss: 0.5742 - val_accuracy: 0.6779\n",
      "Epoch 439/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4768 - accuracy: 0.7651 - val_loss: 0.5742 - val_accuracy: 0.6846\n",
      "Epoch 440/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4834 - accuracy: 0.7584 - val_loss: 0.5848 - val_accuracy: 0.6846\n",
      "Epoch 441/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4976 - accuracy: 0.7450 - val_loss: 0.5699 - val_accuracy: 0.6812\n",
      "Epoch 442/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4747 - accuracy: 0.7685 - val_loss: 0.5674 - val_accuracy: 0.6846\n",
      "Epoch 443/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4779 - accuracy: 0.7651 - val_loss: 0.5748 - val_accuracy: 0.6779\n",
      "Epoch 444/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4743 - accuracy: 0.7685 - val_loss: 0.5718 - val_accuracy: 0.6846\n",
      "Epoch 445/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4856 - accuracy: 0.7584 - val_loss: 0.5762 - val_accuracy: 0.6745\n",
      "Epoch 446/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4798 - accuracy: 0.7550 - val_loss: 0.5753 - val_accuracy: 0.6711\n",
      "Epoch 447/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4843 - accuracy: 0.7651 - val_loss: 0.5770 - val_accuracy: 0.6745\n",
      "Epoch 448/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4791 - accuracy: 0.7550 - val_loss: 0.5681 - val_accuracy: 0.6913\n",
      "Epoch 449/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4710 - accuracy: 0.7651 - val_loss: 0.5825 - val_accuracy: 0.6711\n",
      "Epoch 450/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4788 - accuracy: 0.7617 - val_loss: 0.5745 - val_accuracy: 0.6879\n",
      "Epoch 451/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4839 - accuracy: 0.7550 - val_loss: 0.5751 - val_accuracy: 0.6711\n",
      "Epoch 452/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4778 - accuracy: 0.7685 - val_loss: 0.5735 - val_accuracy: 0.6812\n",
      "Epoch 453/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4749 - accuracy: 0.7617 - val_loss: 0.5741 - val_accuracy: 0.6846\n",
      "Epoch 454/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4734 - accuracy: 0.7685 - val_loss: 0.5753 - val_accuracy: 0.6812\n",
      "Epoch 455/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4786 - accuracy: 0.7550 - val_loss: 0.5770 - val_accuracy: 0.6779\n",
      "Epoch 456/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4705 - accuracy: 0.7685 - val_loss: 0.5712 - val_accuracy: 0.6879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4805 - accuracy: 0.7651 - val_loss: 0.5694 - val_accuracy: 0.7013\n",
      "Epoch 458/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4768 - accuracy: 0.7651 - val_loss: 0.5758 - val_accuracy: 0.6812\n",
      "Epoch 459/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4774 - accuracy: 0.7517 - val_loss: 0.5784 - val_accuracy: 0.6846\n",
      "Epoch 460/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4753 - accuracy: 0.7550 - val_loss: 0.5677 - val_accuracy: 0.6946\n",
      "Epoch 461/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4854 - accuracy: 0.7517 - val_loss: 0.5679 - val_accuracy: 0.7013\n",
      "Epoch 462/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4718 - accuracy: 0.7651 - val_loss: 0.5771 - val_accuracy: 0.6678\n",
      "Epoch 463/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4761 - accuracy: 0.7617 - val_loss: 0.5727 - val_accuracy: 0.6846\n",
      "Epoch 464/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4734 - accuracy: 0.7651 - val_loss: 0.5818 - val_accuracy: 0.6779\n",
      "Epoch 465/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5107 - accuracy: 0.7483 - val_loss: 0.6367 - val_accuracy: 0.6510\n",
      "Epoch 466/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5022 - accuracy: 0.7517 - val_loss: 0.5922 - val_accuracy: 0.6678\n",
      "Epoch 467/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4943 - accuracy: 0.7517 - val_loss: 0.5807 - val_accuracy: 0.6711\n",
      "Epoch 468/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4792 - accuracy: 0.7584 - val_loss: 0.5740 - val_accuracy: 0.6846\n",
      "Epoch 469/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4700 - accuracy: 0.7718 - val_loss: 0.5725 - val_accuracy: 0.6711\n",
      "Epoch 470/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4700 - accuracy: 0.7752 - val_loss: 0.5713 - val_accuracy: 0.6779\n",
      "Epoch 471/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4728 - accuracy: 0.7584 - val_loss: 0.5757 - val_accuracy: 0.6745\n",
      "Epoch 472/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4945 - accuracy: 0.7550 - val_loss: 0.5796 - val_accuracy: 0.6846\n",
      "Epoch 473/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4746 - accuracy: 0.7651 - val_loss: 0.5698 - val_accuracy: 0.6913\n",
      "Epoch 474/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4693 - accuracy: 0.7685 - val_loss: 0.5747 - val_accuracy: 0.6846\n",
      "Epoch 475/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4680 - accuracy: 0.7685 - val_loss: 0.5698 - val_accuracy: 0.6846\n",
      "Epoch 476/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4730 - accuracy: 0.7617 - val_loss: 0.5789 - val_accuracy: 0.6678\n",
      "Epoch 477/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4664 - accuracy: 0.7685 - val_loss: 0.5689 - val_accuracy: 0.6879\n",
      "Epoch 478/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4743 - accuracy: 0.7752 - val_loss: 0.5799 - val_accuracy: 0.6779\n",
      "Epoch 479/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4754 - accuracy: 0.7584 - val_loss: 0.5787 - val_accuracy: 0.6745\n",
      "Epoch 480/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4713 - accuracy: 0.7617 - val_loss: 0.5720 - val_accuracy: 0.6913\n",
      "Epoch 481/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4652 - accuracy: 0.7718 - val_loss: 0.5719 - val_accuracy: 0.6913\n",
      "Epoch 482/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4706 - accuracy: 0.7718 - val_loss: 0.5746 - val_accuracy: 0.6879\n",
      "Epoch 483/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4700 - accuracy: 0.7718 - val_loss: 0.5755 - val_accuracy: 0.6846\n",
      "Epoch 484/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4703 - accuracy: 0.7651 - val_loss: 0.5743 - val_accuracy: 0.6846\n",
      "Epoch 485/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4675 - accuracy: 0.7718 - val_loss: 0.5791 - val_accuracy: 0.6745\n",
      "Epoch 486/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4697 - accuracy: 0.7785 - val_loss: 0.5753 - val_accuracy: 0.6846\n",
      "Epoch 487/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4684 - accuracy: 0.7718 - val_loss: 0.5722 - val_accuracy: 0.6879\n",
      "Epoch 488/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4689 - accuracy: 0.7718 - val_loss: 0.5809 - val_accuracy: 0.6846\n",
      "Epoch 489/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4680 - accuracy: 0.7752 - val_loss: 0.5686 - val_accuracy: 0.6946\n",
      "Epoch 490/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4707 - accuracy: 0.7752 - val_loss: 0.5691 - val_accuracy: 0.7013\n",
      "Epoch 491/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4661 - accuracy: 0.7819 - val_loss: 0.5757 - val_accuracy: 0.6779\n",
      "Epoch 492/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4648 - accuracy: 0.7718 - val_loss: 0.5738 - val_accuracy: 0.6846\n",
      "Epoch 493/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4780 - accuracy: 0.7685 - val_loss: 0.5717 - val_accuracy: 0.6946\n",
      "Epoch 494/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4698 - accuracy: 0.7752 - val_loss: 0.5822 - val_accuracy: 0.6779\n",
      "Epoch 495/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4644 - accuracy: 0.7752 - val_loss: 0.5693 - val_accuracy: 0.6913\n",
      "Epoch 496/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4720 - accuracy: 0.7718 - val_loss: 0.5695 - val_accuracy: 0.6946\n",
      "Epoch 497/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4722 - accuracy: 0.7752 - val_loss: 0.5668 - val_accuracy: 0.6913\n",
      "Epoch 498/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4652 - accuracy: 0.7752 - val_loss: 0.5833 - val_accuracy: 0.6577\n",
      "Epoch 499/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4640 - accuracy: 0.7785 - val_loss: 0.5749 - val_accuracy: 0.6745\n",
      "Epoch 500/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4678 - accuracy: 0.7752 - val_loss: 0.5863 - val_accuracy: 0.6644\n",
      "Epoch 501/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4777 - accuracy: 0.7651 - val_loss: 0.5727 - val_accuracy: 0.6779\n",
      "Epoch 502/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4682 - accuracy: 0.7651 - val_loss: 0.5764 - val_accuracy: 0.6745\n",
      "Epoch 503/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4599 - accuracy: 0.7852 - val_loss: 0.5705 - val_accuracy: 0.6779\n",
      "Epoch 504/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4658 - accuracy: 0.7819 - val_loss: 0.5725 - val_accuracy: 0.6812\n",
      "Epoch 505/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4650 - accuracy: 0.7886 - val_loss: 0.5720 - val_accuracy: 0.6846\n",
      "Epoch 506/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4612 - accuracy: 0.7752 - val_loss: 0.5747 - val_accuracy: 0.6846\n",
      "Epoch 507/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4627 - accuracy: 0.7852 - val_loss: 0.5713 - val_accuracy: 0.6812\n",
      "Epoch 508/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4693 - accuracy: 0.7819 - val_loss: 0.5703 - val_accuracy: 0.6846\n",
      "Epoch 509/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4652 - accuracy: 0.7953 - val_loss: 0.5742 - val_accuracy: 0.6879\n",
      "Epoch 510/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4697 - accuracy: 0.7752 - val_loss: 0.5781 - val_accuracy: 0.6745\n",
      "Epoch 511/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4702 - accuracy: 0.7785 - val_loss: 0.5769 - val_accuracy: 0.6846\n",
      "Epoch 512/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4644 - accuracy: 0.7886 - val_loss: 0.5793 - val_accuracy: 0.6779\n",
      "Epoch 513/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4626 - accuracy: 0.7752 - val_loss: 0.5756 - val_accuracy: 0.6812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4610 - accuracy: 0.7718 - val_loss: 0.5727 - val_accuracy: 0.6846\n",
      "Epoch 515/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4616 - accuracy: 0.7785 - val_loss: 0.5697 - val_accuracy: 0.6812\n",
      "Epoch 516/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4687 - accuracy: 0.7718 - val_loss: 0.5804 - val_accuracy: 0.6711\n",
      "Epoch 517/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4646 - accuracy: 0.7785 - val_loss: 0.5756 - val_accuracy: 0.6812\n",
      "Epoch 518/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4600 - accuracy: 0.7852 - val_loss: 0.5689 - val_accuracy: 0.6812\n",
      "Epoch 519/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4685 - accuracy: 0.7785 - val_loss: 0.5684 - val_accuracy: 0.6711\n",
      "Epoch 520/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4683 - accuracy: 0.7819 - val_loss: 0.5770 - val_accuracy: 0.6711\n",
      "Epoch 521/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4623 - accuracy: 0.7852 - val_loss: 0.5681 - val_accuracy: 0.6745\n",
      "Epoch 522/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4656 - accuracy: 0.7718 - val_loss: 0.5851 - val_accuracy: 0.6779\n",
      "Epoch 523/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4625 - accuracy: 0.7752 - val_loss: 0.5718 - val_accuracy: 0.6846\n",
      "Epoch 524/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4589 - accuracy: 0.7919 - val_loss: 0.5711 - val_accuracy: 0.6779\n",
      "Epoch 525/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4628 - accuracy: 0.7886 - val_loss: 0.5775 - val_accuracy: 0.6779\n",
      "Epoch 526/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4646 - accuracy: 0.7886 - val_loss: 0.5747 - val_accuracy: 0.6779\n",
      "Epoch 527/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4608 - accuracy: 0.7852 - val_loss: 0.5698 - val_accuracy: 0.6812\n",
      "Epoch 528/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4610 - accuracy: 0.7886 - val_loss: 0.5735 - val_accuracy: 0.6745\n",
      "Epoch 529/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5046 - accuracy: 0.7617 - val_loss: 0.5794 - val_accuracy: 0.6846\n",
      "Epoch 530/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4819 - accuracy: 0.7617 - val_loss: 0.6047 - val_accuracy: 0.6644\n",
      "Epoch 531/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4625 - accuracy: 0.7819 - val_loss: 0.5819 - val_accuracy: 0.6879\n",
      "Epoch 532/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4745 - accuracy: 0.7584 - val_loss: 0.6041 - val_accuracy: 0.6678\n",
      "Epoch 533/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4884 - accuracy: 0.7651 - val_loss: 0.5780 - val_accuracy: 0.6711\n",
      "Epoch 534/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4624 - accuracy: 0.7852 - val_loss: 0.5757 - val_accuracy: 0.6846\n",
      "Epoch 535/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4694 - accuracy: 0.7819 - val_loss: 0.5861 - val_accuracy: 0.6779\n",
      "Epoch 536/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4566 - accuracy: 0.7886 - val_loss: 0.5766 - val_accuracy: 0.6879\n",
      "Epoch 537/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4629 - accuracy: 0.7819 - val_loss: 0.5824 - val_accuracy: 0.6745\n",
      "Epoch 538/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4775 - accuracy: 0.7718 - val_loss: 0.5893 - val_accuracy: 0.6644\n",
      "Epoch 539/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4666 - accuracy: 0.7819 - val_loss: 0.5804 - val_accuracy: 0.6711\n",
      "Epoch 540/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4659 - accuracy: 0.7819 - val_loss: 0.5906 - val_accuracy: 0.6678\n",
      "Epoch 541/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4656 - accuracy: 0.7752 - val_loss: 0.5730 - val_accuracy: 0.6745\n",
      "Epoch 542/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4573 - accuracy: 0.7919 - val_loss: 0.5742 - val_accuracy: 0.6846\n",
      "Epoch 543/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4588 - accuracy: 0.7919 - val_loss: 0.5707 - val_accuracy: 0.6812\n",
      "Epoch 544/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4697 - accuracy: 0.7819 - val_loss: 0.5860 - val_accuracy: 0.6711\n",
      "Epoch 545/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4609 - accuracy: 0.7987 - val_loss: 0.5753 - val_accuracy: 0.6812\n",
      "Epoch 546/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4593 - accuracy: 0.7852 - val_loss: 0.5781 - val_accuracy: 0.6779\n",
      "Epoch 547/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4560 - accuracy: 0.7919 - val_loss: 0.5763 - val_accuracy: 0.6745\n",
      "Epoch 548/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4584 - accuracy: 0.7785 - val_loss: 0.5801 - val_accuracy: 0.6779\n",
      "Epoch 549/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4565 - accuracy: 0.7819 - val_loss: 0.5781 - val_accuracy: 0.6745\n",
      "Epoch 550/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4580 - accuracy: 0.7852 - val_loss: 0.5832 - val_accuracy: 0.6745\n",
      "Epoch 551/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4585 - accuracy: 0.7852 - val_loss: 0.5770 - val_accuracy: 0.6745\n",
      "Epoch 552/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4585 - accuracy: 0.7752 - val_loss: 0.5766 - val_accuracy: 0.6812\n",
      "Epoch 553/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4586 - accuracy: 0.7785 - val_loss: 0.5778 - val_accuracy: 0.6812\n",
      "Epoch 554/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4553 - accuracy: 0.7852 - val_loss: 0.5864 - val_accuracy: 0.6644\n",
      "Epoch 555/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4594 - accuracy: 0.7819 - val_loss: 0.5909 - val_accuracy: 0.6544\n",
      "Epoch 556/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4579 - accuracy: 0.7819 - val_loss: 0.5782 - val_accuracy: 0.6711\n",
      "Epoch 557/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4581 - accuracy: 0.7886 - val_loss: 0.5788 - val_accuracy: 0.6745\n",
      "Epoch 558/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4540 - accuracy: 0.7852 - val_loss: 0.5788 - val_accuracy: 0.6846\n",
      "Epoch 559/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4541 - accuracy: 0.7886 - val_loss: 0.5783 - val_accuracy: 0.6879\n",
      "Epoch 560/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4580 - accuracy: 0.7852 - val_loss: 0.5857 - val_accuracy: 0.6711\n",
      "Epoch 561/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4587 - accuracy: 0.7919 - val_loss: 0.5894 - val_accuracy: 0.6644\n",
      "Epoch 562/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4515 - accuracy: 0.7852 - val_loss: 0.5766 - val_accuracy: 0.6879\n",
      "Epoch 563/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4621 - accuracy: 0.7852 - val_loss: 0.5840 - val_accuracy: 0.6779\n",
      "Epoch 564/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4528 - accuracy: 0.7852 - val_loss: 0.5821 - val_accuracy: 0.6812\n",
      "Epoch 565/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4522 - accuracy: 0.7852 - val_loss: 0.5787 - val_accuracy: 0.6745\n",
      "Epoch 566/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4581 - accuracy: 0.7852 - val_loss: 0.5782 - val_accuracy: 0.6846\n",
      "Epoch 567/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4562 - accuracy: 0.7819 - val_loss: 0.5813 - val_accuracy: 0.6711\n",
      "Epoch 568/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4574 - accuracy: 0.7819 - val_loss: 0.5831 - val_accuracy: 0.6812\n",
      "Epoch 569/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4516 - accuracy: 0.7886 - val_loss: 0.5831 - val_accuracy: 0.6745\n",
      "Epoch 570/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4527 - accuracy: 0.7819 - val_loss: 0.5793 - val_accuracy: 0.6846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4508 - accuracy: 0.7819 - val_loss: 0.5889 - val_accuracy: 0.6779\n",
      "Epoch 572/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4592 - accuracy: 0.7852 - val_loss: 0.5841 - val_accuracy: 0.6745\n",
      "Epoch 573/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4522 - accuracy: 0.7852 - val_loss: 0.5928 - val_accuracy: 0.6577\n",
      "Epoch 574/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4520 - accuracy: 0.7819 - val_loss: 0.5803 - val_accuracy: 0.6779\n",
      "Epoch 575/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4519 - accuracy: 0.7886 - val_loss: 0.5808 - val_accuracy: 0.6812\n",
      "Epoch 576/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4508 - accuracy: 0.7886 - val_loss: 0.5871 - val_accuracy: 0.6812\n",
      "Epoch 577/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4510 - accuracy: 0.7919 - val_loss: 0.5801 - val_accuracy: 0.6846\n",
      "Epoch 578/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4565 - accuracy: 0.7819 - val_loss: 0.5815 - val_accuracy: 0.6812\n",
      "Epoch 579/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4575 - accuracy: 0.7819 - val_loss: 0.5879 - val_accuracy: 0.6678\n",
      "Epoch 580/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4513 - accuracy: 0.7886 - val_loss: 0.5833 - val_accuracy: 0.6711\n",
      "Epoch 581/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4527 - accuracy: 0.7886 - val_loss: 0.5868 - val_accuracy: 0.6678\n",
      "Epoch 582/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4500 - accuracy: 0.7919 - val_loss: 0.5765 - val_accuracy: 0.6846\n",
      "Epoch 583/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4595 - accuracy: 0.7886 - val_loss: 0.5837 - val_accuracy: 0.6812\n",
      "Epoch 584/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4560 - accuracy: 0.7953 - val_loss: 0.5792 - val_accuracy: 0.6779\n",
      "Epoch 585/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4524 - accuracy: 0.7953 - val_loss: 0.5849 - val_accuracy: 0.6745\n",
      "Epoch 586/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4518 - accuracy: 0.7819 - val_loss: 0.5838 - val_accuracy: 0.6779\n",
      "Epoch 587/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4518 - accuracy: 0.7987 - val_loss: 0.5894 - val_accuracy: 0.6711\n",
      "Epoch 588/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4501 - accuracy: 0.7953 - val_loss: 0.5923 - val_accuracy: 0.6779\n",
      "Epoch 589/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4518 - accuracy: 0.7953 - val_loss: 0.5936 - val_accuracy: 0.6745\n",
      "Epoch 590/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4535 - accuracy: 0.7919 - val_loss: 0.5911 - val_accuracy: 0.6711\n",
      "Epoch 591/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4481 - accuracy: 0.7919 - val_loss: 0.5840 - val_accuracy: 0.6812\n",
      "Epoch 592/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4539 - accuracy: 0.7852 - val_loss: 0.5970 - val_accuracy: 0.6611\n",
      "Epoch 593/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4492 - accuracy: 0.7953 - val_loss: 0.5805 - val_accuracy: 0.6913\n",
      "Epoch 594/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4510 - accuracy: 0.7886 - val_loss: 0.5910 - val_accuracy: 0.6779\n",
      "Epoch 595/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4528 - accuracy: 0.7953 - val_loss: 0.5947 - val_accuracy: 0.6745\n",
      "Epoch 596/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4515 - accuracy: 0.7987 - val_loss: 0.5959 - val_accuracy: 0.6678\n",
      "Epoch 597/600\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4556 - accuracy: 0.7987 - val_loss: 0.5998 - val_accuracy: 0.6846\n",
      "Epoch 598/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4536 - accuracy: 0.7819 - val_loss: 0.5946 - val_accuracy: 0.6779\n",
      "Epoch 599/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4504 - accuracy: 0.7987 - val_loss: 0.5881 - val_accuracy: 0.6711\n",
      "Epoch 600/600\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4570 - accuracy: 0.7886 - val_loss: 0.5955 - val_accuracy: 0.6644\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd7129304c0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filename = 'p_lin_100.csv'\n",
    "#filename1 = 'p_circ_100.csv'\n",
    "\n",
    "# train the LSTM\n",
    "\n",
    "batch_x_train = []\n",
    "batch_y_train = []\n",
    "\n",
    "df_1 = pd.read_csv('pr_lin_100.csv')\n",
    "\n",
    "for index, rows in df_1.iterrows():\n",
    "    batch_y_train.append(0)\n",
    "    list_1 = rows\n",
    "    batch_x_train.append(list_1)\n",
    "    \n",
    "df_2 = pd.read_csv('pr_circ_100.csv')            \n",
    "\n",
    "for index, rows in df_2.iterrows():\n",
    "    batch_y_train.append(1)\n",
    "    list_2 = rows\n",
    "    batch_x_train.append(list_2)\n",
    "\n",
    "\n",
    "#batch_x_train = tf.keras.utils.to_categorical(batch_x_train) #turn this into a tensor not categorical\n",
    "batch_x_train = tf.convert_to_tensor(batch_x_train, dtype=tf.float32) \n",
    "#batch_x_train = np.asarray(batch_x_train, dtype=object)\n",
    "batch_y_train = tf.keras.utils.to_categorical(batch_y_train)\n",
    "batch_y_test = batch_y_train\n",
    "\n",
    "batch_x_test = []\n",
    "\n",
    "df_3 = pd.read_csv('pt_lin_100.csv')\n",
    "\n",
    "for index, rows in df_3.iterrows():\n",
    "    list_3 = rows\n",
    "    batch_x_test.append(list_3)\n",
    "    \n",
    "df_4 = pd.read_csv('pt_circ_100.csv')\n",
    "for index, rows in df_4.iterrows():\n",
    "    list_4 = rows\n",
    "    batch_x_test.append(list_4)\n",
    "    \n",
    "batch_x_test = tf.convert_to_tensor(batch_x_test, dtype=tf.float32)\n",
    "\n",
    "lr = 2e-3\n",
    "num_nodes = 4\n",
    "num_classes = 2\n",
    "num_epochs = 600\n",
    "timesteps = 1\n",
    "tf.keras.backend.clear_session()\n",
    "X = tf.keras.Input(name='X', shape=[batch_x_train.shape[1],1], dtype=tf.dtypes.float32)\n",
    "lstm_output = tf.keras.layers.LSTM(num_nodes)(X)\n",
    "prediction = tf.keras.layers.Dense(num_classes, activation=tf.keras.activations.softmax)(lstm_output)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "model = keras.Model(inputs=X, outputs=prediction)\n",
    "model.compile(optimizer=opt, loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False), metrics=['accuracy'])\n",
    "model.fit(x=batch_x_train, y=batch_y_train, epochs=num_epochs, validation_data=(batch_x_test, batch_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "295bf767",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x_test = []\n",
    "\n",
    "df_3 = pd.read_csv('pt_lin_100.csv')\n",
    "\n",
    "for index, rows in df_3.iterrows():\n",
    "    list_3 = rows\n",
    "    batch_x_test.append(list_3)\n",
    "    \n",
    "df_4 = pd.read_csv('pt_circ_100.csv')\n",
    "for index, rows in df_4.iterrows():\n",
    "    list_4 = rows\n",
    "    batch_x_test.append(list_4)\n",
    "    \n",
    "batch_x_test = tf.convert_to_tensor(batch_x_test, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c66b72d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x_test = []\n",
    "\n",
    "rows_to_keep = [150,299]\n",
    "df_3 = pd.read_csv('np_t_lin_100.csv',skiprows= lambda x: x not in rows_to_keep, usecols=range(71))\n",
    "\n",
    "for index, rows in df_3.iterrows():\n",
    "    list_3 = rows\n",
    "    batch_x_test.append(list_3)\n",
    "    \n",
    "df_4 = pd.read_csv('np_t_circ_100.csv',nrows=[150:149], usecols=range(71))\n",
    "for index, rows in df_4.iterrows():\n",
    "    list_4 = rows\n",
    "    batch_x_test.append(list_4)\n",
    "    \n",
    "#batch_x_train = tf.keras.utils.to_categorical(batch_x_train) #turn this into a tensor not categorical\n",
    "batch_x_test = tf.convert_to_tensor(batch_x_test, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0530b148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 3ms/step\n",
      "tf.Tensor(\n",
      "[[ 75  74]\n",
      " [ 26 123]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "y_prediction = model.predict(batch_x_test)\n",
    "y_prediction = np.argmax(y_prediction, axis=1)\n",
    "y_test = np.argmax(batch_y_test, axis=1)\n",
    "result = tf.math.confusion_matrix(y_test, y_prediction, num_classes=2, weights=None)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa4f0734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = [\"linear\", \"circular\"]\n",
    "cm = confusion_matrix(y_test, y_prediction)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "51d83cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-25.08594</th>\n",
       "      <th>-21.91016</th>\n",
       "      <th>-6.261719</th>\n",
       "      <th>-42.9375</th>\n",
       "      <th>-92.32422</th>\n",
       "      <th>-88.90234</th>\n",
       "      <th>-79.36719</th>\n",
       "      <th>-107.4844</th>\n",
       "      <th>-102.5938</th>\n",
       "      <th>-93.30078</th>\n",
       "      <th>...</th>\n",
       "      <th>-57.36328</th>\n",
       "      <th>-23.375</th>\n",
       "      <th>-3.082031</th>\n",
       "      <th>-8.949219</th>\n",
       "      <th>14.27734</th>\n",
       "      <th>-4.792969</th>\n",
       "      <th>-7.484375</th>\n",
       "      <th>14.27734.1</th>\n",
       "      <th>-5.527344</th>\n",
       "      <th>7.1875</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows  71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [-25.08594, -21.91016, -6.261719, -42.9375, -92.32422, -88.90234, -79.36719, -107.4844, -102.5938, -93.30078, -91.58984, -101.125, -97.21484, -91.10156, -85.23438, -94.52344, -120.6875, -133.8906, -107.4844.1, -118.2422, -99.41406, -110.6602, -113.5977, -75.94141, -86.70312, -75.94141.1, -93.30078.1, -86.21094, -92.32422.1, -79.36719.1, -85.72266, -99.17188, -100.1484, -89.63672, -102.5938.1, -99.90234, -93.79297, -80.83203, -78.87891, -65.67578, -79.60938, -84.25781, -96.23828, -90.36719, -113.5977.1, -132.668, -113.5977.2, -94.52344.1, -110.1719, -127.7773, -89.39062, -99.66016, -93.30078.2, -86.21094.1, -109.6836, -134.3789, -106.0156, -116.7734, -129.4883, -138.7812, -103.3281, -57.36328, -23.375, -3.082031, -8.949219, 14.27734, -4.792969, -7.484375, 14.27734.1, -5.527344, 7.1875]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 71 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e975d708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n"
     ]
    }
   ],
   "source": [
    "print(batch_x_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f393fbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x_train = []\n",
    "batch_y_train = []\n",
    "\n",
    "df_1 = pd.read_csv('p_lin_100.csv')\n",
    "\n",
    "for index, rows in df_1.iterrows():\n",
    "    batch_y_train.append(0)\n",
    "    list_1 = rows\n",
    "    batch_x_train.append(list_1)\n",
    "    \n",
    "df_2 = pd.read_csv('p_circ_100.csv')            \n",
    "\n",
    "for index, rows in df_2.iterrows():\n",
    "    batch_y_train.append(1)\n",
    "    list_2 = rows\n",
    "    batch_x_train.append(list_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6befe7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_y_train = tf.keras.utils.to_categorical(batch_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d1c6c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('PR_LSTM.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cb02beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('PR_LSTM.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fad454",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
