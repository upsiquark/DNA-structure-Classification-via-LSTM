{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55837807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as pl\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.optimize as spo\n",
    "import pandas as pd\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "429f991d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/350\n",
      "10/10 [==============================] - 2s 64ms/step - loss: 0.7108 - accuracy: 0.4765 - val_loss: 0.6886 - val_accuracy: 0.5503\n",
      "Epoch 2/350\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.7038 - accuracy: 0.4899 - val_loss: 0.6838 - val_accuracy: 0.5436\n",
      "Epoch 3/350\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.6970 - accuracy: 0.4832 - val_loss: 0.6807 - val_accuracy: 0.5302\n",
      "Epoch 4/350\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.6913 - accuracy: 0.4933 - val_loss: 0.6777 - val_accuracy: 0.5336\n",
      "Epoch 5/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.6861 - accuracy: 0.5067 - val_loss: 0.6745 - val_accuracy: 0.5336\n",
      "Epoch 6/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.6804 - accuracy: 0.5201 - val_loss: 0.6717 - val_accuracy: 0.5369\n",
      "Epoch 7/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.6756 - accuracy: 0.5436 - val_loss: 0.6700 - val_accuracy: 0.5503\n",
      "Epoch 8/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.6721 - accuracy: 0.5537 - val_loss: 0.6692 - val_accuracy: 0.5570\n",
      "Epoch 9/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.6695 - accuracy: 0.5638 - val_loss: 0.6680 - val_accuracy: 0.5537\n",
      "Epoch 10/350\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.6670 - accuracy: 0.5772 - val_loss: 0.6668 - val_accuracy: 0.5738\n",
      "Epoch 11/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.6645 - accuracy: 0.6074 - val_loss: 0.6661 - val_accuracy: 0.6007\n",
      "Epoch 12/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.6621 - accuracy: 0.6342 - val_loss: 0.6636 - val_accuracy: 0.6040\n",
      "Epoch 13/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.6595 - accuracy: 0.6510 - val_loss: 0.6621 - val_accuracy: 0.6174\n",
      "Epoch 14/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.6568 - accuracy: 0.6544 - val_loss: 0.6601 - val_accuracy: 0.6174\n",
      "Epoch 15/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.6544 - accuracy: 0.6544 - val_loss: 0.6582 - val_accuracy: 0.6141\n",
      "Epoch 16/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.6519 - accuracy: 0.6611 - val_loss: 0.6558 - val_accuracy: 0.6208\n",
      "Epoch 17/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.6491 - accuracy: 0.6611 - val_loss: 0.6537 - val_accuracy: 0.6342\n",
      "Epoch 18/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.6461 - accuracy: 0.6678 - val_loss: 0.6513 - val_accuracy: 0.6342\n",
      "Epoch 19/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.6426 - accuracy: 0.6711 - val_loss: 0.6466 - val_accuracy: 0.6779\n",
      "Epoch 20/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.6377 - accuracy: 0.6846 - val_loss: 0.6377 - val_accuracy: 0.7047\n",
      "Epoch 21/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.6321 - accuracy: 0.6913 - val_loss: 0.6192 - val_accuracy: 0.7450\n",
      "Epoch 22/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.6370 - accuracy: 0.6879 - val_loss: 0.6266 - val_accuracy: 0.7315\n",
      "Epoch 23/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.6262 - accuracy: 0.7013 - val_loss: 0.6124 - val_accuracy: 0.7383\n",
      "Epoch 24/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.6348 - accuracy: 0.6846 - val_loss: 0.6245 - val_accuracy: 0.7148\n",
      "Epoch 25/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.6233 - accuracy: 0.6745 - val_loss: 0.6371 - val_accuracy: 0.6980\n",
      "Epoch 26/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.6269 - accuracy: 0.6745 - val_loss: 0.6392 - val_accuracy: 0.7013\n",
      "Epoch 27/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.6254 - accuracy: 0.6711 - val_loss: 0.6391 - val_accuracy: 0.6946\n",
      "Epoch 28/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.6238 - accuracy: 0.6745 - val_loss: 0.6372 - val_accuracy: 0.6980\n",
      "Epoch 29/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.6223 - accuracy: 0.6779 - val_loss: 0.6355 - val_accuracy: 0.6980\n",
      "Epoch 30/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.6205 - accuracy: 0.6779 - val_loss: 0.6342 - val_accuracy: 0.7047\n",
      "Epoch 31/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.6186 - accuracy: 0.6779 - val_loss: 0.6311 - val_accuracy: 0.6980\n",
      "Epoch 32/350\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.6160 - accuracy: 0.6812 - val_loss: 0.6288 - val_accuracy: 0.7081\n",
      "Epoch 33/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.6141 - accuracy: 0.6745 - val_loss: 0.6270 - val_accuracy: 0.7114\n",
      "Epoch 34/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.6108 - accuracy: 0.6779 - val_loss: 0.6238 - val_accuracy: 0.7315\n",
      "Epoch 35/350\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.6080 - accuracy: 0.6812 - val_loss: 0.6206 - val_accuracy: 0.7282\n",
      "Epoch 36/350\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.6049 - accuracy: 0.6779 - val_loss: 0.6167 - val_accuracy: 0.7148\n",
      "Epoch 37/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.6020 - accuracy: 0.6946 - val_loss: 0.6147 - val_accuracy: 0.7349\n",
      "Epoch 38/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5990 - accuracy: 0.6913 - val_loss: 0.6096 - val_accuracy: 0.7349\n",
      "Epoch 39/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5963 - accuracy: 0.7013 - val_loss: 0.6088 - val_accuracy: 0.7483\n",
      "Epoch 40/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5927 - accuracy: 0.7047 - val_loss: 0.6002 - val_accuracy: 0.7416\n",
      "Epoch 41/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5894 - accuracy: 0.7013 - val_loss: 0.5888 - val_accuracy: 0.7550\n",
      "Epoch 42/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5855 - accuracy: 0.6946 - val_loss: 0.5835 - val_accuracy: 0.7752\n",
      "Epoch 43/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5800 - accuracy: 0.7047 - val_loss: 0.5834 - val_accuracy: 0.7752\n",
      "Epoch 44/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5765 - accuracy: 0.7081 - val_loss: 0.5774 - val_accuracy: 0.7752\n",
      "Epoch 45/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5736 - accuracy: 0.7215 - val_loss: 0.5709 - val_accuracy: 0.7852\n",
      "Epoch 46/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5708 - accuracy: 0.7248 - val_loss: 0.5661 - val_accuracy: 0.7752\n",
      "Epoch 47/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5692 - accuracy: 0.7215 - val_loss: 0.5626 - val_accuracy: 0.7886\n",
      "Epoch 48/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5697 - accuracy: 0.7114 - val_loss: 0.5437 - val_accuracy: 0.7953\n",
      "Epoch 49/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5751 - accuracy: 0.7248 - val_loss: 0.5422 - val_accuracy: 0.7886\n",
      "Epoch 50/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.5690 - accuracy: 0.7047 - val_loss: 0.5767 - val_accuracy: 0.7517\n",
      "Epoch 51/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5770 - accuracy: 0.7013 - val_loss: 0.5892 - val_accuracy: 0.7550\n",
      "Epoch 52/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5725 - accuracy: 0.7081 - val_loss: 0.5742 - val_accuracy: 0.7718\n",
      "Epoch 53/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5652 - accuracy: 0.7215 - val_loss: 0.5631 - val_accuracy: 0.7819\n",
      "Epoch 54/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5595 - accuracy: 0.7215 - val_loss: 0.5587 - val_accuracy: 0.7852\n",
      "Epoch 55/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5587 - accuracy: 0.7248 - val_loss: 0.5484 - val_accuracy: 0.7852\n",
      "Epoch 56/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5573 - accuracy: 0.7315 - val_loss: 0.5328 - val_accuracy: 0.7919\n",
      "Epoch 57/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5519 - accuracy: 0.7349 - val_loss: 0.5180 - val_accuracy: 0.7953\n",
      "Epoch 58/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5632 - accuracy: 0.6980 - val_loss: 0.5326 - val_accuracy: 0.7550\n",
      "Epoch 59/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5639 - accuracy: 0.7148 - val_loss: 0.5275 - val_accuracy: 0.7785\n",
      "Epoch 60/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.5481 - accuracy: 0.7383 - val_loss: 0.5107 - val_accuracy: 0.8020\n",
      "Epoch 61/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5433 - accuracy: 0.7383 - val_loss: 0.5040 - val_accuracy: 0.8020\n",
      "Epoch 62/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5443 - accuracy: 0.7315 - val_loss: 0.5018 - val_accuracy: 0.7987\n",
      "Epoch 63/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5449 - accuracy: 0.7349 - val_loss: 0.5039 - val_accuracy: 0.7987\n",
      "Epoch 64/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.5372 - accuracy: 0.7383 - val_loss: 0.5227 - val_accuracy: 0.7919\n",
      "Epoch 65/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.5556 - accuracy: 0.7282 - val_loss: 0.5260 - val_accuracy: 0.7886\n",
      "Epoch 66/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.5527 - accuracy: 0.7248 - val_loss: 0.5099 - val_accuracy: 0.7953\n",
      "Epoch 67/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5423 - accuracy: 0.7483 - val_loss: 0.4873 - val_accuracy: 0.8121\n",
      "Epoch 68/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5334 - accuracy: 0.7517 - val_loss: 0.4930 - val_accuracy: 0.8054\n",
      "Epoch 69/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.5340 - accuracy: 0.7550 - val_loss: 0.4909 - val_accuracy: 0.8087\n",
      "Epoch 70/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.5345 - accuracy: 0.7416 - val_loss: 0.4829 - val_accuracy: 0.8188\n",
      "Epoch 71/350\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.5290 - accuracy: 0.7517 - val_loss: 0.4847 - val_accuracy: 0.8188\n",
      "Epoch 72/350\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.5278 - accuracy: 0.7550 - val_loss: 0.4787 - val_accuracy: 0.8221\n",
      "Epoch 73/350\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.5251 - accuracy: 0.7416 - val_loss: 0.4742 - val_accuracy: 0.8356\n",
      "Epoch 74/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.5258 - accuracy: 0.7483 - val_loss: 0.4719 - val_accuracy: 0.8255\n",
      "Epoch 75/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.5233 - accuracy: 0.7584 - val_loss: 0.4687 - val_accuracy: 0.8322\n",
      "Epoch 76/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.5226 - accuracy: 0.7550 - val_loss: 0.4667 - val_accuracy: 0.8255\n",
      "Epoch 77/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5220 - accuracy: 0.7517 - val_loss: 0.4642 - val_accuracy: 0.8289\n",
      "Epoch 78/350\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.5228 - accuracy: 0.7517 - val_loss: 0.4639 - val_accuracy: 0.8322\n",
      "Epoch 79/350\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.5180 - accuracy: 0.7584 - val_loss: 0.4681 - val_accuracy: 0.8255\n",
      "Epoch 80/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.5384 - accuracy: 0.7248 - val_loss: 0.4947 - val_accuracy: 0.7919\n",
      "Epoch 81/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.5462 - accuracy: 0.7215 - val_loss: 0.5215 - val_accuracy: 0.7785\n",
      "Epoch 82/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.5459 - accuracy: 0.7148 - val_loss: 0.5016 - val_accuracy: 0.8054\n",
      "Epoch 83/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.5401 - accuracy: 0.7215 - val_loss: 0.4767 - val_accuracy: 0.8188\n",
      "Epoch 84/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.5334 - accuracy: 0.7282 - val_loss: 0.4723 - val_accuracy: 0.8154\n",
      "Epoch 85/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5231 - accuracy: 0.7550 - val_loss: 0.4626 - val_accuracy: 0.8188\n",
      "Epoch 86/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.5202 - accuracy: 0.7617 - val_loss: 0.4553 - val_accuracy: 0.8221\n",
      "Epoch 87/350\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.5185 - accuracy: 0.7517 - val_loss: 0.4518 - val_accuracy: 0.8322\n",
      "Epoch 88/350\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.5161 - accuracy: 0.7450 - val_loss: 0.4538 - val_accuracy: 0.8289\n",
      "Epoch 89/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5097 - accuracy: 0.7617 - val_loss: 0.4506 - val_accuracy: 0.8255\n",
      "Epoch 90/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5076 - accuracy: 0.7651 - val_loss: 0.4448 - val_accuracy: 0.8356\n",
      "Epoch 91/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5058 - accuracy: 0.7651 - val_loss: 0.4412 - val_accuracy: 0.8322\n",
      "Epoch 92/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5050 - accuracy: 0.7617 - val_loss: 0.4723 - val_accuracy: 0.8154\n",
      "Epoch 93/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.5281 - accuracy: 0.7517 - val_loss: 0.4369 - val_accuracy: 0.8456\n",
      "Epoch 94/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5039 - accuracy: 0.7785 - val_loss: 0.4641 - val_accuracy: 0.8154\n",
      "Epoch 95/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5171 - accuracy: 0.7584 - val_loss: 0.4532 - val_accuracy: 0.8188\n",
      "Epoch 96/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5184 - accuracy: 0.7450 - val_loss: 0.4595 - val_accuracy: 0.8154\n",
      "Epoch 97/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5216 - accuracy: 0.7349 - val_loss: 0.4475 - val_accuracy: 0.8322\n",
      "Epoch 98/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5148 - accuracy: 0.7517 - val_loss: 0.4792 - val_accuracy: 0.7953\n",
      "Epoch 99/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5483 - accuracy: 0.7349 - val_loss: 0.5051 - val_accuracy: 0.7752\n",
      "Epoch 100/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5569 - accuracy: 0.7181 - val_loss: 0.5030 - val_accuracy: 0.7852\n",
      "Epoch 101/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5503 - accuracy: 0.7248 - val_loss: 0.4967 - val_accuracy: 0.7886\n",
      "Epoch 102/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5426 - accuracy: 0.7416 - val_loss: 0.4883 - val_accuracy: 0.7919\n",
      "Epoch 103/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5358 - accuracy: 0.7383 - val_loss: 0.4785 - val_accuracy: 0.7953\n",
      "Epoch 104/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5342 - accuracy: 0.7483 - val_loss: 0.4781 - val_accuracy: 0.7953\n",
      "Epoch 105/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5326 - accuracy: 0.7416 - val_loss: 0.4657 - val_accuracy: 0.8020\n",
      "Epoch 106/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.5306 - accuracy: 0.7450 - val_loss: 0.4601 - val_accuracy: 0.8154\n",
      "Epoch 107/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.5261 - accuracy: 0.7517 - val_loss: 0.4562 - val_accuracy: 0.8154\n",
      "Epoch 108/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5212 - accuracy: 0.7383 - val_loss: 0.4509 - val_accuracy: 0.8188\n",
      "Epoch 109/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5181 - accuracy: 0.7550 - val_loss: 0.4486 - val_accuracy: 0.8289\n",
      "Epoch 110/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5226 - accuracy: 0.7483 - val_loss: 0.4410 - val_accuracy: 0.8389\n",
      "Epoch 111/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5177 - accuracy: 0.7450 - val_loss: 0.4403 - val_accuracy: 0.8255\n",
      "Epoch 112/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5159 - accuracy: 0.7517 - val_loss: 0.4332 - val_accuracy: 0.8456\n",
      "Epoch 113/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5103 - accuracy: 0.7550 - val_loss: 0.4258 - val_accuracy: 0.8389\n",
      "Epoch 114/350\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.5097 - accuracy: 0.7383 - val_loss: 0.4243 - val_accuracy: 0.8289\n",
      "Epoch 115/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 26ms/step - loss: 0.5052 - accuracy: 0.7584 - val_loss: 0.4230 - val_accuracy: 0.8389\n",
      "Epoch 116/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.5039 - accuracy: 0.7617 - val_loss: 0.4223 - val_accuracy: 0.8456\n",
      "Epoch 117/350\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.5025 - accuracy: 0.7617 - val_loss: 0.4214 - val_accuracy: 0.8423\n",
      "Epoch 118/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.5015 - accuracy: 0.7584 - val_loss: 0.4247 - val_accuracy: 0.8356\n",
      "Epoch 119/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4999 - accuracy: 0.7685 - val_loss: 0.4202 - val_accuracy: 0.8557\n",
      "Epoch 120/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.5192 - accuracy: 0.7450 - val_loss: 0.4354 - val_accuracy: 0.8289\n",
      "Epoch 121/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.5264 - accuracy: 0.7383 - val_loss: 0.4245 - val_accuracy: 0.8389\n",
      "Epoch 122/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.5224 - accuracy: 0.7450 - val_loss: 0.4655 - val_accuracy: 0.8087\n",
      "Epoch 123/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.5124 - accuracy: 0.7450 - val_loss: 0.4177 - val_accuracy: 0.8389\n",
      "Epoch 124/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.5007 - accuracy: 0.7517 - val_loss: 0.4235 - val_accuracy: 0.8221\n",
      "Epoch 125/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4982 - accuracy: 0.7550 - val_loss: 0.4173 - val_accuracy: 0.8389\n",
      "Epoch 126/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.4950 - accuracy: 0.7584 - val_loss: 0.4246 - val_accuracy: 0.8456\n",
      "Epoch 127/350\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.4946 - accuracy: 0.7584 - val_loss: 0.4178 - val_accuracy: 0.8456\n",
      "Epoch 128/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4922 - accuracy: 0.7617 - val_loss: 0.4182 - val_accuracy: 0.8356\n",
      "Epoch 129/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.5009 - accuracy: 0.7483 - val_loss: 0.4327 - val_accuracy: 0.8289\n",
      "Epoch 130/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4977 - accuracy: 0.7517 - val_loss: 0.4212 - val_accuracy: 0.8322\n",
      "Epoch 131/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4969 - accuracy: 0.7617 - val_loss: 0.4206 - val_accuracy: 0.8255\n",
      "Epoch 132/350\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.4908 - accuracy: 0.7685 - val_loss: 0.4136 - val_accuracy: 0.8356\n",
      "Epoch 133/350\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.4872 - accuracy: 0.7685 - val_loss: 0.4268 - val_accuracy: 0.8121\n",
      "Epoch 134/350\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.4886 - accuracy: 0.7617 - val_loss: 0.4107 - val_accuracy: 0.8289\n",
      "Epoch 135/350\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.4867 - accuracy: 0.7617 - val_loss: 0.4085 - val_accuracy: 0.8289\n",
      "Epoch 136/350\n",
      "10/10 [==============================] - 0s 40ms/step - loss: 0.4867 - accuracy: 0.7651 - val_loss: 0.4077 - val_accuracy: 0.8322\n",
      "Epoch 137/350\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.4829 - accuracy: 0.7718 - val_loss: 0.4229 - val_accuracy: 0.8221\n",
      "Epoch 138/350\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.5054 - accuracy: 0.7584 - val_loss: 0.4285 - val_accuracy: 0.8255\n",
      "Epoch 139/350\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.5466 - accuracy: 0.7081 - val_loss: 0.5040 - val_accuracy: 0.7315\n",
      "Epoch 140/350\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.5214 - accuracy: 0.7282 - val_loss: 0.4945 - val_accuracy: 0.7685\n",
      "Epoch 141/350\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.5072 - accuracy: 0.7517 - val_loss: 0.4904 - val_accuracy: 0.7953\n",
      "Epoch 142/350\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.4999 - accuracy: 0.7550 - val_loss: 0.4875 - val_accuracy: 0.8087\n",
      "Epoch 143/350\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.4960 - accuracy: 0.7685 - val_loss: 0.4777 - val_accuracy: 0.8356\n",
      "Epoch 144/350\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.4939 - accuracy: 0.7718 - val_loss: 0.4654 - val_accuracy: 0.8356\n",
      "Epoch 145/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4897 - accuracy: 0.7718 - val_loss: 0.4514 - val_accuracy: 0.8221\n",
      "Epoch 146/350\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.4854 - accuracy: 0.7852 - val_loss: 0.4371 - val_accuracy: 0.8356\n",
      "Epoch 147/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4852 - accuracy: 0.7886 - val_loss: 0.4297 - val_accuracy: 0.8289\n",
      "Epoch 148/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4792 - accuracy: 0.7886 - val_loss: 0.4234 - val_accuracy: 0.8389\n",
      "Epoch 149/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4789 - accuracy: 0.7919 - val_loss: 0.4227 - val_accuracy: 0.8456\n",
      "Epoch 150/350\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.4729 - accuracy: 0.7987 - val_loss: 0.4221 - val_accuracy: 0.8423\n",
      "Epoch 151/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4763 - accuracy: 0.7987 - val_loss: 0.4211 - val_accuracy: 0.8456\n",
      "Epoch 152/350\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.4794 - accuracy: 0.7919 - val_loss: 0.4211 - val_accuracy: 0.8423\n",
      "Epoch 153/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4712 - accuracy: 0.8020 - val_loss: 0.4264 - val_accuracy: 0.8389\n",
      "Epoch 154/350\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.4736 - accuracy: 0.8020 - val_loss: 0.4218 - val_accuracy: 0.8389\n",
      "Epoch 155/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4702 - accuracy: 0.7953 - val_loss: 0.4222 - val_accuracy: 0.8389\n",
      "Epoch 156/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4698 - accuracy: 0.7987 - val_loss: 0.4206 - val_accuracy: 0.8356\n",
      "Epoch 157/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4701 - accuracy: 0.7919 - val_loss: 0.4208 - val_accuracy: 0.8289\n",
      "Epoch 158/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4667 - accuracy: 0.7919 - val_loss: 0.4233 - val_accuracy: 0.8322\n",
      "Epoch 159/350\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.4655 - accuracy: 0.7987 - val_loss: 0.4214 - val_accuracy: 0.8289\n",
      "Epoch 160/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4653 - accuracy: 0.8020 - val_loss: 0.4242 - val_accuracy: 0.8221\n",
      "Epoch 161/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4655 - accuracy: 0.8054 - val_loss: 0.4243 - val_accuracy: 0.8255\n",
      "Epoch 162/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4638 - accuracy: 0.8020 - val_loss: 0.4223 - val_accuracy: 0.8255\n",
      "Epoch 163/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4658 - accuracy: 0.8054 - val_loss: 0.4213 - val_accuracy: 0.8255\n",
      "Epoch 164/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4651 - accuracy: 0.8054 - val_loss: 0.4204 - val_accuracy: 0.8221\n",
      "Epoch 165/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4627 - accuracy: 0.8054 - val_loss: 0.4269 - val_accuracy: 0.8289\n",
      "Epoch 166/350\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.4632 - accuracy: 0.7953 - val_loss: 0.4252 - val_accuracy: 0.8154\n",
      "Epoch 167/350\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.4618 - accuracy: 0.8020 - val_loss: 0.4245 - val_accuracy: 0.8221\n",
      "Epoch 168/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4572 - accuracy: 0.8121 - val_loss: 0.4254 - val_accuracy: 0.8221\n",
      "Epoch 169/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4613 - accuracy: 0.7953 - val_loss: 0.4204 - val_accuracy: 0.8221\n",
      "Epoch 170/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4698 - accuracy: 0.7919 - val_loss: 0.4226 - val_accuracy: 0.8289\n",
      "Epoch 171/350\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.4674 - accuracy: 0.7987 - val_loss: 0.4269 - val_accuracy: 0.8221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4660 - accuracy: 0.8020 - val_loss: 0.4216 - val_accuracy: 0.8255\n",
      "Epoch 173/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4650 - accuracy: 0.7953 - val_loss: 0.4264 - val_accuracy: 0.8289\n",
      "Epoch 174/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4589 - accuracy: 0.8020 - val_loss: 0.4308 - val_accuracy: 0.8154\n",
      "Epoch 175/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4565 - accuracy: 0.8054 - val_loss: 0.4367 - val_accuracy: 0.8188\n",
      "Epoch 176/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4559 - accuracy: 0.8121 - val_loss: 0.4326 - val_accuracy: 0.8188\n",
      "Epoch 177/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4563 - accuracy: 0.8054 - val_loss: 0.4304 - val_accuracy: 0.8154\n",
      "Epoch 178/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4556 - accuracy: 0.8020 - val_loss: 0.4306 - val_accuracy: 0.8154\n",
      "Epoch 179/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4746 - accuracy: 0.7852 - val_loss: 0.4335 - val_accuracy: 0.8154\n",
      "Epoch 180/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4587 - accuracy: 0.8054 - val_loss: 0.4336 - val_accuracy: 0.8121\n",
      "Epoch 181/350\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.4531 - accuracy: 0.8154 - val_loss: 0.4319 - val_accuracy: 0.8121\n",
      "Epoch 182/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4543 - accuracy: 0.8020 - val_loss: 0.4299 - val_accuracy: 0.8154\n",
      "Epoch 183/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4658 - accuracy: 0.7953 - val_loss: 0.4296 - val_accuracy: 0.8154\n",
      "Epoch 184/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4526 - accuracy: 0.8087 - val_loss: 0.4349 - val_accuracy: 0.8121\n",
      "Epoch 185/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4507 - accuracy: 0.8087 - val_loss: 0.4284 - val_accuracy: 0.8221\n",
      "Epoch 186/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4535 - accuracy: 0.8054 - val_loss: 0.4329 - val_accuracy: 0.8154\n",
      "Epoch 187/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4676 - accuracy: 0.7852 - val_loss: 0.4373 - val_accuracy: 0.8221\n",
      "Epoch 188/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4569 - accuracy: 0.7953 - val_loss: 0.4317 - val_accuracy: 0.8087\n",
      "Epoch 189/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4523 - accuracy: 0.8154 - val_loss: 0.4336 - val_accuracy: 0.8221\n",
      "Epoch 190/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4500 - accuracy: 0.8087 - val_loss: 0.4275 - val_accuracy: 0.8188\n",
      "Epoch 191/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4539 - accuracy: 0.8087 - val_loss: 0.4262 - val_accuracy: 0.8289\n",
      "Epoch 192/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4504 - accuracy: 0.8154 - val_loss: 0.4332 - val_accuracy: 0.8154\n",
      "Epoch 193/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4469 - accuracy: 0.8188 - val_loss: 0.4306 - val_accuracy: 0.8154\n",
      "Epoch 194/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4485 - accuracy: 0.8154 - val_loss: 0.4320 - val_accuracy: 0.8255\n",
      "Epoch 195/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4453 - accuracy: 0.8221 - val_loss: 0.4425 - val_accuracy: 0.8188\n",
      "Epoch 196/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4489 - accuracy: 0.8221 - val_loss: 0.4321 - val_accuracy: 0.8154\n",
      "Epoch 197/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4510 - accuracy: 0.8054 - val_loss: 0.4304 - val_accuracy: 0.8121\n",
      "Epoch 198/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4451 - accuracy: 0.8154 - val_loss: 0.4357 - val_accuracy: 0.8255\n",
      "Epoch 199/350\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.4465 - accuracy: 0.8255 - val_loss: 0.4375 - val_accuracy: 0.8221\n",
      "Epoch 200/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4416 - accuracy: 0.8255 - val_loss: 0.4293 - val_accuracy: 0.8154\n",
      "Epoch 201/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4431 - accuracy: 0.8121 - val_loss: 0.4310 - val_accuracy: 0.8121\n",
      "Epoch 202/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4414 - accuracy: 0.8188 - val_loss: 0.4308 - val_accuracy: 0.8289\n",
      "Epoch 203/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4411 - accuracy: 0.8154 - val_loss: 0.4310 - val_accuracy: 0.8154\n",
      "Epoch 204/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4402 - accuracy: 0.8188 - val_loss: 0.4351 - val_accuracy: 0.8221\n",
      "Epoch 205/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4400 - accuracy: 0.8255 - val_loss: 0.4320 - val_accuracy: 0.8255\n",
      "Epoch 206/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4393 - accuracy: 0.8221 - val_loss: 0.4307 - val_accuracy: 0.8289\n",
      "Epoch 207/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4383 - accuracy: 0.8289 - val_loss: 0.4308 - val_accuracy: 0.8121\n",
      "Epoch 208/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4367 - accuracy: 0.8221 - val_loss: 0.4314 - val_accuracy: 0.8289\n",
      "Epoch 209/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4373 - accuracy: 0.8221 - val_loss: 0.4315 - val_accuracy: 0.8289\n",
      "Epoch 210/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4356 - accuracy: 0.8255 - val_loss: 0.4327 - val_accuracy: 0.8121\n",
      "Epoch 211/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4359 - accuracy: 0.8289 - val_loss: 0.4319 - val_accuracy: 0.8188\n",
      "Epoch 212/350\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.4353 - accuracy: 0.8221 - val_loss: 0.4316 - val_accuracy: 0.8188\n",
      "Epoch 213/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4347 - accuracy: 0.8221 - val_loss: 0.4321 - val_accuracy: 0.8188\n",
      "Epoch 214/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4341 - accuracy: 0.8289 - val_loss: 0.4323 - val_accuracy: 0.8121\n",
      "Epoch 215/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4334 - accuracy: 0.8255 - val_loss: 0.4329 - val_accuracy: 0.8289\n",
      "Epoch 216/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4317 - accuracy: 0.8188 - val_loss: 0.4331 - val_accuracy: 0.8121\n",
      "Epoch 217/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4320 - accuracy: 0.8255 - val_loss: 0.4326 - val_accuracy: 0.8121\n",
      "Epoch 218/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4315 - accuracy: 0.8188 - val_loss: 0.4362 - val_accuracy: 0.8188\n",
      "Epoch 219/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4314 - accuracy: 0.8188 - val_loss: 0.4340 - val_accuracy: 0.8188\n",
      "Epoch 220/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4335 - accuracy: 0.8188 - val_loss: 0.4354 - val_accuracy: 0.8121\n",
      "Epoch 221/350\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.4297 - accuracy: 0.8121 - val_loss: 0.4404 - val_accuracy: 0.8087\n",
      "Epoch 222/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4331 - accuracy: 0.8221 - val_loss: 0.4386 - val_accuracy: 0.8087\n",
      "Epoch 223/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4297 - accuracy: 0.8188 - val_loss: 0.4383 - val_accuracy: 0.8054\n",
      "Epoch 224/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4285 - accuracy: 0.8154 - val_loss: 0.4391 - val_accuracy: 0.8087\n",
      "Epoch 225/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4279 - accuracy: 0.8221 - val_loss: 0.4408 - val_accuracy: 0.8087\n",
      "Epoch 226/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4278 - accuracy: 0.8289 - val_loss: 0.4415 - val_accuracy: 0.8020\n",
      "Epoch 227/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4268 - accuracy: 0.8221 - val_loss: 0.4410 - val_accuracy: 0.8054\n",
      "Epoch 228/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4269 - accuracy: 0.8188 - val_loss: 0.4389 - val_accuracy: 0.8054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4252 - accuracy: 0.8255 - val_loss: 0.4371 - val_accuracy: 0.8054\n",
      "Epoch 230/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4248 - accuracy: 0.8255 - val_loss: 0.4397 - val_accuracy: 0.7987\n",
      "Epoch 231/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4241 - accuracy: 0.8289 - val_loss: 0.4403 - val_accuracy: 0.7987\n",
      "Epoch 232/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4252 - accuracy: 0.8255 - val_loss: 0.4414 - val_accuracy: 0.7987\n",
      "Epoch 233/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4233 - accuracy: 0.8289 - val_loss: 0.4411 - val_accuracy: 0.7987\n",
      "Epoch 234/350\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.4240 - accuracy: 0.8322 - val_loss: 0.4415 - val_accuracy: 0.8020\n",
      "Epoch 235/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4217 - accuracy: 0.8289 - val_loss: 0.4404 - val_accuracy: 0.8020\n",
      "Epoch 236/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4217 - accuracy: 0.8221 - val_loss: 0.4428 - val_accuracy: 0.7987\n",
      "Epoch 237/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4217 - accuracy: 0.8289 - val_loss: 0.4421 - val_accuracy: 0.7987\n",
      "Epoch 238/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4228 - accuracy: 0.8289 - val_loss: 0.4412 - val_accuracy: 0.7987\n",
      "Epoch 239/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4201 - accuracy: 0.8255 - val_loss: 0.4393 - val_accuracy: 0.8020\n",
      "Epoch 240/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4199 - accuracy: 0.8289 - val_loss: 0.4395 - val_accuracy: 0.7987\n",
      "Epoch 241/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4195 - accuracy: 0.8289 - val_loss: 0.4407 - val_accuracy: 0.8020\n",
      "Epoch 242/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4183 - accuracy: 0.8322 - val_loss: 0.4396 - val_accuracy: 0.8054\n",
      "Epoch 243/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4176 - accuracy: 0.8356 - val_loss: 0.4434 - val_accuracy: 0.8054\n",
      "Epoch 244/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4172 - accuracy: 0.8356 - val_loss: 0.4452 - val_accuracy: 0.7987\n",
      "Epoch 245/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4167 - accuracy: 0.8322 - val_loss: 0.4453 - val_accuracy: 0.7987\n",
      "Epoch 246/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4162 - accuracy: 0.8356 - val_loss: 0.4475 - val_accuracy: 0.7987\n",
      "Epoch 247/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4162 - accuracy: 0.8322 - val_loss: 0.4460 - val_accuracy: 0.7987\n",
      "Epoch 248/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4150 - accuracy: 0.8322 - val_loss: 0.4492 - val_accuracy: 0.8020\n",
      "Epoch 249/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4145 - accuracy: 0.8356 - val_loss: 0.4450 - val_accuracy: 0.8087\n",
      "Epoch 250/350\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.4144 - accuracy: 0.8389 - val_loss: 0.4466 - val_accuracy: 0.7919\n",
      "Epoch 251/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4139 - accuracy: 0.8356 - val_loss: 0.4443 - val_accuracy: 0.8054\n",
      "Epoch 252/350\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.4135 - accuracy: 0.8356 - val_loss: 0.4444 - val_accuracy: 0.8020\n",
      "Epoch 253/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4129 - accuracy: 0.8356 - val_loss: 0.4438 - val_accuracy: 0.8054\n",
      "Epoch 254/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4121 - accuracy: 0.8389 - val_loss: 0.4472 - val_accuracy: 0.8087\n",
      "Epoch 255/350\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.4120 - accuracy: 0.8389 - val_loss: 0.4444 - val_accuracy: 0.8020\n",
      "Epoch 256/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4111 - accuracy: 0.8356 - val_loss: 0.4445 - val_accuracy: 0.8020\n",
      "Epoch 257/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4113 - accuracy: 0.8356 - val_loss: 0.4396 - val_accuracy: 0.8054\n",
      "Epoch 258/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4102 - accuracy: 0.8356 - val_loss: 0.4439 - val_accuracy: 0.7987\n",
      "Epoch 259/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4096 - accuracy: 0.8389 - val_loss: 0.4442 - val_accuracy: 0.8020\n",
      "Epoch 260/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4113 - accuracy: 0.8423 - val_loss: 0.4439 - val_accuracy: 0.8020\n",
      "Epoch 261/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4083 - accuracy: 0.8356 - val_loss: 0.4441 - val_accuracy: 0.8121\n",
      "Epoch 262/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4076 - accuracy: 0.8389 - val_loss: 0.4492 - val_accuracy: 0.7987\n",
      "Epoch 263/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4063 - accuracy: 0.8389 - val_loss: 0.4468 - val_accuracy: 0.8020\n",
      "Epoch 264/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4066 - accuracy: 0.8356 - val_loss: 0.4525 - val_accuracy: 0.8054\n",
      "Epoch 265/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4074 - accuracy: 0.8356 - val_loss: 0.4465 - val_accuracy: 0.8020\n",
      "Epoch 266/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4070 - accuracy: 0.8322 - val_loss: 0.4469 - val_accuracy: 0.8087\n",
      "Epoch 267/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4048 - accuracy: 0.8490 - val_loss: 0.4522 - val_accuracy: 0.7987\n",
      "Epoch 268/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4036 - accuracy: 0.8423 - val_loss: 0.4454 - val_accuracy: 0.8020\n",
      "Epoch 269/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4124 - accuracy: 0.8221 - val_loss: 0.4513 - val_accuracy: 0.7987\n",
      "Epoch 270/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4052 - accuracy: 0.8423 - val_loss: 0.4537 - val_accuracy: 0.7987\n",
      "Epoch 271/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4118 - accuracy: 0.8255 - val_loss: 0.5014 - val_accuracy: 0.7886\n",
      "Epoch 272/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.5398 - accuracy: 0.7450 - val_loss: 0.6351 - val_accuracy: 0.7081\n",
      "Epoch 273/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.5337 - accuracy: 0.7718 - val_loss: 0.5272 - val_accuracy: 0.7685\n",
      "Epoch 274/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4722 - accuracy: 0.7919 - val_loss: 0.4387 - val_accuracy: 0.8121\n",
      "Epoch 275/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4624 - accuracy: 0.7819 - val_loss: 0.4337 - val_accuracy: 0.8221\n",
      "Epoch 276/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4311 - accuracy: 0.8221 - val_loss: 0.4520 - val_accuracy: 0.8020\n",
      "Epoch 277/350\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.4117 - accuracy: 0.8289 - val_loss: 0.4632 - val_accuracy: 0.7987\n",
      "Epoch 278/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4171 - accuracy: 0.8255 - val_loss: 0.4467 - val_accuracy: 0.8020\n",
      "Epoch 279/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4066 - accuracy: 0.8255 - val_loss: 0.4431 - val_accuracy: 0.8054\n",
      "Epoch 280/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4029 - accuracy: 0.8322 - val_loss: 0.4486 - val_accuracy: 0.8087\n",
      "Epoch 281/350\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.4015 - accuracy: 0.8356 - val_loss: 0.4558 - val_accuracy: 0.8087\n",
      "Epoch 282/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4020 - accuracy: 0.8389 - val_loss: 0.4540 - val_accuracy: 0.8087\n",
      "Epoch 283/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3993 - accuracy: 0.8356 - val_loss: 0.4540 - val_accuracy: 0.7987\n",
      "Epoch 284/350\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.3993 - accuracy: 0.8356 - val_loss: 0.4580 - val_accuracy: 0.8020\n",
      "Epoch 285/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3973 - accuracy: 0.8389 - val_loss: 0.4525 - val_accuracy: 0.8054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3973 - accuracy: 0.8389 - val_loss: 0.4592 - val_accuracy: 0.7987\n",
      "Epoch 287/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3960 - accuracy: 0.8490 - val_loss: 0.4598 - val_accuracy: 0.7987\n",
      "Epoch 288/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3962 - accuracy: 0.8423 - val_loss: 0.4604 - val_accuracy: 0.8020\n",
      "Epoch 289/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3951 - accuracy: 0.8356 - val_loss: 0.4544 - val_accuracy: 0.8054\n",
      "Epoch 290/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3944 - accuracy: 0.8423 - val_loss: 0.4615 - val_accuracy: 0.7987\n",
      "Epoch 291/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3938 - accuracy: 0.8456 - val_loss: 0.4569 - val_accuracy: 0.7953\n",
      "Epoch 292/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3913 - accuracy: 0.8490 - val_loss: 0.4649 - val_accuracy: 0.7953\n",
      "Epoch 293/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3949 - accuracy: 0.8456 - val_loss: 0.4697 - val_accuracy: 0.7987\n",
      "Epoch 294/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3913 - accuracy: 0.8423 - val_loss: 0.4589 - val_accuracy: 0.7987\n",
      "Epoch 295/350\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.3914 - accuracy: 0.8456 - val_loss: 0.4674 - val_accuracy: 0.8020\n",
      "Epoch 296/350\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.3916 - accuracy: 0.8456 - val_loss: 0.4724 - val_accuracy: 0.7919\n",
      "Epoch 297/350\n",
      "10/10 [==============================] - 0s 36ms/step - loss: 0.3897 - accuracy: 0.8456 - val_loss: 0.4635 - val_accuracy: 0.8020\n",
      "Epoch 298/350\n",
      "10/10 [==============================] - 0s 40ms/step - loss: 0.3887 - accuracy: 0.8456 - val_loss: 0.4717 - val_accuracy: 0.7886\n",
      "Epoch 299/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3869 - accuracy: 0.8490 - val_loss: 0.4783 - val_accuracy: 0.7852\n",
      "Epoch 300/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3897 - accuracy: 0.8490 - val_loss: 0.4709 - val_accuracy: 0.7919\n",
      "Epoch 301/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3846 - accuracy: 0.8490 - val_loss: 0.4735 - val_accuracy: 0.7852\n",
      "Epoch 302/350\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.3841 - accuracy: 0.8490 - val_loss: 0.4790 - val_accuracy: 0.7852\n",
      "Epoch 303/350\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.3831 - accuracy: 0.8523 - val_loss: 0.4745 - val_accuracy: 0.7886\n",
      "Epoch 304/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3820 - accuracy: 0.8456 - val_loss: 0.4800 - val_accuracy: 0.7819\n",
      "Epoch 305/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3810 - accuracy: 0.8490 - val_loss: 0.4831 - val_accuracy: 0.7785\n",
      "Epoch 306/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3790 - accuracy: 0.8523 - val_loss: 0.4896 - val_accuracy: 0.7785\n",
      "Epoch 307/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3806 - accuracy: 0.8557 - val_loss: 0.4876 - val_accuracy: 0.7752\n",
      "Epoch 308/350\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.3826 - accuracy: 0.8490 - val_loss: 0.4864 - val_accuracy: 0.7718\n",
      "Epoch 309/350\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.3749 - accuracy: 0.8591 - val_loss: 0.5009 - val_accuracy: 0.7718\n",
      "Epoch 310/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3764 - accuracy: 0.8557 - val_loss: 0.4855 - val_accuracy: 0.7852\n",
      "Epoch 311/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3792 - accuracy: 0.8523 - val_loss: 0.4962 - val_accuracy: 0.7718\n",
      "Epoch 312/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3760 - accuracy: 0.8523 - val_loss: 0.5076 - val_accuracy: 0.7617\n",
      "Epoch 313/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3715 - accuracy: 0.8591 - val_loss: 0.4971 - val_accuracy: 0.7718\n",
      "Epoch 314/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3704 - accuracy: 0.8557 - val_loss: 0.5001 - val_accuracy: 0.7718\n",
      "Epoch 315/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3707 - accuracy: 0.8591 - val_loss: 0.4963 - val_accuracy: 0.7785\n",
      "Epoch 316/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3757 - accuracy: 0.8557 - val_loss: 0.4786 - val_accuracy: 0.7919\n",
      "Epoch 317/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3717 - accuracy: 0.8624 - val_loss: 0.5133 - val_accuracy: 0.7718\n",
      "Epoch 318/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3731 - accuracy: 0.8557 - val_loss: 0.5096 - val_accuracy: 0.7651\n",
      "Epoch 319/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3701 - accuracy: 0.8591 - val_loss: 0.4824 - val_accuracy: 0.7886\n",
      "Epoch 320/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3813 - accuracy: 0.8523 - val_loss: 0.5192 - val_accuracy: 0.7685\n",
      "Epoch 321/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3737 - accuracy: 0.8356 - val_loss: 0.5118 - val_accuracy: 0.7685\n",
      "Epoch 322/350\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.3675 - accuracy: 0.8557 - val_loss: 0.5055 - val_accuracy: 0.7718\n",
      "Epoch 323/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3612 - accuracy: 0.8591 - val_loss: 0.5218 - val_accuracy: 0.7718\n",
      "Epoch 324/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3682 - accuracy: 0.8523 - val_loss: 0.5032 - val_accuracy: 0.7785\n",
      "Epoch 325/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3701 - accuracy: 0.8557 - val_loss: 0.5243 - val_accuracy: 0.7685\n",
      "Epoch 326/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3665 - accuracy: 0.8624 - val_loss: 0.4991 - val_accuracy: 0.7819\n",
      "Epoch 327/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3625 - accuracy: 0.8624 - val_loss: 0.5041 - val_accuracy: 0.7819\n",
      "Epoch 328/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3634 - accuracy: 0.8624 - val_loss: 0.5031 - val_accuracy: 0.7752\n",
      "Epoch 329/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3799 - accuracy: 0.8490 - val_loss: 0.5146 - val_accuracy: 0.7718\n",
      "Epoch 330/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3749 - accuracy: 0.8389 - val_loss: 0.5196 - val_accuracy: 0.7718\n",
      "Epoch 331/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3643 - accuracy: 0.8490 - val_loss: 0.4977 - val_accuracy: 0.7819\n",
      "Epoch 332/350\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.3633 - accuracy: 0.8557 - val_loss: 0.5216 - val_accuracy: 0.7685\n",
      "Epoch 333/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3571 - accuracy: 0.8658 - val_loss: 0.5150 - val_accuracy: 0.7785\n",
      "Epoch 334/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3544 - accuracy: 0.8691 - val_loss: 0.5094 - val_accuracy: 0.7785\n",
      "Epoch 335/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3533 - accuracy: 0.8691 - val_loss: 0.5182 - val_accuracy: 0.7752\n",
      "Epoch 336/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3525 - accuracy: 0.8658 - val_loss: 0.5204 - val_accuracy: 0.7752\n",
      "Epoch 337/350\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.3521 - accuracy: 0.8691 - val_loss: 0.5172 - val_accuracy: 0.7785\n",
      "Epoch 338/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3522 - accuracy: 0.8658 - val_loss: 0.5047 - val_accuracy: 0.7852\n",
      "Epoch 339/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3552 - accuracy: 0.8691 - val_loss: 0.5480 - val_accuracy: 0.7651\n",
      "Epoch 340/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3700 - accuracy: 0.8389 - val_loss: 0.4869 - val_accuracy: 0.7852\n",
      "Epoch 341/350\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.3577 - accuracy: 0.8523 - val_loss: 0.5248 - val_accuracy: 0.7785\n",
      "Epoch 342/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3530 - accuracy: 0.8557 - val_loss: 0.5080 - val_accuracy: 0.7785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3541 - accuracy: 0.8591 - val_loss: 0.5326 - val_accuracy: 0.7752\n",
      "Epoch 344/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3526 - accuracy: 0.8658 - val_loss: 0.5086 - val_accuracy: 0.7819\n",
      "Epoch 345/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3726 - accuracy: 0.8557 - val_loss: 0.5291 - val_accuracy: 0.7752\n",
      "Epoch 346/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4316 - accuracy: 0.8154 - val_loss: 0.6625 - val_accuracy: 0.7248\n",
      "Epoch 347/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4698 - accuracy: 0.8020 - val_loss: 0.4812 - val_accuracy: 0.7886\n",
      "Epoch 348/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4244 - accuracy: 0.8087 - val_loss: 0.5292 - val_accuracy: 0.7785\n",
      "Epoch 349/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4071 - accuracy: 0.8188 - val_loss: 0.5387 - val_accuracy: 0.7785\n",
      "Epoch 350/350\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3795 - accuracy: 0.8423 - val_loss: 0.4948 - val_accuracy: 0.7987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f87885fd9f0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filename = 'p_lin_100.csv'\n",
    "#filename1 = 'p_circ_100.csv'\n",
    "\n",
    "# train the LSTM\n",
    "\n",
    "batch_x_train = []\n",
    "batch_y_train = []\n",
    "\n",
    "df_1 = pd.read_csv('p_lin_100_ex.csv')\n",
    "\n",
    "for index, rows in df_1.iterrows():\n",
    "    batch_y_train.append(0)\n",
    "    list_1 = rows\n",
    "    batch_x_train.append(list_1)\n",
    "    \n",
    "df_2 = pd.read_csv('p_circ_100_ex.csv')            \n",
    "\n",
    "for index, rows in df_2.iterrows():\n",
    "    batch_y_train.append(1)\n",
    "    list_2 = rows\n",
    "    batch_x_train.append(list_2)\n",
    "\n",
    "\n",
    "#batch_x_train = tf.keras.utils.to_categorical(batch_x_train) #turn this into a tensor not categorical\n",
    "batch_x_train = tf.convert_to_tensor(batch_x_train, dtype=tf.float32) \n",
    "#batch_x_train = np.asarray(batch_x_train, dtype=object)\n",
    "batch_y_train = tf.keras.utils.to_categorical(batch_y_train)\n",
    "batch_y_test = batch_y_train\n",
    "\n",
    "batch_x_test = []\n",
    "\n",
    "df_3 = pd.read_csv('p_v_lin_200_ex.csv')\n",
    "\n",
    "for index, rows in df_3.iterrows():\n",
    "    list_3 = rows\n",
    "    batch_x_test.append(list_3)\n",
    "    \n",
    "df_4 = pd.read_csv('p_v_circ_200_ex.csv')\n",
    "for index, rows in df_4.iterrows():\n",
    "    list_4 = rows\n",
    "    batch_x_test.append(list_4)\n",
    "    \n",
    "batch_x_test = tf.convert_to_tensor(batch_x_test, dtype=tf.float32)\n",
    "\n",
    "\n",
    "lr = 1e-3\n",
    "num_nodes = 6\n",
    "num_classes = 2\n",
    "num_epochs = 350\n",
    "timesteps = 71\n",
    "tf.keras.backend.clear_session()\n",
    "X = tf.keras.Input(name='X', shape=[batch_x_train.shape[1],1], dtype=tf.dtypes.float32)\n",
    "lstm_output = tf.keras.layers.LSTM(num_nodes)(X)\n",
    "prediction = tf.keras.layers.Dense(num_classes)(lstm_output)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "model = keras.Model(inputs=X, outputs=prediction)\n",
    "model.compile(optimizer=opt, loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "model.fit(x=batch_x_train, y=batch_y_train, epochs=num_epochs, validation_data=(batch_x_test,batch_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "295bf767",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x_val = []\n",
    "\n",
    "df_3 = pd.read_csv('p_v_lin_200_ex.csv')\n",
    "\n",
    "for index, rows in df_3.iterrows():\n",
    "    list_3 = rows\n",
    "    batch_x_val.append(list_3)\n",
    "    \n",
    "df_4 = pd.read_csv('p_v_circ_200_ex.csv')\n",
    "for index, rows in df_4.iterrows():\n",
    "    list_4 = rows\n",
    "    batch_x_val.append(list_4)\n",
    "    \n",
    "batch_x_val = tf.convert_to_tensor(batch_x_val, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c66b72d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x_test = []\n",
    "\n",
    "rows_to_keep = [150,299]\n",
    "df_3 = pd.read_csv('p_lin_200.csv',skiprows= lambda x: x not in rows_to_keep, usecols=range(71))\n",
    "\n",
    "for index, rows in df_3.iterrows():\n",
    "    list_3 = rows\n",
    "    batch_x_test.append(list_3)\n",
    "    \n",
    "df_4 = pd.read_csv('p_circ_100.csv',nrows=[150:149], usecols=range(71))\n",
    "for index, rows in df_4.iterrows():\n",
    "    list_4 = rows\n",
    "    batch_x_test.append(list_4)\n",
    "    \n",
    "#batch_x_train = tf.keras.utils.to_categorical(batch_x_train) #turn this into a tensor not categorical\n",
    "batch_x_test = tf.convert_to_tensor(batch_x_test, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0530b148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 4ms/step\n",
      "tf.Tensor(\n",
      "[[116  33]\n",
      " [ 27 122]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "y_prediction = model.predict(batch_x_val)\n",
    "y_prediction = np.argmax(y_prediction, axis=1)\n",
    "y_test = np.argmax(batch_y_train, axis=1)\n",
    "result = tf.math.confusion_matrix(y_test, y_prediction, num_classes=2, weights=None)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa4f0734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = [\"linear\", \"circular\"]\n",
    "cm = confusion_matrix(y_test, y_prediction)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "51d83cc5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-25.08594</th>\n",
       "      <th>-21.91016</th>\n",
       "      <th>-6.261719</th>\n",
       "      <th>-42.9375</th>\n",
       "      <th>-92.32422</th>\n",
       "      <th>-88.90234</th>\n",
       "      <th>-79.36719</th>\n",
       "      <th>-107.4844</th>\n",
       "      <th>-102.5938</th>\n",
       "      <th>-93.30078</th>\n",
       "      <th>...</th>\n",
       "      <th>-57.36328</th>\n",
       "      <th>-23.375</th>\n",
       "      <th>-3.082031</th>\n",
       "      <th>-8.949219</th>\n",
       "      <th>14.27734</th>\n",
       "      <th>-4.792969</th>\n",
       "      <th>-7.484375</th>\n",
       "      <th>14.27734.1</th>\n",
       "      <th>-5.527344</th>\n",
       "      <th>7.1875</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [-25.08594, -21.91016, -6.261719, -42.9375, -92.32422, -88.90234, -79.36719, -107.4844, -102.5938, -93.30078, -91.58984, -101.125, -97.21484, -91.10156, -85.23438, -94.52344, -120.6875, -133.8906, -107.4844.1, -118.2422, -99.41406, -110.6602, -113.5977, -75.94141, -86.70312, -75.94141.1, -93.30078.1, -86.21094, -92.32422.1, -79.36719.1, -85.72266, -99.17188, -100.1484, -89.63672, -102.5938.1, -99.90234, -93.79297, -80.83203, -78.87891, -65.67578, -79.60938, -84.25781, -96.23828, -90.36719, -113.5977.1, -132.668, -113.5977.2, -94.52344.1, -110.1719, -127.7773, -89.39062, -99.66016, -93.30078.2, -86.21094.1, -109.6836, -134.3789, -106.0156, -116.7734, -129.4883, -138.7812, -103.3281, -57.36328, -23.375, -3.082031, -8.949219, 14.27734, -4.792969, -7.484375, 14.27734.1, -5.527344, 7.1875]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 71 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e975d708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n"
     ]
    }
   ],
   "source": [
    "print(batch_x_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f393fbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x_test = []\n",
    "batch_y_test = []\n",
    "\n",
    "df_1 = pd.read_csv('p_lin_100.csv')\n",
    "\n",
    "for index, rows in df_1.iterrows():\n",
    "    batch_y_train.append(0)\n",
    "    list_1 = rows\n",
    "    batch_x_train.append(list_1)\n",
    "    \n",
    "df_2 = pd.read_csv('p_circ_100.csv')            \n",
    "\n",
    "for index, rows in df_2.iterrows():\n",
    "    batch_y_train.append(1)\n",
    "    list_2 = rows\n",
    "    batch_x_train.append(list_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6befe7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_y_train = tf.keras.utils.to_categorical(batch_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c694810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(batch_y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c2856de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch_y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d1c6c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('P_extended_TS_LSTM.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34421e20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
